"""
GPU Video Super Resolver - çœŸå® GPU è¶…åˆ†æ ¸å¿ƒæ¨¡å—

è¿™æ˜¯ Stage 4.2 çš„æ ¸å¿ƒå®ç°ï¼Œç¡®ä¿ï¼š
1. nvidia-smi æ˜¾ç¤ºæ˜¾å­˜å ç”¨ > 1GB
2. GPU Util æ³¢åŠ¨ 30%~90%
3. è¾“å‡ºè§†é¢‘å¯æ’­æ”¾ä¸”åˆ†è¾¨ç‡æå‡

è®¾è®¡åŸåˆ™ï¼š
- é€å¸§å¤„ç†ï¼šdecode â†’ GPU â†’ encode
- å¤±è´¥å›é€€ï¼šGPU å¤±è´¥ä¸å½±å“æ•´ä½“æµç¨‹
- è¿›åº¦æ˜¾ç¤ºï¼šå®æ—¶æ˜¾ç¤ºå¤„ç†è¿›åº¦
"""

import os
import sys
import logging
import subprocess
import tempfile
from pathlib import Path
from typing import Optional, Callable
import time

import cv2
import numpy as np

from .model_manager import GPUModelManager

logger = logging.getLogger(__name__)


class GPUVideoSuperResolver:
    """
    GPU è§†é¢‘è¶…åˆ†è¾¨ç‡å¤„ç†å™¨
    
    ä½¿ç”¨ Real-ESRGAN è¿›è¡ŒçœŸå® GPU è¶…åˆ†ï¼Œç¡®ä¿ï¼š
    - GPU ç¡®å®å‚ä¸åƒç´ è®¡ç®—
    - å¯æ’æ‹”ã€å¯å›é€€
    - è¿›åº¦å¯è§†åŒ–
    """
    
    def __init__(self,
                 model_name: str = "RealESRGAN_x4plus",
                 tile_size: int = 384,
                 device: str = "cuda",
                 models_dir: str = "./models"):
        """
        åˆå§‹åŒ– GPU è¶…åˆ†å¤„ç†å™¨
        
        Args:
            model_name: æ¨¡å‹åç§° ("RealESRGAN_x4plus" æˆ– "RealESRGAN_x2plus")
            tile_size: ç“¦ç‰‡å¤§å°ï¼Œå½±å“æ˜¾å­˜å ç”¨ (æ¨è 512 for x2, 384 for x4)
            device: è®¾å¤‡ ("cuda" æˆ– "cpu")
            models_dir: æ¨¡å‹å­˜å‚¨ç›®å½•
        """
        self.model_name = model_name
        self.tile_size = tile_size
        self.device = device
        
        # åˆå§‹åŒ–æ¨¡å‹ç®¡ç†å™¨
        self.model_manager = GPUModelManager(models_dir=models_dir)
        
        # æ¨¡å‹åŠ è½½çŠ¶æ€
        self._model_loaded = False
        
        logger.info(f"GPUVideoSuperResolver åˆå§‹åŒ–: model={model_name}, tile={tile_size}")
    
    def _ensure_model_loaded(self) -> bool:
        """ç¡®ä¿æ¨¡å‹å·²åŠ è½½"""
        if self._model_loaded:
            return True
        
        success = self.model_manager.load_model(
            model_name=self.model_name,
            tile_size=self.tile_size,
            half=True  # FP16 èŠ‚çœæ˜¾å­˜
        )
        
        if success:
            self._model_loaded = True
            
            # æ‰“å° GPU çŠ¶æ€
            stats = self.model_manager.get_gpu_stats()
            if stats.get("available"):
                print(f"\nğŸ® GPU çŠ¶æ€:")
                print(f"   è®¾å¤‡: {stats['device']}")
                print(f"   æ€»æ˜¾å­˜: {stats['total_memory_mb']} MB")
                print(f"   å·²åˆ†é…: {stats['allocated_mb']} MB")
        
        return success
    
    def enhance_video(self,
                     input_video: str,
                     output_video: str,
                     progress_callback: Optional[Callable[[float], None]] = None) -> bool:
        """
        GPU è¶…åˆ†å¢å¼ºè§†é¢‘
        
        å¤„ç†æµç¨‹ï¼š
        1. FFmpeg è§£ç è§†é¢‘å¸§
        2. æ¯å¸§é€å…¥ GPU è¿›è¡Œ Real-ESRGAN æ¨ç†
        3. FFmpeg ç¼–ç è¾“å‡ºè§†é¢‘
        
        Args:
            input_video: è¾“å…¥è§†é¢‘è·¯å¾„
            output_video: è¾“å‡ºè§†é¢‘è·¯å¾„
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°
            
        Returns:
            å¤„ç†æˆåŠŸè¿”å› True
        """
        # éªŒè¯è¾“å…¥
        if not Path(input_video).exists():
            logger.error(f"è¾“å…¥è§†é¢‘ä¸å­˜åœ¨: {input_video}")
            return False
        
        # ç¡®ä¿æ¨¡å‹åŠ è½½
        if not self._ensure_model_loaded():
            logger.error("æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œæ— æ³•è¿›è¡Œ GPU è¶…åˆ†")
            return False
        
        try:
            # è·å–è§†é¢‘ä¿¡æ¯
            cap = cv2.VideoCapture(input_video)
            if not cap.isOpened():
                logger.error(f"æ— æ³•æ‰“å¼€è§†é¢‘: {input_video}")
                return False
            
            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            fps = cap.get(cv2.CAP_PROP_FPS)
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            
            # è®¡ç®—è¾“å‡ºåˆ†è¾¨ç‡
            scale = 4 if "x4" in self.model_name else 2
            out_width = width * scale
            out_height = height * scale
            
            print(f"\nğŸš€ GPU è¶…åˆ†å¢å¼ºå¼€å§‹")
            print(f"   è¾“å…¥: {width}x{height} @ {fps:.1f}fps")
            print(f"   è¾“å‡º: {out_width}x{out_height}")
            print(f"   æ€»å¸§æ•°: {total_frames}")
            print(f"   æ¨¡å‹: {self.model_name}")
            print(f"   ç“¦ç‰‡å¤§å°: {self.tile_size}")
            print(f"\nğŸ’¡ æç¤º:")
            print(f"   - è¿™æ˜¯ç¦»çº¿å¤„ç†ï¼Œé€‚åˆå…³é”®ç‰‡æ®µçš„é«˜è´¨é‡å¢å¼º")
            print(f"   - GPU åˆ©ç”¨ç‡ä¼šå‘ˆæ³¢å½¢ï¼Œè¿™æ˜¯æ­£å¸¸ç°è±¡")
            print(f"   - å¯åœ¨å¦ä¸€ç»ˆç«¯è¿è¡Œ 'watch -n 1 nvidia-smi' ç›‘æ§ GPU")
            print(f"   - å¤„ç†é€Ÿåº¦çº¦ 0.4 fpsï¼Œè¯·è€å¿ƒç­‰å¾…\n")
            
            # åˆ›å»ºè¾“å‡ºç›®å½•
            Path(output_video).parent.mkdir(parents=True, exist_ok=True)
            
            # åˆ›å»ºè§†é¢‘å†™å…¥å™¨
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            out = cv2.VideoWriter(output_video, fourcc, fps, (out_width, out_height))
            
            if not out.isOpened():
                logger.error("æ— æ³•åˆ›å»ºè¾“å‡ºè§†é¢‘")
                cap.release()
                return False
            
            # é€å¸§å¤„ç†
            frame_idx = 0
            start_time = time.time()
            last_print_time = start_time
            
            while True:
                ret, frame = cap.read()
                if not ret:
                    break
                
                # GPU è¶…åˆ†å¤„ç†
                try:
                    enhanced_frame = self.model_manager.enhance_frame(frame)
                except Exception as e:
                    logger.error(f"å¸§ {frame_idx} GPU å¤„ç†å¤±è´¥: {e}")
                    # å›é€€åˆ°ç®€å•æ”¾å¤§
                    enhanced_frame = cv2.resize(frame, (out_width, out_height), 
                                               interpolation=cv2.INTER_LANCZOS4)
                
                # å†™å…¥è¾“å‡º
                out.write(enhanced_frame)
                
                frame_idx += 1
                
                # è¿›åº¦æ˜¾ç¤º (æ¯ç§’æ›´æ–°ä¸€æ¬¡)
                current_time = time.time()
                if current_time - last_print_time >= 1.0 or frame_idx == total_frames:
                    last_print_time = current_time
                    progress = frame_idx / total_frames
                    elapsed = current_time - start_time
                    fps_actual = frame_idx / elapsed if elapsed > 0 else 0
                    eta = (total_frames - frame_idx) / fps_actual if fps_actual > 0 else 0
                    
                    # æ ¼å¼åŒ–å‰©ä½™æ—¶é—´
                    days = int(eta // 86400)
                    hours = int((eta % 86400) // 3600)
                    minutes = int((eta % 3600) // 60)
                    seconds = int(eta % 60)
                    
                    if days > 0:
                        eta_str = f"{days}å¤©{hours}å°æ—¶{minutes}åˆ†{seconds}ç§’"
                    elif hours > 0:
                        eta_str = f"{hours}å°æ—¶{minutes}åˆ†{seconds}ç§’"
                    elif minutes > 0:
                        eta_str = f"{minutes}åˆ†{seconds}ç§’"
                    else:
                        eta_str = f"{seconds}ç§’"
                    
                    bar_width = 40
                    filled = int(bar_width * progress)
                    bar = 'â–ˆ' * filled + 'â–‘' * (bar_width - filled)
                    
                    print(f"\r   è¿›åº¦: [{bar}] {progress*100:.1f}% "
                          f"({frame_idx}/{total_frames}) "
                          f"é€Ÿåº¦: {fps_actual:.1f} fps "
                          f"å‰©ä½™: {eta_str}", end='', flush=True)
                    
                    if progress_callback:
                        progress_callback(progress)
            
            print()  # æ¢è¡Œ
            
            # é‡Šæ”¾èµ„æº
            cap.release()
            out.release()
            
            # éªŒè¯è¾“å‡º
            if not Path(output_video).exists():
                logger.error("è¾“å‡ºè§†é¢‘æœªç”Ÿæˆ")
                return False
            
            output_size = Path(output_video).stat().st_size
            if output_size < 1000:
                logger.error(f"è¾“å‡ºè§†é¢‘å¤ªå°: {output_size} bytes")
                return False
            
            # æ‰“å°ç»Ÿè®¡
            total_time = time.time() - start_time
            avg_fps = frame_idx / total_time if total_time > 0 else 0
            
            print(f"\nâœ… GPU è¶…åˆ†å®Œæˆ!")
            print(f"   å¤„ç†å¸§æ•°: {frame_idx}")
            print(f"   æ€»è€—æ—¶: {total_time:.1f}s")
            print(f"   å¹³å‡é€Ÿåº¦: {avg_fps:.2f} fps")
            print(f"   ä¸´æ—¶æ–‡ä»¶: {output_video}")
            print(f"   æ–‡ä»¶å¤§å°: {output_size / (1024*1024):.1f} MB")
            
            # åˆå¹¶éŸ³é¢‘
            print(f"\nğŸ”Š åˆå¹¶éŸ³é¢‘...")
            temp_video = output_video + ".temp.mp4"
            Path(output_video).rename(temp_video)
            
            merge_cmd = [
                'ffmpeg', '-y',
                '-i', temp_video,
                '-i', input_video,
                '-c:v', 'copy',
                '-c:a', 'copy',
                '-map', '0:v:0',
                '-map', '1:a:0?',
                output_video
            ]
            
            result = subprocess.run(merge_cmd, capture_output=True, text=True)
            
            if result.returncode == 0:
                # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
                Path(temp_video).unlink()
                print(f"âœ… éŸ³é¢‘åˆå¹¶å®Œæˆ: {output_video}")
            else:
                logger.warning(f"éŸ³é¢‘åˆå¹¶å¤±è´¥ï¼Œä¿ç•™æ— éŸ³é¢‘ç‰ˆæœ¬: {result.stderr}")
                Path(temp_video).rename(output_video)
            
            return True
            
        except Exception as e:
            logger.error(f"GPU è¶…åˆ†å¤„ç†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def enhance_video_ffmpeg_pipe(self,
                                  input_video: str,
                                  output_video: str,
                                  progress_callback: Optional[Callable[[float], None]] = None) -> bool:
        """
        ä½¿ç”¨ FFmpeg pipe è¿›è¡Œ GPU è¶…åˆ† (æ›´é«˜æ•ˆçš„ç‰ˆæœ¬)
        
        æµç¨‹ï¼š
        FFmpeg decode (pipe) â†’ GPU æ¨ç† â†’ FFmpeg encode (pipe)
        
        Args:
            input_video: è¾“å…¥è§†é¢‘è·¯å¾„
            output_video: è¾“å‡ºè§†é¢‘è·¯å¾„
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°
            
        Returns:
            å¤„ç†æˆåŠŸè¿”å› True
        """
        # éªŒè¯è¾“å…¥
        if not Path(input_video).exists():
            logger.error(f"è¾“å…¥è§†é¢‘ä¸å­˜åœ¨: {input_video}")
            return False
        
        # ç¡®ä¿æ¨¡å‹åŠ è½½
        if not self._ensure_model_loaded():
            logger.error("æ¨¡å‹åŠ è½½å¤±è´¥")
            return False
        
        try:
            # è·å–è§†é¢‘ä¿¡æ¯
            probe_cmd = [
                'ffprobe', '-v', 'quiet',
                '-select_streams', 'v:0',
                '-show_entries', 'stream=width,height,r_frame_rate,nb_frames',
                '-of', 'csv=p=0',
                input_video
            ]
            result = subprocess.run(probe_cmd, capture_output=True, text=True)
            parts = result.stdout.strip().split(',')
            
            width = int(parts[0])
            height = int(parts[1])
            fps_parts = parts[2].split('/')
            fps = float(fps_parts[0]) / float(fps_parts[1]) if len(fps_parts) == 2 else float(fps_parts[0])
            total_frames = int(parts[3]) if len(parts) > 3 and parts[3].isdigit() else 0
            
            # è®¡ç®—è¾“å‡ºåˆ†è¾¨ç‡
            scale = 4 if "x4" in self.model_name else 2
            out_width = width * scale
            out_height = height * scale
            
            print(f"\nğŸš€ GPU è¶…åˆ†å¢å¼º (FFmpeg Pipe æ¨¡å¼)")
            print(f"   è¾“å…¥: {width}x{height} @ {fps:.1f}fps")
            print(f"   è¾“å‡º: {out_width}x{out_height}")
            print(f"   æ¨¡å‹: {self.model_name}")
            
            # FFmpeg è§£ç è¿›ç¨‹
            decode_cmd = [
                'ffmpeg', '-i', input_video,
                '-f', 'rawvideo',
                '-pix_fmt', 'bgr24',
                '-v', 'quiet',
                '-'
            ]
            
            # FFmpeg ç¼–ç è¿›ç¨‹
            encode_cmd = [
                'ffmpeg', '-y',
                '-f', 'rawvideo',
                '-pix_fmt', 'bgr24',
                '-s', f'{out_width}x{out_height}',
                '-r', str(fps),
                '-i', '-',
                '-c:v', 'libx264',
                '-preset', 'medium',
                '-crf', '18',
                '-pix_fmt', 'yuv420p',
                '-v', 'quiet',
                output_video
            ]
            
            # å¯åŠ¨è¿›ç¨‹
            decode_proc = subprocess.Popen(decode_cmd, stdout=subprocess.PIPE)
            encode_proc = subprocess.Popen(encode_cmd, stdin=subprocess.PIPE)
            
            frame_size = width * height * 3
            frame_idx = 0
            start_time = time.time()
            
            while True:
                # è¯»å–ä¸€å¸§
                raw_frame = decode_proc.stdout.read(frame_size)
                if len(raw_frame) != frame_size:
                    break
                
                # è½¬æ¢ä¸º numpy æ•°ç»„
                frame = np.frombuffer(raw_frame, dtype=np.uint8).reshape((height, width, 3))
                
                # GPU è¶…åˆ†
                try:
                    enhanced_frame = self.model_manager.enhance_frame(frame)
                except Exception as e:
                    logger.warning(f"å¸§ {frame_idx} GPU å¤±è´¥ï¼Œå›é€€åˆ° CPU: {e}")
                    enhanced_frame = cv2.resize(frame, (out_width, out_height),
                                               interpolation=cv2.INTER_LANCZOS4)
                
                # å†™å…¥ç¼–ç å™¨
                encode_proc.stdin.write(enhanced_frame.tobytes())
                
                frame_idx += 1
                
                # è¿›åº¦æ˜¾ç¤º
                if frame_idx % 10 == 0:
                    elapsed = time.time() - start_time
                    fps_actual = frame_idx / elapsed if elapsed > 0 else 0
                    
                    if total_frames > 0:
                        progress = frame_idx / total_frames
                        eta = (total_frames - frame_idx) / fps_actual if fps_actual > 0 else 0
                        
                        # æ ¼å¼åŒ–å‰©ä½™æ—¶é—´
                        days = int(eta // 86400)
                        hours = int((eta % 86400) // 3600)
                        minutes = int((eta % 3600) // 60)
                        seconds = int(eta % 60)
                        
                        if days > 0:
                            eta_str = f"{days}å¤©{hours}å°æ—¶{minutes}åˆ†{seconds}ç§’"
                        elif hours > 0:
                            eta_str = f"{hours}å°æ—¶{minutes}åˆ†{seconds}ç§’"
                        elif minutes > 0:
                            eta_str = f"{minutes}åˆ†{seconds}ç§’"
                        else:
                            eta_str = f"{seconds}ç§’"
                        
                        bar_width = 40
                        filled = int(bar_width * progress)
                        bar = 'â–ˆ' * filled + 'â–‘' * (bar_width - filled)
                        print(f"\r   è¿›åº¦: [{bar}] {progress*100:.1f}% "
                              f"é€Ÿåº¦: {fps_actual:.1f} fps "
                              f"å‰©ä½™: {eta_str}", end='', flush=True)
                    else:
                        print(f"\r   å·²å¤„ç†: {frame_idx} å¸§, é€Ÿåº¦: {fps_actual:.1f} fps", 
                              end='', flush=True)
            
            print()
            
            # å…³é—­è¿›ç¨‹
            decode_proc.stdout.close()
            encode_proc.stdin.close()
            decode_proc.wait()
            encode_proc.wait()
            
            # éªŒè¯è¾“å‡º
            if not Path(output_video).exists():
                logger.error("è¾“å‡ºè§†é¢‘æœªç”Ÿæˆ")
                return False
            
            total_time = time.time() - start_time
            print(f"\nâœ… GPU è¶…åˆ†å®Œæˆ! å¤„ç† {frame_idx} å¸§, è€—æ—¶ {total_time:.1f}s")
            
            # åˆå¹¶éŸ³é¢‘
            print(f"\nğŸ”Š åˆå¹¶éŸ³é¢‘...")
            temp_video = output_video + ".temp.mp4"
            Path(output_video).rename(temp_video)
            
            merge_cmd = [
                'ffmpeg', '-y',
                '-i', temp_video,
                '-i', input_video,
                '-c:v', 'copy',
                '-c:a', 'copy',
                '-map', '0:v:0',
                '-map', '1:a:0?',
                output_video
            ]
            
            result = subprocess.run(merge_cmd, capture_output=True, text=True)
            
            if result.returncode == 0:
                # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
                Path(temp_video).unlink()
                print(f"âœ… éŸ³é¢‘åˆå¹¶å®Œæˆ: {output_video}")
                return True
            else:
                logger.warning(f"éŸ³é¢‘åˆå¹¶å¤±è´¥ï¼Œä¿ç•™æ— éŸ³é¢‘ç‰ˆæœ¬: {result.stderr}")
                Path(temp_video).rename(output_video)
                return True
                
        except Exception as e:
            logger.error(f"FFmpeg pipe å¤„ç†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def cleanup(self) -> None:
        """æ¸…ç†èµ„æºï¼Œé‡Šæ”¾ GPU æ˜¾å­˜"""
        self.model_manager.unload_model()
        self._model_loaded = False
        logger.info("GPU èµ„æºå·²é‡Šæ”¾")


def test_gpu_stage():
    """æµ‹è¯• GPU Stage æ˜¯å¦æ­£å¸¸å·¥ä½œ"""
    print("=" * 60)
    print("GPU Stage æµ‹è¯•")
    print("=" * 60)
    
    # æ£€æŸ¥ GPU
    try:
        import torch
        if torch.cuda.is_available():
            print(f"âœ… CUDA å¯ç”¨: {torch.cuda.get_device_name(0)}")
            print(f"   æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / (1024**3):.1f} GB")
        else:
            print("âŒ CUDA ä¸å¯ç”¨")
            return False
    except ImportError:
        print("âŒ PyTorch æœªå®‰è£…")
        return False
    
    # æ£€æŸ¥ Real-ESRGAN
    try:
        from realesrgan import RealESRGANer
        print("âœ… Real-ESRGAN å¯ç”¨")
    except ImportError:
        print("âŒ Real-ESRGAN æœªå®‰è£…")
        print("   è¯·è¿è¡Œ: pip install realesrgan basicsr")
        return False
    
    # åˆ›å»ºæµ‹è¯•å›¾åƒ
    print("\nåˆ›å»ºæµ‹è¯•å›¾åƒ...")
    test_image = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)
    
    # æµ‹è¯•æ¨¡å‹åŠ è½½
    print("\næµ‹è¯•æ¨¡å‹åŠ è½½...")
    resolver = GPUVideoSuperResolver(
        model_name="RealESRGAN_x4plus",
        tile_size=384
    )
    
    if resolver._ensure_model_loaded():
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
        
        # æµ‹è¯•å•å¸§æ¨ç†
        print("\næµ‹è¯•å•å¸§ GPU æ¨ç†...")
        try:
            start = time.time()
            enhanced = resolver.model_manager.enhance_frame(test_image)
            elapsed = time.time() - start
            
            print(f"âœ… GPU æ¨ç†æˆåŠŸ!")
            print(f"   è¾“å…¥: {test_image.shape}")
            print(f"   è¾“å‡º: {enhanced.shape}")
            print(f"   è€—æ—¶: {elapsed:.2f}s")
            
            # æ£€æŸ¥ GPU ä½¿ç”¨
            allocated = torch.cuda.memory_allocated(0) / (1024**2)
            print(f"   æ˜¾å­˜å ç”¨: {allocated:.0f} MB")
            
            return True
        except Exception as e:
            print(f"âŒ GPU æ¨ç†å¤±è´¥: {e}")
            return False
    else:
        print("âŒ æ¨¡å‹åŠ è½½å¤±è´¥")
        return False


if __name__ == "__main__":
    test_gpu_stage()
