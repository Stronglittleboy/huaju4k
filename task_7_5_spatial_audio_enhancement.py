#!/usr/bin/env python3
"""
ä»»åŠ¡7.5: ç©ºé—´éŸ³é¢‘å¢å¼ºå’Œä¼˜åŒ–
Spatial audio enhancement and optimization for theater recordings
"""

import os
import json
import numpy as np
import librosa
import librosa.effects
import soundfile as sf
from pathlib import Path
from datetime import datetime
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt

class SpatialAudioEnhancer:
    def __init__(self, workspace_dir="audio_workspace"):
        self.workspace = Path(workspace_dir)
        self.workspace.mkdir(exist_ok=True)
        
        # ç©ºé—´éŸ³é¢‘å‚æ•°
        self.spatial_params = {
            "reverb_room_size": 0.7,      # å‰§åœºç©ºé—´å¤§å°
            "reverb_damping": 0.3,        # é˜»å°¼ç³»æ•°
            "stereo_width": 1.2,          # ç«‹ä½“å£°å®½åº¦
            "stage_depth": 0.8,           # èˆå°æ·±åº¦æ„Ÿ
            "ambient_level": 0.15,        # ç¯å¢ƒå£°çº§åˆ«
            "center_focus": 0.6           # ä¸­å¿ƒèšç„¦åº¦
        }
        
    def analyze_spatial_characteristics(self, audio_path):
        """åˆ†æåŸå§‹å½•éŸ³çš„ç©ºé—´ç‰¹æ€§"""
        print(f"ğŸ­ åˆ†æç©ºé—´ç‰¹æ€§: {audio_path}")
        
        # åŠ è½½ç«‹ä½“å£°éŸ³é¢‘
        y, sr = librosa.load(audio_path, sr=None, mono=False)
        
        if y.ndim == 1:
            print("âš ï¸ éŸ³é¢‘æ˜¯å•å£°é“ï¼Œå°†åˆ›å»ºä¼ªç«‹ä½“å£°")
            y = np.array([y, y])
        
        left_channel = y[0]
        right_channel = y[1]
        
        # åˆ†æç«‹ä½“å£°ç‰¹æ€§
        spatial_analysis = {}
        
        # 1. ç«‹ä½“å£°ç›¸å…³æ€§åˆ†æ
        correlation = np.corrcoef(left_channel, right_channel)[0, 1]
        spatial_analysis["stereo_correlation"] = correlation
        
        # 2. å·¦å³å£°é“èƒ½é‡å·®å¼‚
        left_energy = np.mean(left_channel**2)
        right_energy = np.mean(right_channel**2)
        energy_balance = (right_energy - left_energy) / (right_energy + left_energy + 1e-10)
        spatial_analysis["energy_balance"] = energy_balance
        
        # 3. ç›¸ä½å·®åˆ†æ
        # ä½¿ç”¨çŸ­æ—¶å‚…é‡Œå¶å˜æ¢åˆ†æç›¸ä½å…³ç³»
        stft_left = librosa.stft(left_channel)
        stft_right = librosa.stft(right_channel)
        
        phase_left = np.angle(stft_left)
        phase_right = np.angle(stft_right)
        phase_diff = np.mean(np.abs(phase_left - phase_right))
        spatial_analysis["average_phase_difference"] = phase_diff
        
        # 4. é¢‘è°±å®½åº¦åˆ†æ
        spectral_centroid_left = librosa.feature.spectral_centroid(y=left_channel, sr=sr)[0]
        spectral_centroid_right = librosa.feature.spectral_centroid(y=right_channel, sr=sr)[0]
        
        spatial_analysis["spectral_centroid_left"] = np.mean(spectral_centroid_left)
        spatial_analysis["spectral_centroid_right"] = np.mean(spectral_centroid_right)
        
        # 5. åŠ¨æ€èŒƒå›´åˆ†æ
        left_rms = librosa.feature.rms(y=left_channel)[0]
        right_rms = librosa.feature.rms(y=right_channel)[0]
        
        spatial_analysis["left_dynamic_range"] = 20 * np.log10(np.max(left_rms) / (np.mean(left_rms) + 1e-10))
        spatial_analysis["right_dynamic_range"] = 20 * np.log10(np.max(right_rms) / (np.mean(right_rms) + 1e-10))
        
        print(f"  ç«‹ä½“å£°ç›¸å…³æ€§: {correlation:.3f}")
        print(f"  èƒ½é‡å¹³è¡¡: {energy_balance:.3f}")
        print(f"  å¹³å‡ç›¸ä½å·®: {phase_diff:.3f}")
        
        return spatial_analysis, y, sr
    
    def enhance_stereo_width(self, audio_data, sr, width_factor=1.2):
        """å¢å¼ºç«‹ä½“å£°å®½åº¦"""
        print(f"ğŸ”Š å¢å¼ºç«‹ä½“å£°å®½åº¦ (å› å­: {width_factor})")
        
        if audio_data.ndim == 1:
            # å•å£°é“è½¬ç«‹ä½“å£°
            enhanced = np.array([audio_data, audio_data])
        else:
            left = audio_data[0]
            right = audio_data[1]
            
            # è®¡ç®—ä¸­é—´(Mid)å’Œä¾§é¢(Side)ä¿¡å·
            mid = (left + right) / 2
            side = (left - right) / 2
            
            # å¢å¼ºä¾§é¢ä¿¡å·ä»¥æ‰©å±•ç«‹ä½“å£°å®½åº¦
            enhanced_side = side * width_factor
            
            # é‡æ„å·¦å³å£°é“
            enhanced_left = mid + enhanced_side
            enhanced_right = mid - enhanced_side
            
            enhanced = np.array([enhanced_left, enhanced_right])
        
        return enhanced
    
    def add_stage_reverb(self, audio_data, sr):
        """æ·»åŠ èˆå°æ··å“æ•ˆæœ"""
        print("ğŸª æ·»åŠ èˆå°æ··å“æ•ˆæœ")
        
        # åˆ›å»ºç®€å•çš„æ··å“æ•ˆæœ
        # ä½¿ç”¨å¤šä¸ªå»¶è¿Ÿå’Œè¡°å‡æ¥æ¨¡æ‹Ÿå‰§åœºç©ºé—´
        
        reverb_delays = [0.02, 0.04, 0.08, 0.15, 0.25]  # å»¶è¿Ÿæ—¶é—´(ç§’)
        reverb_gains = [0.3, 0.25, 0.2, 0.15, 0.1]      # å¯¹åº”å¢ç›Š
        
        enhanced = audio_data.copy()
        
        for delay, gain in zip(reverb_delays, reverb_gains):
            delay_samples = int(delay * sr)
            
            if audio_data.ndim == 1:
                # å•å£°é“å¤„ç†
                delayed = np.zeros_like(audio_data)
                if delay_samples < len(audio_data):
                    delayed[delay_samples:] = audio_data[:-delay_samples] * gain
                enhanced += delayed
            else:
                # ç«‹ä½“å£°å¤„ç†
                for channel in range(audio_data.shape[0]):
                    delayed = np.zeros_like(audio_data[channel])
                    if delay_samples < len(audio_data[channel]):
                        delayed[delay_samples:] = audio_data[channel][:-delay_samples] * gain
                    enhanced[channel] += delayed
        
        # å½’ä¸€åŒ–é˜²æ­¢å‰Šæ³¢
        max_val = np.max(np.abs(enhanced))
        if max_val > 0.95:
            enhanced = enhanced * 0.95 / max_val
        
        return enhanced
    
    def enhance_stage_presence(self, audio_data, sr):
        """å¢å¼ºèˆå°ä¸´åœºæ„Ÿ"""
        print("ğŸ­ å¢å¼ºèˆå°ä¸´åœºæ„Ÿ")
        
        # 1. å¢å¼ºä¸­é¢‘èŒƒå›´ (äººå£°ä¸»è¦é¢‘æ®µ)
        # ä½¿ç”¨ç®€å•çš„é¢‘åŸŸæ»¤æ³¢
        if audio_data.ndim == 1:
            channels = [audio_data]
        else:
            channels = [audio_data[i] for i in range(audio_data.shape[0])]
        
        enhanced_channels = []
        
        for channel in channels:
            # FFTå¤„ç†
            fft = np.fft.rfft(channel)
            freqs = np.fft.rfftfreq(len(channel), 1/sr)
            
            # åˆ›å»ºå¢å¼ºæ»¤æ³¢å™¨
            # å¢å¼º300Hz-3kHzèŒƒå›´ (äººå£°æ¸…æ™°åº¦)
            enhancement = np.ones_like(freqs)
            
            # äººå£°å¢å¼º
            voice_mask = (freqs >= 300) & (freqs <= 3000)
            enhancement[voice_mask] *= 1.15
            
            # è½»å¾®è¡°å‡ä½é¢‘å™ªå£°
            low_freq_mask = freqs < 100
            enhancement[low_freq_mask] *= 0.9
            
            # è½»å¾®è¡°å‡é«˜é¢‘å™ªå£°
            high_freq_mask = freqs > 8000
            enhancement[high_freq_mask] *= 0.95
            
            # åº”ç”¨æ»¤æ³¢å™¨
            enhanced_fft = fft * enhancement
            enhanced_channel = np.fft.irfft(enhanced_fft, len(channel))
            enhanced_channels.append(enhanced_channel)
        
        if audio_data.ndim == 1:
            return enhanced_channels[0]
        else:
            return np.array(enhanced_channels)
    
    def optimize_spatial_depth(self, audio_data, sr):
        """ä¼˜åŒ–ç©ºé—´æ·±åº¦æ„Ÿ"""
        print("ğŸŒŠ ä¼˜åŒ–ç©ºé—´æ·±åº¦æ„Ÿ")
        
        if audio_data.ndim == 1:
            # å•å£°é“ï¼šåˆ›å»ºç®€å•çš„æ·±åº¦æ•ˆæœ
            # ä½¿ç”¨è½»å¾®çš„å»¶è¿Ÿå’Œæ»¤æ³¢
            delayed = np.zeros_like(audio_data)
            delay_samples = int(0.01 * sr)  # 10mså»¶è¿Ÿ
            
            if delay_samples < len(audio_data):
                delayed[delay_samples:] = audio_data[:-delay_samples] * 0.2
            
            enhanced = audio_data + delayed
        else:
            # ç«‹ä½“å£°ï¼šåˆ›å»ºäº¤å‰å»¶è¿Ÿæ•ˆæœ
            left = audio_data[0]
            right = audio_data[1]
            
            # å·¦å£°é“æ·»åŠ æ¥è‡ªå³å£°é“çš„è½»å¾®å»¶è¿Ÿ
            delay_samples = int(0.005 * sr)  # 5mså»¶è¿Ÿ
            
            left_enhanced = left.copy()
            right_enhanced = right.copy()
            
            if delay_samples < len(left):
                # å³åˆ°å·¦çš„å»¶è¿Ÿåé¦ˆ
                left_enhanced[delay_samples:] += right[:-delay_samples] * 0.1
                # å·¦åˆ°å³çš„å»¶è¿Ÿåé¦ˆ
                right_enhanced[delay_samples:] += left[:-delay_samples] * 0.1
            
            enhanced = np.array([left_enhanced, right_enhanced])
        
        return enhanced
    
    def process_spatial_enhancement(self, input_path, output_path):
        """æ‰§è¡Œå®Œæ•´çš„ç©ºé—´éŸ³é¢‘å¢å¼º"""
        print(f"\nğŸš€ å¼€å§‹ç©ºé—´éŸ³é¢‘å¢å¼ºå¤„ç†")
        print(f"è¾“å…¥: {input_path}")
        print(f"è¾“å‡º: {output_path}")
        
        # 1. åˆ†æåŸå§‹ç©ºé—´ç‰¹æ€§
        spatial_analysis, audio_data, sr = self.analyze_spatial_characteristics(input_path)
        
        # 2. å¢å¼ºç«‹ä½“å£°å®½åº¦
        enhanced_audio = self.enhance_stereo_width(
            audio_data, sr, 
            width_factor=self.spatial_params["stereo_width"]
        )
        
        # 3. æ·»åŠ èˆå°æ··å“
        enhanced_audio = self.add_stage_reverb(enhanced_audio, sr)
        
        # 4. å¢å¼ºèˆå°ä¸´åœºæ„Ÿ
        enhanced_audio = self.enhance_stage_presence(enhanced_audio, sr)
        
        # 5. ä¼˜åŒ–ç©ºé—´æ·±åº¦
        enhanced_audio = self.optimize_spatial_depth(enhanced_audio, sr)
        
        # 6. æœ€ç»ˆå½’ä¸€åŒ–
        max_val = np.max(np.abs(enhanced_audio))
        if max_val > 0.95:
            enhanced_audio = enhanced_audio * 0.95 / max_val
        
        # 7. ä¿å­˜å¢å¼ºåçš„éŸ³é¢‘
        if enhanced_audio.ndim == 1:
            sf.write(output_path, enhanced_audio, sr)
        else:
            sf.write(output_path, enhanced_audio.T, sr)  # soundfileéœ€è¦è½¬ç½®
        
        print(f"âœ… ç©ºé—´éŸ³é¢‘å¢å¼ºå®Œæˆ")
        
        # 8. åˆ†æå¢å¼ºåçš„ç©ºé—´ç‰¹æ€§
        enhanced_analysis, _, _ = self.analyze_spatial_characteristics(output_path)
        
        return spatial_analysis, enhanced_analysis
    
    def create_spatial_comparison_plot(self, original_analysis, enhanced_analysis):
        """åˆ›å»ºç©ºé—´ç‰¹æ€§å¯¹æ¯”å›¾"""
        print("ğŸ“Š ç”Ÿæˆç©ºé—´ç‰¹æ€§å¯¹æ¯”å›¾")
        
        fig, axes = plt.subplots(2, 2, figsize=(12, 8))
        fig.suptitle('ç©ºé—´éŸ³é¢‘å¢å¼ºæ•ˆæœå¯¹æ¯”', fontsize=14)
        
        # 1. ç«‹ä½“å£°ç›¸å…³æ€§å¯¹æ¯”
        correlations = [original_analysis["stereo_correlation"], enhanced_analysis["stereo_correlation"]]
        axes[0,0].bar(['åŸå§‹', 'å¢å¼º'], correlations, color=['blue', 'orange'])
        axes[0,0].set_title('ç«‹ä½“å£°ç›¸å…³æ€§')
        axes[0,0].set_ylabel('ç›¸å…³ç³»æ•°')
        axes[0,0].set_ylim([0, 1])
        
        # 2. èƒ½é‡å¹³è¡¡å¯¹æ¯”
        balances = [original_analysis["energy_balance"], enhanced_analysis["energy_balance"]]
        axes[0,1].bar(['åŸå§‹', 'å¢å¼º'], balances, color=['blue', 'orange'])
        axes[0,1].set_title('å·¦å³å£°é“èƒ½é‡å¹³è¡¡')
        axes[0,1].set_ylabel('å¹³è¡¡ç³»æ•°')
        
        # 3. é¢‘è°±é‡å¿ƒå¯¹æ¯”
        left_centroids = [original_analysis["spectral_centroid_left"], enhanced_analysis["spectral_centroid_left"]]
        right_centroids = [original_analysis["spectral_centroid_right"], enhanced_analysis["spectral_centroid_right"]]
        
        x = np.arange(2)
        width = 0.35
        axes[1,0].bar(x - width/2, left_centroids, width, label='å·¦å£°é“', color='lightblue')
        axes[1,0].bar(x + width/2, right_centroids, width, label='å³å£°é“', color='lightcoral')
        axes[1,0].set_title('é¢‘è°±é‡å¿ƒå¯¹æ¯”')
        axes[1,0].set_ylabel('é¢‘ç‡ (Hz)')
        axes[1,0].set_xticks(x)
        axes[1,0].set_xticklabels(['åŸå§‹', 'å¢å¼º'])
        axes[1,0].legend()
        
        # 4. åŠ¨æ€èŒƒå›´å¯¹æ¯”
        left_dr = [original_analysis["left_dynamic_range"], enhanced_analysis["left_dynamic_range"]]
        right_dr = [original_analysis["right_dynamic_range"], enhanced_analysis["right_dynamic_range"]]
        
        axes[1,1].bar(x - width/2, left_dr, width, label='å·¦å£°é“', color='lightblue')
        axes[1,1].bar(x + width/2, right_dr, width, label='å³å£°é“', color='lightcoral')
        axes[1,1].set_title('åŠ¨æ€èŒƒå›´å¯¹æ¯”')
        axes[1,1].set_ylabel('åŠ¨æ€èŒƒå›´ (dB)')
        axes[1,1].set_xticks(x)
        axes[1,1].set_xticklabels(['åŸå§‹', 'å¢å¼º'])
        axes[1,1].legend()
        
        plt.tight_layout()
        
        plot_path = self.workspace / "spatial_enhancement_comparison.png"
        plt.savefig(plot_path, dpi=150, bbox_inches='tight')
        plt.close()
        
        print(f"âœ… å¯¹æ¯”å›¾å·²ä¿å­˜: {plot_path}")
        return plot_path

def main():
    print("ğŸ­ ä»»åŠ¡7.5: ç©ºé—´éŸ³é¢‘å¢å¼ºå’Œä¼˜åŒ–")
    print("=" * 50)
    
    # åˆå§‹åŒ–ç©ºé—´éŸ³é¢‘å¢å¼ºå™¨
    enhancer = SpatialAudioEnhancer()
    
    # è¾“å…¥è¾“å‡ºæ–‡ä»¶è·¯å¾„
    input_audio = Path("audio_workspace/acoustics_optimized_audio.wav")
    output_audio = Path("audio_workspace/spatial_enhanced_audio.wav")
    
    if not input_audio.exists():
        print(f"âŒ è¾“å…¥éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {input_audio}")
        return False
    
    try:
        # æ‰§è¡Œç©ºé—´éŸ³é¢‘å¢å¼º
        original_analysis, enhanced_analysis = enhancer.process_spatial_enhancement(
            input_audio, output_audio
        )
        
        # ç”Ÿæˆå¯¹æ¯”å›¾
        plot_path = enhancer.create_spatial_comparison_plot(original_analysis, enhanced_analysis)
        
        # ç”ŸæˆæŠ¥å‘Š
        report = {
            "task": "7.5 Spatial audio enhancement and optimization",
            "timestamp": datetime.now().isoformat(),
            "input_file": str(input_audio),
            "output_file": str(output_audio),
            "spatial_parameters": enhancer.spatial_params,
            "original_analysis": original_analysis,
            "enhanced_analysis": enhanced_analysis,
            "improvements": {
                "stereo_correlation_change": enhanced_analysis["stereo_correlation"] - original_analysis["stereo_correlation"],
                "energy_balance_change": enhanced_analysis["energy_balance"] - original_analysis["energy_balance"],
                "phase_difference_change": enhanced_analysis["average_phase_difference"] - original_analysis["average_phase_difference"]
            },
            "visualization": str(plot_path)
        }
        
        # ä¿å­˜æŠ¥å‘Š
        report_path = Path("audio_workspace/task_7_5_spatial_enhancement_report.json")
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        # æ‰“å°ç»“æœ
        print(f"\nğŸ“Š ç©ºé—´éŸ³é¢‘å¢å¼ºç»“æœ:")
        print(f"   ç«‹ä½“å£°ç›¸å…³æ€§å˜åŒ–: {report['improvements']['stereo_correlation_change']:.3f}")
        print(f"   èƒ½é‡å¹³è¡¡å˜åŒ–: {report['improvements']['energy_balance_change']:.3f}")
        print(f"   ç›¸ä½å·®å˜åŒ–: {report['improvements']['phase_difference_change']:.3f}")
        print(f"   è¾“å‡ºæ–‡ä»¶: {output_audio}")
        print(f"   å¯¹æ¯”å›¾: {plot_path}")
        print(f"   æŠ¥å‘Šæ–‡ä»¶: {report_path}")
        
        print(f"\nâœ… ä»»åŠ¡7.5å®Œæˆ: ç©ºé—´éŸ³é¢‘å¢å¼ºå’Œä¼˜åŒ–")
        return True
        
    except Exception as e:
        print(f"âŒ ç©ºé—´éŸ³é¢‘å¢å¼ºå¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    success = main()
    if success:
        print("\nğŸ‰ ç©ºé—´éŸ³é¢‘å¢å¼ºä»»åŠ¡æˆåŠŸå®Œæˆ!")
    else:
        print("\nâŒ ç©ºé—´éŸ³é¢‘å¢å¼ºä»»åŠ¡å¤±è´¥")