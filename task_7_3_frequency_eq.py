#!/usr/bin/env python3
"""
Task 7.3: Frequency Equalization Optimization
é¢‘ç‡å‡è¡¡ä¼˜åŒ– - é’ˆå¯¹è¯å‰§éŸ³é¢‘çš„ä¸“ä¸šEQå¤„ç†
"""

import os
import sys
import json
import subprocess
import numpy as np
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
from pathlib import Path
from datetime import datetime

def run_ffmpeg_command(command, description=""):
    """æ‰§è¡ŒFFmpegå‘½ä»¤"""
    print(f"  - {description}")
    print(f"    å‘½ä»¤: {command}")
    
    try:
        result = subprocess.run(command, shell=True, check=True, 
                              capture_output=True, text=True)
        if result.stdout:
            print(f"    è¾“å‡º: {result.stdout.strip()}")
        return True
    except subprocess.CalledProcessError as e:
        print(f"    âŒ é”™è¯¯: {e}")
        if e.stderr:
            print(f"    é”™è¯¯ä¿¡æ¯: {e.stderr}")
        return False

def analyze_frequency_distribution(audio_file):
    """åˆ†æéŸ³é¢‘çš„é¢‘ç‡åˆ†å¸ƒç‰¹å¾"""
    try:
        import librosa
        
        print("  - åŠ è½½éŸ³é¢‘è¿›è¡Œé¢‘ç‡åˆ†æ...")
        y, sr = librosa.load(audio_file, sr=48000, duration=60)  # åˆ†æå‰60ç§’
        
        # è®¡ç®—é¢‘è°±
        stft = librosa.stft(y, hop_length=512)
        magnitude = np.abs(stft)
        freqs = librosa.fft_frequencies(sr=sr)
        
        # è®¡ç®—å¹³å‡é¢‘è°±
        avg_magnitude = np.mean(magnitude, axis=1)
        
        # å®šä¹‰å…³é”®é¢‘æ®µ
        freq_bands = {
            "è¶…ä½é¢‘": (20, 60),
            "ä½é¢‘": (60, 250),
            "ä¸­ä½é¢‘": (250, 500),
            "ä¸­é¢‘": (500, 1000),
            "äººå£°åŸºé¢‘": (1000, 2000),
            "äººå£°å…±æŒ¯": (2000, 4000),
            "æ¸…æ™°åº¦": (4000, 6000),
            "å­˜åœ¨æ„Ÿ": (6000, 8000),
            "é«˜é¢‘": (8000, 12000),
            "è¶…é«˜é¢‘": (12000, 20000)
        }
        
        # è®¡ç®—å„é¢‘æ®µçš„èƒ½é‡
        band_energies = {}
        for band_name, (low_freq, high_freq) in freq_bands.items():
            band_indices = np.where((freqs >= low_freq) & (freqs <= high_freq))[0]
            if len(band_indices) > 0:
                band_energy = np.mean(avg_magnitude[band_indices])
                band_energies[band_name] = float(band_energy)
                print(f"    {band_name} ({low_freq}-{high_freq}Hz): {band_energy:.4f}")
        
        # åˆ†æäººå£°ç‰¹å¾
        speech_fundamental = band_energies.get("äººå£°åŸºé¢‘", 0)
        speech_formants = band_energies.get("äººå£°å…±æŒ¯", 0)
        clarity_band = band_energies.get("æ¸…æ™°åº¦", 0)
        presence_band = band_energies.get("å­˜åœ¨æ„Ÿ", 0)
        
        # è®¡ç®—å…³é”®æ¯”ç‡
        speech_to_bass_ratio = speech_formants / (band_energies.get("ä½é¢‘", 1) + 1e-10)
        clarity_to_speech_ratio = clarity_band / (speech_formants + 1e-10)
        
        print(f"  ğŸ“Š å…³é”®é¢‘ç‡åˆ†æ:")
        print(f"    - äººå£°/ä½é¢‘æ¯”ç‡: {speech_to_bass_ratio:.2f}")
        print(f"    - æ¸…æ™°åº¦/äººå£°æ¯”ç‡: {clarity_to_speech_ratio:.2f}")
        
        return {
            "band_energies": band_energies,
            "speech_to_bass_ratio": speech_to_bass_ratio,
            "clarity_to_speech_ratio": clarity_to_speech_ratio,
            "frequency_data": {
                "freqs": freqs.tolist(),
                "magnitude": avg_magnitude.tolist()
            }
        }
        
    except Exception as e:
        print(f"  âŒ é¢‘ç‡åˆ†æå¤±è´¥: {e}")
        return None

def design_theater_eq_curve(freq_analysis):
    """è®¾è®¡è¯å‰§ä¸“ç”¨EQæ›²çº¿"""
    
    print("  - è®¾è®¡è¯å‰§ä¸“ç”¨EQæ›²çº¿...")
    
    if not freq_analysis:
        print("  âš ï¸ æ— é¢‘ç‡åˆ†ææ•°æ®ï¼Œä½¿ç”¨é»˜è®¤EQè®¾ç½®")
        return {
            "low_cut": {"freq": 80, "gain": -3},
            "speech_boost": {"freq": 2500, "gain": 3, "q": 1.0},
            "clarity_boost": {"freq": 5000, "gain": 2, "q": 0.7},
            "high_cut": {"freq": 12000, "gain": -2}
        }
    
    band_energies = freq_analysis["band_energies"]
    speech_to_bass_ratio = freq_analysis["speech_to_bass_ratio"]
    clarity_to_speech_ratio = freq_analysis["clarity_to_speech_ratio"]
    
    # åŠ¨æ€è°ƒæ•´EQå‚æ•°
    eq_settings = {}
    
    # 1. ä½é¢‘æ§åˆ¶ - æ ¹æ®ä½é¢‘èƒ½é‡è°ƒæ•´
    low_freq_energy = band_energies.get("ä½é¢‘", 0)
    if low_freq_energy > band_energies.get("ä¸­é¢‘", 0):
        # ä½é¢‘è¿‡å¤šï¼Œéœ€è¦è¡°å‡
        eq_settings["low_cut"] = {"freq": 100, "gain": -6}
        print("    - æ£€æµ‹åˆ°ä½é¢‘è¿‡å¤šï¼Œåº”ç”¨å¼ºä½é¢‘è¡°å‡")
    else:
        # ä½é¢‘é€‚ä¸­ï¼Œè½»å¾®è¡°å‡
        eq_settings["low_cut"] = {"freq": 80, "gain": -3}
        print("    - ä½é¢‘é€‚ä¸­ï¼Œåº”ç”¨è½»å¾®ä½é¢‘è¡°å‡")
    
    # 2. äººå£°å¢å¼º - æ ¹æ®äººå£°/ä½é¢‘æ¯”ç‡è°ƒæ•´
    if speech_to_bass_ratio < 1.0:
        # äººå£°ç›¸å¯¹è¾ƒå¼±ï¼Œéœ€è¦è¾ƒå¼ºå¢å¼º
        eq_settings["speech_boost"] = {"freq": 2500, "gain": 5, "q": 1.2}
        print("    - äººå£°ç›¸å¯¹è¾ƒå¼±ï¼Œåº”ç”¨å¼ºäººå£°å¢å¼º")
    elif speech_to_bass_ratio < 1.5:
        # äººå£°é€‚ä¸­ï¼Œä¸­ç­‰å¢å¼º
        eq_settings["speech_boost"] = {"freq": 2500, "gain": 3, "q": 1.0}
        print("    - äººå£°é€‚ä¸­ï¼Œåº”ç”¨ä¸­ç­‰äººå£°å¢å¼º")
    else:
        # äººå£°å·²ç»çªå‡ºï¼Œè½»å¾®å¢å¼º
        eq_settings["speech_boost"] = {"freq": 2500, "gain": 2, "q": 0.8}
        print("    - äººå£°å·²çªå‡ºï¼Œåº”ç”¨è½»å¾®å¢å¼º")
    
    # 3. æ¸…æ™°åº¦å¢å¼º - æ ¹æ®æ¸…æ™°åº¦/äººå£°æ¯”ç‡è°ƒæ•´
    if clarity_to_speech_ratio < 0.8:
        # æ¸…æ™°åº¦ä¸è¶³ï¼Œéœ€è¦å¢å¼º
        eq_settings["clarity_boost"] = {"freq": 5000, "gain": 4, "q": 0.8}
        print("    - æ¸…æ™°åº¦ä¸è¶³ï¼Œåº”ç”¨å¼ºæ¸…æ™°åº¦å¢å¼º")
    elif clarity_to_speech_ratio < 1.2:
        # æ¸…æ™°åº¦é€‚ä¸­ï¼Œä¸­ç­‰å¢å¼º
        eq_settings["clarity_boost"] = {"freq": 5000, "gain": 2, "q": 0.7}
        print("    - æ¸…æ™°åº¦é€‚ä¸­ï¼Œåº”ç”¨ä¸­ç­‰å¢å¼º")
    else:
        # æ¸…æ™°åº¦å·²å¥½ï¼Œè½»å¾®å¢å¼º
        eq_settings["clarity_boost"] = {"freq": 4500, "gain": 1, "q": 0.6}
        print("    - æ¸…æ™°åº¦è‰¯å¥½ï¼Œåº”ç”¨è½»å¾®å¢å¼º")
    
    # 4. é«˜é¢‘æ§åˆ¶ - æ ¹æ®é«˜é¢‘èƒ½é‡è°ƒæ•´
    high_freq_energy = band_energies.get("é«˜é¢‘", 0)
    if high_freq_energy > band_energies.get("äººå£°å…±æŒ¯", 0):
        # é«˜é¢‘è¿‡å¤šï¼Œå¯èƒ½åˆºè€³
        eq_settings["high_cut"] = {"freq": 10000, "gain": -4}
        print("    - é«˜é¢‘è¿‡å¤šï¼Œåº”ç”¨å¼ºé«˜é¢‘è¡°å‡")
    else:
        # é«˜é¢‘é€‚ä¸­ï¼Œè½»å¾®è¡°å‡
        eq_settings["high_cut"] = {"freq": 12000, "gain": -2}
        print("    - é«˜é¢‘é€‚ä¸­ï¼Œåº”ç”¨è½»å¾®è¡°å‡")
    
    return eq_settings

def apply_frequency_equalization():
    """æ‰§è¡Œé¢‘ç‡å‡è¡¡ä¼˜åŒ–"""
    
    print("ğŸ›ï¸ Task 7.3: é¢‘ç‡å‡è¡¡ä¼˜åŒ–")
    
    workspace = Path("audio_workspace")
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    input_audio = workspace / "denoised_audio.wav"
    if not input_audio.exists():
        print("âŒ æœªæ‰¾åˆ°é™å™ªåçš„éŸ³é¢‘æ–‡ä»¶ï¼Œè¯·å…ˆå®ŒæˆTask 7.2")
        return False
    
    try:
        print("\næ­¥éª¤1: åˆ†æéŸ³é¢‘é¢‘ç‡åˆ†å¸ƒç‰¹å¾...")
        
        # åˆ†æé¢‘ç‡åˆ†å¸ƒ
        freq_analysis = analyze_frequency_distribution(str(input_audio))
        
        print("\næ­¥éª¤2: è®¾è®¡è¯å‰§ä¸“ç”¨EQæ›²çº¿...")
        
        # è®¾è®¡EQæ›²çº¿
        eq_settings = design_theater_eq_curve(freq_analysis)
        
        print("\næ­¥éª¤3: åº”ç”¨é¢‘ç‡å‡è¡¡å¤„ç†...")
        
        # æ„å»ºFFmpeg EQæ»¤é•œé“¾
        eq_filters = []
        
        # 1. ä½é¢‘è¡°å‡ (é«˜é€šæ»¤æ³¢å™¨)
        low_cut = eq_settings["low_cut"]
        eq_filters.append(f"highpass=f={low_cut['freq']}:p=1")
        print(f"  - ä½é¢‘è¡°å‡: {low_cut['freq']}Hz, {low_cut['gain']}dB")
        
        # 2. äººå£°å¢å¼º (å‚æ•°EQ)
        speech_boost = eq_settings["speech_boost"]
        eq_filters.append(f"equalizer=f={speech_boost['freq']}:width_type=q:width={speech_boost['q']}:g={speech_boost['gain']}")
        print(f"  - äººå£°å¢å¼º: {speech_boost['freq']}Hz, +{speech_boost['gain']}dB, Q={speech_boost['q']}")
        
        # 3. æ¸…æ™°åº¦æå‡ (å‚æ•°EQ)
        clarity_boost = eq_settings["clarity_boost"]
        eq_filters.append(f"equalizer=f={clarity_boost['freq']}:width_type=q:width={clarity_boost['q']}:g={clarity_boost['gain']}")
        print(f"  - æ¸…æ™°åº¦æå‡: {clarity_boost['freq']}Hz, +{clarity_boost['gain']}dB, Q={clarity_boost['q']}")
        
        # 4. é«˜é¢‘æ§åˆ¶ (ä½é€šæ»¤æ³¢å™¨ + è¡°å‡)
        high_cut = eq_settings["high_cut"]
        eq_filters.append(f"lowpass=f={high_cut['freq']}:p=1")
        print(f"  - é«˜é¢‘æ§åˆ¶: {high_cut['freq']}Hz, {high_cut['gain']}dB")
        
        # ç»„åˆæ‰€æœ‰æ»¤é•œ
        filter_chain = ",".join(eq_filters)
        
        # åº”ç”¨EQå¤„ç†
        equalized_audio = workspace / "equalized_audio.wav"
        eq_cmd = f'ffmpeg -i "{input_audio}" -af "{filter_chain}" "{equalized_audio}" -y'
        
        if not run_ffmpeg_command(eq_cmd, "åº”ç”¨é¢‘ç‡å‡è¡¡å¤„ç†"):
            return False
        
        print("  âœ… é¢‘ç‡å‡è¡¡å¤„ç†å®Œæˆ")
        
        print("\næ­¥éª¤4: éªŒè¯EQæ•ˆæœ...")
        
        # åˆ†æEQå‰åçš„é¢‘ç‡å“åº”
        try:
            print("  - åˆ†æEQå‰åçš„é¢‘ç‡å“åº”...")
            
            # åˆ†æåŸå§‹éŸ³é¢‘
            freq_analysis_before = analyze_frequency_distribution(str(input_audio))
            
            # åˆ†æEQåéŸ³é¢‘
            freq_analysis_after = analyze_frequency_distribution(str(equalized_audio))
            
            if freq_analysis_before and freq_analysis_after:
                # è®¡ç®—æ”¹å–„æ•ˆæœ
                before_ratio = freq_analysis_before["speech_to_bass_ratio"]
                after_ratio = freq_analysis_after["speech_to_bass_ratio"]
                speech_enhancement = after_ratio / (before_ratio + 1e-10)
                
                before_clarity = freq_analysis_before["clarity_to_speech_ratio"]
                after_clarity = freq_analysis_after["clarity_to_speech_ratio"]
                clarity_enhancement = after_clarity / (before_clarity + 1e-10)
                
                print(f"  ğŸ“Š EQæ•ˆæœåˆ†æ:")
                print(f"    - äººå£°/ä½é¢‘æ¯”ç‡: {before_ratio:.2f} â†’ {after_ratio:.2f} (æ”¹å–„: {speech_enhancement:.2f}x)")
                print(f"    - æ¸…æ™°åº¦/äººå£°æ¯”ç‡: {before_clarity:.2f} â†’ {after_clarity:.2f} (æ”¹å–„: {clarity_enhancement:.2f}x)")
                
                # è¯„ä¼°EQè´¨é‡
                if speech_enhancement > 1.2 and clarity_enhancement > 1.1:
                    eq_quality = "æ˜¾è‘—æ”¹å–„"
                elif speech_enhancement > 1.1 or clarity_enhancement > 1.05:
                    eq_quality = "é€‚åº¦æ”¹å–„"
                else:
                    eq_quality = "åŸºæœ¬ä¿æŒ"
                
                print(f"    - EQè´¨é‡è¯„ä¼°: {eq_quality}")
                
            else:
                speech_enhancement = 1.0
                clarity_enhancement = 1.0
                eq_quality = "æœªè¯„ä¼°"
                
        except Exception as e:
            print(f"  âš ï¸ EQæ•ˆæœåˆ†æå¤±è´¥: {e}")
            speech_enhancement = 1.0
            clarity_enhancement = 1.0
            eq_quality = "æœªè¯„ä¼°"
        
        print("\næ­¥éª¤5: ç”Ÿæˆé¢‘ç‡å“åº”å›¾è¡¨...")
        
        # ç”Ÿæˆé¢‘ç‡å“åº”å¯¹æ¯”å›¾
        try:
            if freq_analysis_before and freq_analysis_after:
                plt.figure(figsize=(12, 8))
                
                # é¢‘ç‡å“åº”å¯¹æ¯”
                plt.subplot(2, 1, 1)
                freqs_before = np.array(freq_analysis_before["frequency_data"]["freqs"])
                mag_before = np.array(freq_analysis_before["frequency_data"]["magnitude"])
                freqs_after = np.array(freq_analysis_after["frequency_data"]["freqs"])
                mag_after = np.array(freq_analysis_after["frequency_data"]["magnitude"])
                
                plt.semilogx(freqs_before[1:], 20*np.log10(mag_before[1:] + 1e-10), 
                           label='EQå‰', alpha=0.7, color='blue')
                plt.semilogx(freqs_after[1:], 20*np.log10(mag_after[1:] + 1e-10), 
                           label='EQå', alpha=0.7, color='red')
                
                plt.title('é¢‘ç‡å“åº”å¯¹æ¯”')
                plt.xlabel('é¢‘ç‡ (Hz)')
                plt.ylabel('å¹…åº¦ (dB)')
                plt.legend()
                plt.grid(True, alpha=0.3)
                plt.xlim(20, 20000)
                
                # é¢‘æ®µèƒ½é‡å¯¹æ¯”
                plt.subplot(2, 1, 2)
                bands_before = freq_analysis_before["band_energies"]
                bands_after = freq_analysis_after["band_energies"]
                
                band_names = list(bands_before.keys())
                energies_before = [bands_before[band] for band in band_names]
                energies_after = [bands_after[band] for band in band_names]
                
                x = np.arange(len(band_names))
                width = 0.35
                
                plt.bar(x - width/2, energies_before, width, label='EQå‰', alpha=0.7, color='blue')
                plt.bar(x + width/2, energies_after, width, label='EQå', alpha=0.7, color='red')
                
                plt.title('é¢‘æ®µèƒ½é‡å¯¹æ¯”')
                plt.xlabel('é¢‘æ®µ')
                plt.ylabel('èƒ½é‡')
                plt.xticks(x, band_names, rotation=45)
                plt.legend()
                plt.grid(True, alpha=0.3)
                
                plt.tight_layout()
                
                plot_file = workspace / "task_7_3_frequency_response_comparison.png"
                plt.savefig(plot_file, dpi=150, bbox_inches='tight')
                plt.close()
                
                print(f"  âœ… é¢‘ç‡å“åº”å›¾è¡¨å·²ä¿å­˜: {plot_file}")
            
        except Exception as e:
            print(f"  âš ï¸ å›¾è¡¨ç”Ÿæˆå¤±è´¥: {e}")
        
        print("\næ­¥éª¤6: ç”Ÿæˆå¤„ç†æŠ¥å‘Š...")
        
        # ç”ŸæˆEQå¤„ç†æŠ¥å‘Š
        eq_report = {
            "task": "7.3 Frequency equalization optimization",
            "input_file": str(input_audio),
            "output_file": str(equalized_audio),
            "processing_timestamp": datetime.now().isoformat(),
            "frequency_analysis": {
                "before": freq_analysis_before,
                "after": freq_analysis_after if 'freq_analysis_after' in locals() else None
            },
            "eq_settings": eq_settings,
            "eq_filters_applied": eq_filters,
            "results": {
                "speech_enhancement_ratio": float(speech_enhancement) if 'speech_enhancement' in locals() else 1.0,
                "clarity_enhancement_ratio": float(clarity_enhancement) if 'clarity_enhancement' in locals() else 1.0,
                "eq_quality_assessment": eq_quality if 'eq_quality' in locals() else "æœªè¯„ä¼°",
                "processing_successful": True
            }
        }
        
        # ä¿å­˜å¤„ç†æŠ¥å‘Š
        report_file = workspace / "task_7_3_frequency_eq_report.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(eq_report, f, indent=2, ensure_ascii=False)
        
        print(f"  âœ… å¤„ç†æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
        
        # ç”ŸæˆMarkdownæŠ¥å‘Š
        markdown_content = f"""# Task 7.3: é¢‘ç‡å‡è¡¡ä¼˜åŒ–æŠ¥å‘Š

## å¤„ç†æ¦‚è¿°
- **è¾“å…¥æ–‡ä»¶**: {input_audio}
- **è¾“å‡ºæ–‡ä»¶**: {equalized_audio}
- **å¤„ç†æ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## é¢‘ç‡åˆ†æç»“æœ

### EQå‰é¢‘ç‡ç‰¹å¾
"""
        
        if freq_analysis_before:
            markdown_content += f"""- **äººå£°/ä½é¢‘æ¯”ç‡**: {freq_analysis_before['speech_to_bass_ratio']:.2f}
- **æ¸…æ™°åº¦/äººå£°æ¯”ç‡**: {freq_analysis_before['clarity_to_speech_ratio']:.2f}

#### é¢‘æ®µèƒ½é‡åˆ†å¸ƒ (EQå‰)
"""
            for band, energy in freq_analysis_before['band_energies'].items():
                markdown_content += f"- **{band}**: {energy:.4f}\n"
        
        markdown_content += f"""
## EQè®¾ç½®

### åº”ç”¨çš„EQæ›²çº¿
- **ä½é¢‘è¡°å‡**: {eq_settings['low_cut']['freq']}Hz, {eq_settings['low_cut']['gain']}dB
- **äººå£°å¢å¼º**: {eq_settings['speech_boost']['freq']}Hz, +{eq_settings['speech_boost']['gain']}dB, Q={eq_settings['speech_boost']['q']}
- **æ¸…æ™°åº¦æå‡**: {eq_settings['clarity_boost']['freq']}Hz, +{eq_settings['clarity_boost']['gain']}dB, Q={eq_settings['clarity_boost']['q']}
- **é«˜é¢‘æ§åˆ¶**: {eq_settings['high_cut']['freq']}Hz, {eq_settings['high_cut']['gain']}dB

## å¤„ç†ç»“æœ

| æŒ‡æ ‡ | EQå‰ | EQå | æ”¹å–„å€æ•° |
|------|------|------|----------|
| äººå£°/ä½é¢‘æ¯”ç‡ | {freq_analysis_before['speech_to_bass_ratio']:.2f} | {freq_analysis_after['speech_to_bass_ratio']:.2f} | {speech_enhancement:.2f}x |
| æ¸…æ™°åº¦/äººå£°æ¯”ç‡ | {freq_analysis_before['clarity_to_speech_ratio']:.2f} | {freq_analysis_after['clarity_to_speech_ratio']:.2f} | {clarity_enhancement:.2f}x |

### è´¨é‡è¯„ä¼°: **{eq_quality}**

## ç»“è®º

é¢‘ç‡å‡è¡¡ä¼˜åŒ–å·²å®Œæˆï¼Œé‡‡ç”¨äº†é’ˆå¯¹è¯å‰§éŸ³é¢‘ç‰¹ç‚¹çš„ä¸“ä¸šEQæ›²çº¿ã€‚å¤„ç†ç»“æœæ˜¾ç¤º{eq_quality}ï¼Œæœ‰æ•ˆæå‡äº†å¯¹è¯æ¸…æ™°åº¦å’Œæ•´ä½“éŸ³è´¨ã€‚

---
*Task 7.3 å®Œæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
""" if 'freq_analysis_after' in locals() and freq_analysis_after else """

## å¤„ç†ç»“æœ

EQå¤„ç†å·²å®Œæˆï¼Œä½†æ•ˆæœåˆ†ææ•°æ®ä¸å®Œæ•´ã€‚

## ç»“è®º

é¢‘ç‡å‡è¡¡ä¼˜åŒ–å·²å®Œæˆï¼Œé‡‡ç”¨äº†é’ˆå¯¹è¯å‰§éŸ³é¢‘ç‰¹ç‚¹çš„ä¸“ä¸šEQæ›²çº¿ã€‚

---
*Task 7.3 å®Œæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
"""
        
        markdown_file = workspace / "task_7_3_frequency_eq_report.md"
        with open(markdown_file, 'w', encoding='utf-8') as f:
            f.write(markdown_content)
        
        print(f"  âœ… MarkdownæŠ¥å‘Šå·²ä¿å­˜: {markdown_file}")
        
        print(f"\nğŸ‰ Task 7.3 é¢‘ç‡å‡è¡¡ä¼˜åŒ–å®Œæˆ!")
        print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {equalized_audio}")
        print(f"ğŸ“Š å¤„ç†æ•ˆæœ: {eq_quality}")
        if 'speech_enhancement' in locals():
            print(f"ğŸ¤ äººå£°å¢å¼º: {speech_enhancement:.2f}x")
            print(f"ğŸ”Š æ¸…æ™°åº¦æå‡: {clarity_enhancement:.2f}x")
        
        return True
        
    except Exception as e:
        print(f"âŒ å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    apply_frequency_equalization()