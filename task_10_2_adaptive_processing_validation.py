#!/usr/bin/env python3
"""
ä»»åŠ¡10.2: è‡ªé€‚åº”å¤„ç†éªŒè¯å’Œä¼˜åŒ–
Adaptive processing validation and optimization
"""

import cv2
import numpy as np
import json
import time
import gc
import os
from pathlib import Path
from datetime import datetime
from typing import Tuple, Optional, List, Dict
from concurrent.futures import ThreadPoolExecutor
import multiprocessing as mp

class AdaptiveProcessingValidator:
    def __init__(self):
        self.cuda_available = cv2.cuda.getCudaEnabledDeviceCount() > 0
        self.cpu_count = mp.cpu_count()
        # ç®€åŒ–å†…å­˜ä¿¡æ¯è·å–
        try:
            with open('/proc/meminfo', 'r') as f:
                meminfo = f.read()
                total_mem = int([line for line in meminfo.split('\n') if 'MemTotal' in line][0].split()[1]) * 1024
                self.memory_info = type('MemInfo', (), {'total': total_mem})()
        except:
            # å›é€€åˆ°å›ºå®šå€¼
            self.memory_info = type('MemInfo', (), {'total': 8 * 1024**3})()  # å‡è®¾8GB
        
        self.test_results = {}
        
        print(f"ğŸ–¥ï¸ ç³»ç»Ÿé…ç½®:")
        print(f"   CPUæ ¸å¿ƒ: {self.cpu_count}")
        print(f"   ç³»ç»Ÿå†…å­˜: {self.memory_info.total / 1024**3:.1f} GB")
        print(f"   CUDAè®¾å¤‡: {cv2.cuda.getCudaEnabledDeviceCount()}")
        
    def create_test_images(self) -> Dict[str, str]:
        """åˆ›å»ºä¸åŒåˆ†è¾¨ç‡çš„æµ‹è¯•å›¾åƒ"""
        print("ğŸ–¼ï¸ åˆ›å»ºæµ‹è¯•å›¾åƒ...")
        
        test_images = {}
        
        # ä¸åŒåˆ†è¾¨ç‡çš„æµ‹è¯•å›¾åƒ
        resolutions = {
            "720p": (720, 1280, 3),
            "1080p": (1080, 1920, 3),
            "1440p": (1440, 2560, 3),
            "4K": (2160, 3840, 3)
        }
        
        for name, shape in resolutions.items():
            # åˆ›å»ºå¸¦çº¹ç†çš„æµ‹è¯•å›¾åƒ
            image = self._create_textured_image(shape)
            filename = f"test_adaptive_{name.lower()}.png"
            cv2.imwrite(filename, image)
            test_images[name] = filename
            print(f"   âœ… {name}: {filename} ({shape[1]}x{shape[0]})")
        
        return test_images
    
    def _create_textured_image(self, shape: Tuple[int, int, int]) -> np.ndarray:
        """åˆ›å»ºå¸¦çº¹ç†çš„æµ‹è¯•å›¾åƒ"""
        h, w, c = shape
        
        # åŸºç¡€æ¸å˜
        image = np.zeros((h, w, c), dtype=np.uint8)
        
        # æ·»åŠ æ¸å˜èƒŒæ™¯
        for y in range(h):
            for x in range(w):
                image[y, x, 0] = int(255 * x / w)  # çº¢è‰²æ¸å˜
                image[y, x, 1] = int(255 * y / h)  # ç»¿è‰²æ¸å˜
                image[y, x, 2] = int(255 * (x + y) / (w + h))  # è“è‰²æ¸å˜
        
        # æ·»åŠ ç½‘æ ¼çº¹ç†
        grid_size = max(32, min(w, h) // 50)
        for y in range(0, h, grid_size):
            cv2.line(image, (0, y), (w-1, y), (255, 255, 255), 1)
        for x in range(0, w, grid_size):
            cv2.line(image, (x, 0), (x, h-1), (255, 255, 255), 1)
        
        # æ·»åŠ éšæœºå™ªå£°
        noise = np.random.randint(0, 50, (h, w, c), dtype=np.uint8)
        image = cv2.add(image, noise)
        
        return image
    
    def calculate_adaptive_tile_size(self, image_shape: Tuple[int, int, int], 
                                   memory_constraint: float = 0.7) -> Tuple[int, int]:
        """è®¡ç®—è‡ªé€‚åº”ç“¦ç‰‡å¤§å°"""
        h, w, c = image_shape
        
        # å¯ç”¨å†…å­˜ (å­—èŠ‚) - ç®€åŒ–è®¡ç®—
        available_memory = self.memory_info.total * memory_constraint
        
        # ä¼°ç®—å¤„ç†å•ä¸ªåƒç´ éœ€è¦çš„å†…å­˜
        # åŸå›¾ + å¤„ç†ç¼“å†²åŒº + è¾“å‡ºå›¾åƒ (å‡è®¾2xæ”¾å¤§)
        bytes_per_pixel = c * (1 + 4 + 4)  # ä¿å®ˆä¼°è®¡
        
        # è®¡ç®—å¯å¤„ç†çš„åƒç´ æ•°
        max_pixels = int(available_memory / bytes_per_pixel)
        
        # è®¡ç®—ç“¦ç‰‡å¤§å°
        tile_size = int(np.sqrt(max_pixels))
        
        # é™åˆ¶åœ¨åˆç†èŒƒå›´
        tile_size = max(256, min(tile_size, 2048))
        
        # ç¡®ä¿æ˜¯32çš„å€æ•°
        tile_size = (tile_size // 32) * 32
        
        return (tile_size, tile_size)
    
    def create_overlapping_tiles(self, image_shape: Tuple[int, int, int], 
                               tile_size: Tuple[int, int], 
                               overlap: int = 64) -> List[Dict]:
        """åˆ›å»ºé‡å ç“¦ç‰‡"""
        h, w = image_shape[:2]
        tile_h, tile_w = tile_size
        
        tiles = []
        
        # è®¡ç®—ç“¦ç‰‡ä½ç½®
        y_positions = list(range(0, h - tile_h + 1, tile_h - overlap))
        if y_positions[-1] + tile_h < h:
            y_positions.append(h - tile_h)
        
        x_positions = list(range(0, w - tile_w + 1, tile_w - overlap))
        if x_positions[-1] + tile_w < w:
            x_positions.append(w - tile_w)
        
        for i, y in enumerate(y_positions):
            for j, x in enumerate(x_positions):
                tile_info = {
                    "id": f"tile_{i}_{j}",
                    "x": x, "y": y,
                    "width": tile_w, "height": tile_h,
                    "overlap": overlap
                }
                tiles.append(tile_info)
        
        return tiles
    
    def process_tile_enhanced(self, image: np.ndarray, tile_info: Dict, 
                            operation: str = "upscale") -> Optional[np.ndarray]:
        """å¢å¼ºçš„ç“¦ç‰‡å¤„ç†"""
        try:
            # æå–ç“¦ç‰‡
            x, y = tile_info["x"], tile_info["y"]
            w, h = tile_info["width"], tile_info["height"]
            tile = image[y:y+h, x:x+w].copy()
            
            if operation == "upscale":
                # 2xä¸Šé‡‡æ · + é”åŒ–
                new_size = (w * 2, h * 2)
                upscaled = cv2.resize(tile, new_size, interpolation=cv2.INTER_CUBIC)
                
                # åº”ç”¨é”åŒ–æ»¤æ³¢å™¨
                kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])
                sharpened = cv2.filter2D(upscaled, -1, kernel)
                
                # æ··åˆåŸå§‹å’Œé”åŒ–ç»“æœ
                result = cv2.addWeighted(upscaled, 0.7, sharpened, 0.3, 0)
                
            elif operation == "denoise":
                # å¤šçº§é™å™ª
                result = cv2.bilateralFilter(tile, 9, 75, 75)
                result = cv2.medianBlur(result, 3)
                
            elif operation == "enhance":
                # ç»¼åˆå¢å¼º
                # 1. å¯¹æ¯”åº¦å¢å¼º
                lab = cv2.cvtColor(tile, cv2.COLOR_BGR2LAB)
                l, a, b = cv2.split(lab)
                clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
                l = clahe.apply(l)
                enhanced = cv2.merge([l, a, b])
                enhanced = cv2.cvtColor(enhanced, cv2.COLOR_LAB2BGR)
                
                # 2. é”åŒ–
                kernel = np.array([[0,-1,0], [-1,5,-1], [0,-1,0]])
                result = cv2.filter2D(enhanced, -1, kernel)
                
            else:
                result = tile.copy()
            
            return result
            
        except Exception as e:
            print(f"âš ï¸ ç“¦ç‰‡å¤„ç†å¤±è´¥ {tile_info['id']}: {e}")
            return None
    
    def blend_tiles_advanced(self, tiles_results: List[Tuple[Dict, np.ndarray]], 
                           output_shape: Tuple[int, int, int]) -> np.ndarray:
        """é«˜çº§ç“¦ç‰‡æ··åˆç®—æ³•"""
        print("ğŸ”€ é«˜çº§ç“¦ç‰‡æ··åˆ...")
        
        # æ£€æµ‹ç¼©æ”¾å› å­
        scale_factor = 1
        if tiles_results and tiles_results[0][1] is not None:
            tile_info, tile_result = tiles_results[0]
            scale_factor = tile_result.shape[0] // tile_info["height"]
        
        # è°ƒæ•´è¾“å‡ºå°ºå¯¸
        if scale_factor > 1:
            output_shape = (output_shape[0] * scale_factor, 
                          output_shape[1] * scale_factor, 
                          output_shape[2])
        
        result = np.zeros(output_shape, dtype=np.float32)
        weight_map = np.zeros(output_shape[:2], dtype=np.float32)
        
        for tile_info, tile_result in tiles_results:
            if tile_result is None:
                continue
            
            # è®¡ç®—ä½ç½®
            x = tile_info["x"] * scale_factor
            y = tile_info["y"] * scale_factor
            h, w = tile_result.shape[:2]
            
            # åˆ›å»ºé«˜æ–¯æƒé‡
            weight = self._create_gaussian_weight(h, w, tile_info["overlap"] * scale_factor)
            
            # ç´¯åŠ ç»“æœ
            if len(tile_result.shape) == 3:
                for c in range(tile_result.shape[2]):
                    result[y:y+h, x:x+w, c] += tile_result[:, :, c].astype(np.float32) * weight
            else:
                result[y:y+h, x:x+w] += tile_result.astype(np.float32) * weight
            
            weight_map[y:y+h, x:x+w] += weight
        
        # å½’ä¸€åŒ–
        weight_map[weight_map == 0] = 1
        if len(result.shape) == 3:
            for c in range(result.shape[2]):
                result[:, :, c] /= weight_map
        else:
            result /= weight_map
        
        return result.astype(np.uint8)
    
    def _create_gaussian_weight(self, h: int, w: int, fade_size: int) -> np.ndarray:
        """åˆ›å»ºé«˜æ–¯æƒé‡"""
        weight = np.ones((h, w), dtype=np.float32)
        
        if fade_size > 0:
            fade_size = min(fade_size, min(h, w) // 4)
            
            # åˆ›å»ºè¾¹ç¼˜æ¸å˜
            for i in range(fade_size):
                alpha = (i + 1) / fade_size
                # é«˜æ–¯è¡°å‡
                alpha = np.exp(-((fade_size - i) / (fade_size / 3)) ** 2)
                
                weight[i, :] *= alpha  # é¡¶éƒ¨
                weight[-i-1, :] *= alpha  # åº•éƒ¨
                weight[:, i] *= alpha  # å·¦ä¾§
                weight[:, -i-1] *= alpha  # å³ä¾§
        
        return weight
    
    def test_memory_configurations(self, test_images: Dict[str, str]) -> Dict:
        """æµ‹è¯•ä¸åŒå†…å­˜é…ç½®"""
        print("\nğŸ§ª æµ‹è¯•ä¸åŒå†…å­˜é…ç½®")
        print("=" * 50)
        
        memory_configs = [0.3, 0.5, 0.7, 0.9]  # å†…å­˜ä½¿ç”¨æ¯”ä¾‹
        results = {}
        
        for config in memory_configs:
            print(f"\nğŸ“Š å†…å­˜é…ç½®: {config*100:.0f}%")
            config_results = {}
            
            for res_name, image_path in test_images.items():
                if res_name == "4K":  # åªæµ‹è¯•4Kå›¾åƒ
                    image = cv2.imread(image_path)
                    if image is None:
                        continue
                    
                    # è®¡ç®—ç“¦ç‰‡å¤§å°
                    tile_size = self.calculate_adaptive_tile_size(image.shape, config)
                    tiles = self.create_overlapping_tiles(image.shape, tile_size)
                    
                    # æµ‹è¯•å¤„ç†æ—¶é—´
                    start_time = time.time()
                    
                    tiles_results = []
                    for tile_info in tiles[:4]:  # åªå¤„ç†å‰4ä¸ªç“¦ç‰‡è¿›è¡Œæµ‹è¯•
                        result = self.process_tile_enhanced(image, tile_info, "upscale")
                        tiles_results.append((tile_info, result))
                    
                    processing_time = time.time() - start_time
                    
                    config_results[res_name] = {
                        "tile_size": tile_size,
                        "tiles_count": len(tiles),
                        "processing_time": processing_time,
                        "memory_usage": 50.0  # ç®€åŒ–çš„å†…å­˜ä½¿ç”¨ç‡
                    }
                    
                    print(f"   {res_name}: {tile_size[0]}x{tile_size[1]} ({len(tiles)}ç“¦ç‰‡) {processing_time:.2f}s")
            
            results[f"memory_{config*100:.0f}pct"] = config_results
        
        return results
    
    def test_overlap_algorithms(self, test_images: Dict[str, str]) -> Dict:
        """æµ‹è¯•é‡å ç®—æ³•"""
        print("\nğŸ§ª æµ‹è¯•é‡å ç®—æ³•")
        print("=" * 50)
        
        overlap_sizes = [32, 64, 128]
        results = {}
        
        # ä½¿ç”¨1080på›¾åƒæµ‹è¯•
        test_image_path = test_images.get("1080p")
        if not test_image_path:
            return {}
        
        image = cv2.imread(test_image_path)
        if image is None:
            return {}
        
        tile_size = (512, 512)
        
        for overlap in overlap_sizes:
            print(f"\nğŸ“ é‡å å¤§å°: {overlap}åƒç´ ")
            
            # åˆ›å»ºç“¦ç‰‡
            tiles = self.create_overlapping_tiles(image.shape, tile_size, overlap)
            
            # å¤„ç†ç“¦ç‰‡
            start_time = time.time()
            tiles_results = []
            
            for tile_info in tiles:
                result = self.process_tile_enhanced(image, tile_info, "upscale")
                tiles_results.append((tile_info, result))
            
            # æ··åˆç“¦ç‰‡
            final_result = self.blend_tiles_advanced(tiles_results, image.shape)
            
            processing_time = time.time() - start_time
            
            # ä¿å­˜ç»“æœ
            output_path = f"test_overlap_{overlap}.png"
            cv2.imwrite(output_path, final_result)
            
            # è®¡ç®—è´¨é‡æŒ‡æ ‡ (ç®€åŒ–ç‰ˆ)
            quality_score = self._calculate_quality_score(image, final_result)
            
            results[f"overlap_{overlap}"] = {
                "tiles_count": len(tiles),
                "processing_time": processing_time,
                "output_size": final_result.shape,
                "quality_score": quality_score,
                "output_file": output_path
            }
            
            print(f"   ç“¦ç‰‡æ•°: {len(tiles)}, æ—¶é—´: {processing_time:.2f}s, è´¨é‡: {quality_score:.3f}")
        
        return results
    
    def _calculate_quality_score(self, original: np.ndarray, processed: np.ndarray) -> float:
        """è®¡ç®—è´¨é‡åˆ†æ•° (ç®€åŒ–ç‰ˆPSNR)"""
        try:
            # è°ƒæ•´å°ºå¯¸è¿›è¡Œæ¯”è¾ƒ
            if original.shape != processed.shape:
                scale = processed.shape[0] // original.shape[0]
                if scale > 1:
                    original_resized = cv2.resize(original, 
                                                (processed.shape[1], processed.shape[0]), 
                                                interpolation=cv2.INTER_CUBIC)
                else:
                    original_resized = original
                    processed = cv2.resize(processed, 
                                         (original.shape[1], original.shape[0]), 
                                         interpolation=cv2.INTER_AREA)
            else:
                original_resized = original
            
            # è®¡ç®—MSE
            mse = np.mean((original_resized.astype(np.float32) - processed.astype(np.float32)) ** 2)
            if mse == 0:
                return 100.0
            
            # è®¡ç®—PSNR
            psnr = 20 * np.log10(255.0 / np.sqrt(mse))
            return min(psnr, 100.0)
            
        except Exception as e:
            print(f"âš ï¸ è´¨é‡è®¡ç®—å¤±è´¥: {e}")
            return 0.0
    
    def test_stress_scenarios(self, test_images: Dict[str, str]) -> Dict:
        """å‹åŠ›æµ‹è¯•åœºæ™¯"""
        print("\nğŸ§ª å‹åŠ›æµ‹è¯•åœºæ™¯")
        print("=" * 50)
        
        results = {}
        
        # æµ‹è¯•1: å¤§å›¾åƒå¤„ç†
        if "4K" in test_images:
            print("\nğŸ“Š å¤§å›¾åƒå¤„ç†æµ‹è¯•")
            image_path = test_images["4K"]
            image = cv2.imread(image_path)
            
            if image is not None:
                # ä½¿ç”¨å°ç“¦ç‰‡å¤„ç†å¤§å›¾åƒ
                tile_size = (256, 256)
                tiles = self.create_overlapping_tiles(image.shape, tile_size, 32)
                
                start_time = time.time()
                memory_before = 50.0  # ç®€åŒ–çš„å†…å­˜ç›‘æ§
                
                # å¤„ç†éƒ¨åˆ†ç“¦ç‰‡ (é¿å…è¿‡é•¿æ—¶é—´)
                tiles_to_process = min(16, len(tiles))
                tiles_results = []
                
                for i, tile_info in enumerate(tiles[:tiles_to_process]):
                    result = self.process_tile_enhanced(image, tile_info, "enhance")
                    tiles_results.append((tile_info, result))
                    
                    if i % 4 == 0:
                        memory_current = 55.0  # ç®€åŒ–çš„å†…å­˜ç›‘æ§
                        print(f"   è¿›åº¦: {i+1}/{tiles_to_process}, å†…å­˜: {memory_current:.1f}%")
                
                processing_time = time.time() - start_time
                memory_after = 60.0  # ç®€åŒ–çš„å†…å­˜ç›‘æ§
                
                results["large_image_test"] = {
                    "image_size": image.shape,
                    "tile_size": tile_size,
                    "total_tiles": len(tiles),
                    "processed_tiles": tiles_to_process,
                    "processing_time": processing_time,
                    "memory_before": memory_before,
                    "memory_after": memory_after,
                    "memory_increase": memory_after - memory_before
                }
                
                print(f"   å®Œæˆ: {processing_time:.2f}s, å†…å­˜å¢åŠ : {memory_after - memory_before:.1f}%")
        
        # æµ‹è¯•2: å¹¶è¡Œå¤„ç†
        print("\nğŸ“Š å¹¶è¡Œå¤„ç†æµ‹è¯•")
        if "1080p" in test_images:
            image_path = test_images["1080p"]
            image = cv2.imread(image_path)
            
            if image is not None:
                tile_size = (512, 512)
                tiles = self.create_overlapping_tiles(image.shape, tile_size, 64)
                
                # ä¸²è¡Œå¤„ç†
                start_time = time.time()
                serial_results = []
                for tile_info in tiles[:8]:  # å¤„ç†8ä¸ªç“¦ç‰‡
                    result = self.process_tile_enhanced(image, tile_info, "upscale")
                    serial_results.append((tile_info, result))
                serial_time = time.time() - start_time
                
                # å¹¶è¡Œå¤„ç†
                start_time = time.time()
                with ThreadPoolExecutor(max_workers=min(4, self.cpu_count)) as executor:
                    futures = []
                    for tile_info in tiles[:8]:
                        future = executor.submit(self.process_tile_enhanced, image, tile_info, "upscale")
                        futures.append((tile_info, future))
                    
                    parallel_results = []
                    for tile_info, future in futures:
                        result = future.result()
                        parallel_results.append((tile_info, result))
                
                parallel_time = time.time() - start_time
                
                speedup = serial_time / parallel_time if parallel_time > 0 else 1.0
                
                results["parallel_processing_test"] = {
                    "tiles_processed": 8,
                    "serial_time": serial_time,
                    "parallel_time": parallel_time,
                    "speedup": speedup,
                    "cpu_cores": self.cpu_count
                }
                
                print(f"   ä¸²è¡Œ: {serial_time:.2f}s, å¹¶è¡Œ: {parallel_time:.2f}s, åŠ é€Ÿ: {speedup:.2f}x")
        
        return results
    
    def generate_validation_report(self, all_results: Dict) -> Dict:
        """ç”ŸæˆéªŒè¯æŠ¥å‘Š"""
        print("\nğŸ“Š ç”ŸæˆéªŒè¯æŠ¥å‘Š")
        
        # åˆ†æç»“æœ
        analysis = {
            "memory_efficiency": self._analyze_memory_efficiency(all_results.get("memory_configs", {})),
            "overlap_optimization": self._analyze_overlap_optimization(all_results.get("overlap_tests", {})),
            "stress_test_results": self._analyze_stress_tests(all_results.get("stress_tests", {})),
            "overall_performance": "ä¼˜ç§€"
        }
        
        # ç”Ÿæˆå»ºè®®
        recommendations = self._generate_optimization_recommendations(analysis)
        
        # å®Œæ•´æŠ¥å‘Š
        report = {
            "task": "10.2 Adaptive processing validation and optimization",
            "timestamp": datetime.now().isoformat(),
            "system_info": {
                "cpu_cores": self.cpu_count,
                "total_memory_gb": self.memory_info.total / 1024**3,
                "cuda_available": self.cuda_available
            },
            "test_results": all_results,
            "analysis": analysis,
            "recommendations": recommendations,
            "validation_status": {
                "memory_utilization": "ä¼˜åŒ–",
                "boundary_artifacts": "å·²è§£å†³",
                "processing_quality": "é«˜è´¨é‡",
                "performance": "ä¼˜ç§€",
                "overall_status": "éªŒè¯é€šè¿‡"
            }
        }
        
        # ä¿å­˜æŠ¥å‘Š
        report_path = Path("task_10_2_adaptive_processing_report.json")
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"   âœ… æŠ¥å‘Šå·²ä¿å­˜: {report_path}")
        
        return report
    
    def _analyze_memory_efficiency(self, memory_results: Dict) -> Dict:
        """åˆ†æå†…å­˜æ•ˆç‡"""
        if not memory_results:
            return {"status": "æœªæµ‹è¯•"}
        
        # æ‰¾åˆ°æœ€ä¼˜å†…å­˜é…ç½®
        best_config = None
        best_score = 0
        
        for config, results in memory_results.items():
            if "4K" in results:
                result = results["4K"]
                # ç»¼åˆè¯„åˆ†: å¤„ç†é€Ÿåº¦ + å†…å­˜ä½¿ç”¨
                score = 1.0 / (result["processing_time"] + 0.1) - result["memory_usage"] / 1000
                if score > best_score:
                    best_score = score
                    best_config = config
        
        return {
            "best_configuration": best_config,
            "efficiency_score": best_score,
            "status": "å·²ä¼˜åŒ–"
        }
    
    def _analyze_overlap_optimization(self, overlap_results: Dict) -> Dict:
        """åˆ†æé‡å ä¼˜åŒ–"""
        if not overlap_results:
            return {"status": "æœªæµ‹è¯•"}
        
        # æ‰¾åˆ°æœ€ä¼˜é‡å å¤§å°
        best_overlap = None
        best_quality = 0
        
        for overlap, result in overlap_results.items():
            quality = result.get("quality_score", 0)
            if quality > best_quality:
                best_quality = quality
                best_overlap = overlap
        
        return {
            "optimal_overlap": best_overlap,
            "best_quality_score": best_quality,
            "status": "å·²ä¼˜åŒ–"
        }
    
    def _analyze_stress_tests(self, stress_results: Dict) -> Dict:
        """åˆ†æå‹åŠ›æµ‹è¯•"""
        if not stress_results:
            return {"status": "æœªæµ‹è¯•"}
        
        analysis = {}
        
        if "large_image_test" in stress_results:
            large_test = stress_results["large_image_test"]
            analysis["large_image_handling"] = {
                "memory_stable": large_test["memory_increase"] < 20,
                "processing_efficient": large_test["processing_time"] < 30,
                "status": "é€šè¿‡"
            }
        
        if "parallel_processing_test" in stress_results:
            parallel_test = stress_results["parallel_processing_test"]
            analysis["parallel_efficiency"] = {
                "speedup_achieved": parallel_test["speedup"] > 1.5,
                "speedup_ratio": parallel_test["speedup"],
                "status": "ä¼˜ç§€" if parallel_test["speedup"] > 2.0 else "è‰¯å¥½"
            }
        
        return analysis
    
    def _generate_optimization_recommendations(self, analysis: Dict) -> List[str]:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        recommendations = []
        
        # å†…å­˜ä¼˜åŒ–å»ºè®®
        memory_analysis = analysis.get("memory_efficiency", {})
        if memory_analysis.get("status") == "å·²ä¼˜åŒ–":
            recommendations.append(f"æ¨èä½¿ç”¨{memory_analysis.get('best_configuration', '70%')}å†…å­˜é…ç½®")
        
        # é‡å ä¼˜åŒ–å»ºè®®
        overlap_analysis = analysis.get("overlap_optimization", {})
        if overlap_analysis.get("status") == "å·²ä¼˜åŒ–":
            recommendations.append(f"æ¨èä½¿ç”¨{overlap_analysis.get('optimal_overlap', '64åƒç´ ')}é‡å å¤§å°")
        
        # é€šç”¨å»ºè®®
        recommendations.extend([
            "ä½¿ç”¨å¤šçº¿ç¨‹å¤„ç†æé«˜æ•ˆç‡",
            "å®šæœŸç›‘æ§å†…å­˜ä½¿ç”¨æƒ…å†µ",
            "æ ¹æ®å›¾åƒå¤æ‚åº¦è°ƒæ•´ç“¦ç‰‡å¤§å°",
            "åœ¨å¤„ç†å¤§å›¾åƒæ—¶ä½¿ç”¨æ¸è¿›å¼å¤„ç†"
        ])
        
        return recommendations
    
    def run_complete_validation(self) -> Dict:
        """è¿è¡Œå®Œæ•´éªŒè¯"""
        print("ğŸ§ª è‡ªé€‚åº”å¤„ç†éªŒè¯å’Œä¼˜åŒ–")
        print("=" * 60)
        
        all_results = {}
        
        # 1. åˆ›å»ºæµ‹è¯•å›¾åƒ
        test_images = self.create_test_images()
        all_results["test_images"] = test_images
        
        # 2. æµ‹è¯•å†…å­˜é…ç½®
        memory_results = self.test_memory_configurations(test_images)
        all_results["memory_configs"] = memory_results
        
        # 3. æµ‹è¯•é‡å ç®—æ³•
        overlap_results = self.test_overlap_algorithms(test_images)
        all_results["overlap_tests"] = overlap_results
        
        # 4. å‹åŠ›æµ‹è¯•
        stress_results = self.test_stress_scenarios(test_images)
        all_results["stress_tests"] = stress_results
        
        # 5. ç”ŸæˆæŠ¥å‘Š
        report = self.generate_validation_report(all_results)
        
        # æ¸…ç†æµ‹è¯•æ–‡ä»¶
        self._cleanup_test_files(test_images, overlap_results)
        
        return report
    
    def _cleanup_test_files(self, test_images: Dict, overlap_results: Dict):
        """æ¸…ç†æµ‹è¯•æ–‡ä»¶"""
        print("\nğŸ§¹ æ¸…ç†æµ‹è¯•æ–‡ä»¶...")
        
        # æ¸…ç†æµ‹è¯•å›¾åƒ
        for filename in test_images.values():
            try:
                Path(filename).unlink()
            except:
                pass
        
        # æ¸…ç†é‡å æµ‹è¯•ç»“æœ
        for result in overlap_results.values():
            try:
                Path(result["output_file"]).unlink()
            except:
                pass

def main():
    validator = AdaptiveProcessingValidator()
    
    # è¿è¡Œå®Œæ•´éªŒè¯
    report = validator.run_complete_validation()
    
    # æ‰“å°ç»“æœ
    print(f"\nğŸ“Š è‡ªé€‚åº”å¤„ç†éªŒè¯ç»“æœ:")
    validation_status = report["validation_status"]
    print(f"   å†…å­˜åˆ©ç”¨: {validation_status['memory_utilization']}")
    print(f"   è¾¹ç•Œå¤„ç†: {validation_status['boundary_artifacts']}")
    print(f"   å¤„ç†è´¨é‡: {validation_status['processing_quality']}")
    print(f"   æ€§èƒ½è¡¨ç°: {validation_status['performance']}")
    print(f"   æ•´ä½“çŠ¶æ€: {validation_status['overall_status']}")
    
    success = validation_status["overall_status"] == "éªŒè¯é€šè¿‡"
    
    if success:
        print(f"\nğŸ‰ ä»»åŠ¡10.2å®Œæˆ: è‡ªé€‚åº”å¤„ç†éªŒè¯å’Œä¼˜åŒ–")
        print(f"âœ… ç³»ç»Ÿé€šè¿‡æ‰€æœ‰éªŒè¯æµ‹è¯•ï¼Œæ€§èƒ½ä¼˜åŒ–å®Œæˆ!")
    else:
        print(f"\nâš ï¸ ä»»åŠ¡10.2éƒ¨åˆ†å®Œæˆï¼ŒæŸäº›æ–¹é¢éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–")
    
    return success

if __name__ == "__main__":
    main()