#!/usr/bin/env python3
"""
Theater Audio Enhancement System
ä¸“ä¸šè¯å‰§éŸ³é¢‘å¢å¼ºå¤„ç†å·¥å…·

åŠŸèƒ½åŒ…æ‹¬:
- æ™ºèƒ½é™å™ª
- é¢‘ç‡å‡è¡¡
- åŠ¨æ€èŒƒå›´æ§åˆ¶
- ç©ºé—´éŸ³æ•ˆä¼˜åŒ–
- éŸ³è§†é¢‘åŒæ­¥
"""

import os
import sys
import json
import subprocess
import logging
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
from datetime import datetime
import librosa
import soundfile as sf

class TheaterAudioEnhancer:
    def __init__(self, config_file="audio_config.json"):
        self.config = self.load_config(config_file)
        self.setup_logging()
        self.workspace = Path("audio_workspace")
        self.workspace.mkdir(exist_ok=True)
        
    def load_config(self, config_file):
        """åŠ è½½éŸ³é¢‘å¤„ç†é…ç½®"""
        default_config = {
            "noise_reduction": {
                "method": "spectral_subtraction",
                "strength": "medium",
                "noise_floor": -40
            },
            "equalizer": {
                "low_cut": {"freq": 100, "gain": -6},
                "speech_boost": {"freq_range": [300, 3000], "gain": 3},
                "clarity_boost": {"freq_range": [4000, 8000], "gain": 2},
                "high_cut": {"freq": 10000, "gain": -3}
            },
            "dynamics": {
                "compressor": {
                    "ratio": 4.0,
                    "threshold": -18,
                    "attack": 5,
                    "release": 100
                },
                "limiter": {
                    "threshold": -1,
                    "release": 50
                }
            },
            "spatial": {
                "reverb_time": 1.2,
                "stereo_width": 120,
                "room_size": "medium"
            }
        }
        
        if Path(config_file).exists():
            try:
                with open(config_file, 'r', encoding='utf-8') as f:
                    user_config = json.load(f)
                    default_config.update(user_config)
            except Exception as e:
                self.logger.warning(f"é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤é…ç½®: {e}")
        
        return default_config
    
    def setup_logging(self):
        """è®¾ç½®æ—¥å¿—ç³»ç»Ÿ"""
        log_file = f"audio_enhancement_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file, encoding='utf-8'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
    
    def run_ffmpeg(self, command, check=True):
        """æ‰§è¡ŒFFmpegå‘½ä»¤"""
        self.logger.info(f"æ‰§è¡ŒFFmpeg: {command}")
        try:
            result = subprocess.run(command, shell=True, check=check,
                                  capture_output=True, text=True)
            if result.stdout:
                self.logger.debug(f"è¾“å‡º: {result.stdout}")
            return result
        except subprocess.CalledProcessError as e:
            self.logger.error(f"FFmpegå‘½ä»¤å¤±è´¥: {e}")
            if e.stderr:
                self.logger.error(f"é”™è¯¯ä¿¡æ¯: {e.stderr}")
            raise
    
    def extract_audio(self, video_file):
        """ä»è§†é¢‘ä¸­æå–éŸ³é¢‘"""
        self.logger.info("ä»è§†é¢‘ä¸­æå–éŸ³é¢‘...")
        
        audio_file = self.workspace / "original_audio.wav"
        cmd = f'ffmpeg -i "{video_file}" -vn -acodec pcm_s16le -ar 48000 -ac 2 "{audio_file}" -y'
        
        self.run_ffmpeg(cmd)
        
        if audio_file.exists():
            self.logger.info(f"éŸ³é¢‘æå–æˆåŠŸ: {audio_file}")
            return str(audio_file)
        else:
            raise RuntimeError("éŸ³é¢‘æå–å¤±è´¥")
    
    def analyze_audio(self, audio_file):
        """åˆ†æéŸ³é¢‘ç‰¹å¾"""
        self.logger.info("åˆ†æéŸ³é¢‘ç‰¹å¾...")
        
        # ä½¿ç”¨librosaåŠ è½½éŸ³é¢‘
        y, sr = librosa.load(audio_file, sr=48000)
        
        # åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯
        duration = len(y) / sr
        rms_energy = np.sqrt(np.mean(y**2))
        peak_amplitude = np.max(np.abs(y))
        
        # é¢‘è°±åˆ†æ
        stft = librosa.stft(y)
        magnitude = np.abs(stft)
        
        # è®¡ç®—é¢‘è°±è´¨å¿ƒå’Œå¸¦å®½
        spectral_centroids = librosa.feature.spectral_centroid(y=y, sr=sr)[0]
        spectral_bandwidth = librosa.feature.spectral_bandwidth(y=y, sr=sr)[0]
        
        # åŠ¨æ€èŒƒå›´åˆ†æ
        dynamic_range = 20 * np.log10(peak_amplitude / (rms_energy + 1e-10))
        
        analysis_result = {
            "duration": duration,
            "sample_rate": sr,
            "rms_energy": float(rms_energy),
            "peak_amplitude": float(peak_amplitude),
            "dynamic_range_db": float(dynamic_range),
            "spectral_centroid_mean": float(np.mean(spectral_centroids)),
            "spectral_bandwidth_mean": float(np.mean(spectral_bandwidth))
        }
        
        # ä¿å­˜åˆ†æç»“æœ
        with open(self.workspace / "audio_analysis.json", 'w', encoding='utf-8') as f:
            json.dump(analysis_result, f, indent=2, ensure_ascii=False)
        
        # ç”Ÿæˆé¢‘è°±å›¾
        self.generate_spectrum_plot(y, sr, "original_spectrum.png")
        
        self.logger.info(f"éŸ³é¢‘åˆ†æå®Œæˆ: æ—¶é•¿{duration:.1f}ç§’, åŠ¨æ€èŒƒå›´{dynamic_range:.1f}dB")
        return analysis_result
    
    def generate_spectrum_plot(self, y, sr, filename):
        """ç”Ÿæˆé¢‘è°±åˆ†æå›¾"""
        plt.figure(figsize=(12, 8))
        
        # å­å›¾1: æ³¢å½¢å›¾
        plt.subplot(3, 1, 1)
        time = np.linspace(0, len(y)/sr, len(y))
        plt.plot(time[:sr*10], y[:sr*10])  # åªæ˜¾ç¤ºå‰10ç§’
        plt.title('éŸ³é¢‘æ³¢å½¢ (å‰10ç§’)')
        plt.xlabel('æ—¶é—´ (ç§’)')
        plt.ylabel('æŒ¯å¹…')
        
        # å­å›¾2: é¢‘è°±å›¾
        plt.subplot(3, 1, 2)
        D = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)
        librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='hz')
        plt.colorbar(format='%+2.0f dB')
        plt.title('é¢‘è°±å›¾')
        
        # å­å›¾3: é¢‘ç‡åˆ†å¸ƒ
        plt.subplot(3, 1, 3)
        fft = np.fft.fft(y[:sr*10])  # å‰10ç§’çš„FFT
        freqs = np.fft.fftfreq(len(fft), 1/sr)
        magnitude = np.abs(fft)
        
        # åªæ˜¾ç¤ºæ­£é¢‘ç‡éƒ¨åˆ†
        pos_freqs = freqs[:len(freqs)//2]
        pos_magnitude = magnitude[:len(magnitude)//2]
        
        plt.semilogx(pos_freqs[1:], 20*np.log10(pos_magnitude[1:] + 1e-10))
        plt.title('é¢‘ç‡å“åº”')
        plt.xlabel('é¢‘ç‡ (Hz)')
        plt.ylabel('å¹…åº¦ (dB)')
        plt.grid(True)
        
        plt.tight_layout()
        plt.savefig(self.workspace / filename, dpi=150, bbox_inches='tight')
        plt.close()
        
        self.logger.info(f"é¢‘è°±å›¾å·²ä¿å­˜: {filename}")
    
    def noise_reduction(self, audio_file):
        """æ™ºèƒ½é™å™ªå¤„ç†"""
        self.logger.info("å¼€å§‹é™å™ªå¤„ç†...")
        
        config = self.config["noise_reduction"]
        output_file = self.workspace / "denoised_audio.wav"
        
        # ä½¿ç”¨FFmpegçš„afftdnæ»¤é•œè¿›è¡Œé™å™ª
        noise_floor = config["noise_floor"]
        
        if config["strength"] == "light":
            nr_strength = 0.5
        elif config["strength"] == "medium":
            nr_strength = 1.0
        else:  # heavy
            nr_strength = 1.5
        
        # FFmpegé™å™ªå‘½ä»¤
        cmd = f'''ffmpeg -i "{audio_file}" -af "afftdn=nr={nr_strength}:nf={noise_floor}:tn=1" "{output_file}" -y'''
        
        self.run_ffmpeg(cmd)
        
        if output_file.exists():
            self.logger.info("é™å™ªå¤„ç†å®Œæˆ")
            return str(output_file)
        else:
            raise RuntimeError("é™å™ªå¤„ç†å¤±è´¥")
    
    def apply_equalizer(self, audio_file):
        """åº”ç”¨é¢‘ç‡å‡è¡¡"""
        self.logger.info("åº”ç”¨é¢‘ç‡å‡è¡¡...")
        
        config = self.config["equalizer"]
        output_file = self.workspace / "equalized_audio.wav"
        
        # æ„å»ºEQæ»¤é•œé“¾
        eq_filters = []
        
        # ä½é¢‘è¡°å‡
        low_cut = config["low_cut"]
        eq_filters.append(f"highpass=f={low_cut['freq']}:p=1")
        
        # äººå£°å¢å¼º (ä½¿ç”¨peaking EQ)
        speech = config["speech_boost"]
        center_freq = (speech["freq_range"][0] + speech["freq_range"][1]) // 2
        eq_filters.append(f"equalizer=f={center_freq}:width_type=h:width=1000:g={speech['gain']}")
        
        # æ¸…æ™°åº¦æå‡
        clarity = config["clarity_boost"]
        center_freq = (clarity["freq_range"][0] + clarity["freq_range"][1]) // 2
        eq_filters.append(f"equalizer=f={center_freq}:width_type=h:width=2000:g={clarity['gain']}")
        
        # é«˜é¢‘æ§åˆ¶
        high_cut = config["high_cut"]
        eq_filters.append(f"lowpass=f={high_cut['freq']}:p=1")
        
        # ç»„åˆæ‰€æœ‰æ»¤é•œ
        filter_chain = ",".join(eq_filters)
        cmd = f'ffmpeg -i "{audio_file}" -af "{filter_chain}" "{output_file}" -y'
        
        self.run_ffmpeg(cmd)
        
        if output_file.exists():
            self.logger.info("é¢‘ç‡å‡è¡¡å®Œæˆ")
            return str(output_file)
        else:
            raise RuntimeError("é¢‘ç‡å‡è¡¡å¤±è´¥")
    
    def apply_dynamics_processing(self, audio_file):
        """åº”ç”¨åŠ¨æ€èŒƒå›´æ§åˆ¶"""
        self.logger.info("åº”ç”¨åŠ¨æ€èŒƒå›´æ§åˆ¶...")
        
        config = self.config["dynamics"]
        output_file = self.workspace / "compressed_audio.wav"
        
        # å‹ç¼©å™¨å‚æ•°
        comp = config["compressor"]
        limiter = config["limiter"]
        
        # æ„å»ºåŠ¨æ€å¤„ç†æ»¤é•œé“¾
        filters = []
        
        # å‹ç¼©å™¨
        comp_filter = f"acompressor=threshold={comp['threshold']}dB:ratio={comp['ratio']}:attack={comp['attack']}:release={comp['release']}"
        filters.append(comp_filter)
        
        # é™å¹…å™¨
        limiter_filter = f"alimiter=level_in=1:level_out=0.9:limit={limiter['threshold']}:release={limiter['release']}"
        filters.append(limiter_filter)
        
        filter_chain = ",".join(filters)
        cmd = f'ffmpeg -i "{audio_file}" -af "{filter_chain}" "{output_file}" -y'
        
        self.run_ffmpeg(cmd)
        
        if output_file.exists():
            self.logger.info("åŠ¨æ€èŒƒå›´æ§åˆ¶å®Œæˆ")
            return str(output_file)
        else:
            raise RuntimeError("åŠ¨æ€èŒƒå›´æ§åˆ¶å¤±è´¥")
    
    def apply_spatial_enhancement(self, audio_file):
        """åº”ç”¨ç©ºé—´éŸ³æ•ˆä¼˜åŒ–"""
        self.logger.info("åº”ç”¨ç©ºé—´éŸ³æ•ˆä¼˜åŒ–...")
        
        config = self.config["spatial"]
        output_file = self.workspace / "spatial_enhanced_audio.wav"
        
        filters = []
        
        # ç«‹ä½“å£°å®½åº¦è°ƒæ•´
        stereo_width = config["stereo_width"] / 100.0
        filters.append(f"extrastereo=m={stereo_width}")
        
        # ç®€å•æ··å“ (ä½¿ç”¨aechoæ¨¡æ‹Ÿ)
        reverb_time = config["reverb_time"]
        delay_ms = int(reverb_time * 100)  # è½¬æ¢ä¸ºæ¯«ç§’
        filters.append(f"aecho=0.8:0.88:{delay_ms}:0.4")
        
        filter_chain = ",".join(filters)
        cmd = f'ffmpeg -i "{audio_file}" -af "{filter_chain}" "{output_file}" -y'
        
        self.run_ffmpeg(cmd)
        
        if output_file.exists():
            self.logger.info("ç©ºé—´éŸ³æ•ˆä¼˜åŒ–å®Œæˆ")
            return str(output_file)
        else:
            raise RuntimeError("ç©ºé—´éŸ³æ•ˆä¼˜åŒ–å¤±è´¥")
    
    def merge_with_video(self, enhanced_audio, original_video, output_video):
        """å°†å¢å¼ºéŸ³é¢‘ä¸åŸè§†é¢‘åˆå¹¶"""
        self.logger.info("åˆå¹¶å¢å¼ºéŸ³é¢‘ä¸è§†é¢‘...")
        
        # ä½¿ç”¨é«˜è´¨é‡ç¼–ç å‚æ•°
        cmd = f'''ffmpeg -i "{original_video}" -i "{enhanced_audio}" -c:v copy -c:a aac -b:a 192k -ar 48000 -ac 2 -map 0:v:0 -map 1:a:0 -shortest "{output_video}" -y'''
        
        self.run_ffmpeg(cmd)
        
        if Path(output_video).exists():
            file_size = Path(output_video).stat().st_size / (1024*1024)
            self.logger.info(f"éŸ³è§†é¢‘åˆå¹¶å®Œæˆ: {output_video} ({file_size:.1f} MB)")
            return True
        else:
            raise RuntimeError("éŸ³è§†é¢‘åˆå¹¶å¤±è´¥")
    
    def generate_comparison_report(self, original_audio, enhanced_audio):
        """ç”Ÿæˆå¤„ç†å‰åå¯¹æ¯”æŠ¥å‘Š"""
        self.logger.info("ç”Ÿæˆå¯¹æ¯”åˆ†ææŠ¥å‘Š...")
        
        # åˆ†æåŸå§‹éŸ³é¢‘
        y_orig, sr = librosa.load(original_audio, sr=48000)
        
        # åˆ†æå¢å¼ºéŸ³é¢‘
        y_enh, _ = librosa.load(enhanced_audio, sr=48000)
        
        # ç¡®ä¿é•¿åº¦ä¸€è‡´
        min_len = min(len(y_orig), len(y_enh))
        y_orig = y_orig[:min_len]
        y_enh = y_enh[:min_len]
        
        # è®¡ç®—å¯¹æ¯”æŒ‡æ ‡
        rms_orig = np.sqrt(np.mean(y_orig**2))
        rms_enh = np.sqrt(np.mean(y_enh**2))
        
        peak_orig = np.max(np.abs(y_orig))
        peak_enh = np.max(np.abs(y_enh))
        
        # ä¿¡å™ªæ¯”ä¼°ç®— (ç®€åŒ–è®¡ç®—)
        noise_floor_orig = np.percentile(np.abs(y_orig), 10)
        noise_floor_enh = np.percentile(np.abs(y_enh), 10)
        
        snr_orig = 20 * np.log10(rms_orig / (noise_floor_orig + 1e-10))
        snr_enh = 20 * np.log10(rms_enh / (noise_floor_enh + 1e-10))
        
        comparison_data = {
            "original": {
                "rms_level": float(rms_orig),
                "peak_level": float(peak_orig),
                "estimated_snr_db": float(snr_orig),
                "dynamic_range_db": float(20 * np.log10(peak_orig / (rms_orig + 1e-10)))
            },
            "enhanced": {
                "rms_level": float(rms_enh),
                "peak_level": float(peak_enh),
                "estimated_snr_db": float(snr_enh),
                "dynamic_range_db": float(20 * np.log10(peak_enh / (rms_enh + 1e-10)))
            },
            "improvements": {
                "snr_improvement_db": float(snr_enh - snr_orig),
                "noise_reduction_db": float(20 * np.log10(noise_floor_orig / (noise_floor_enh + 1e-10))),
                "rms_change_db": float(20 * np.log10(rms_enh / (rms_orig + 1e-10)))
            }
        }
        
        # ä¿å­˜å¯¹æ¯”æŠ¥å‘Š
        with open(self.workspace / "audio_comparison_report.json", 'w', encoding='utf-8') as f:
            json.dump(comparison_data, f, indent=2, ensure_ascii=False)
        
        # ç”Ÿæˆå¯¹æ¯”é¢‘è°±å›¾
        self.generate_comparison_plot(y_orig, y_enh, sr)
        
        self.logger.info(f"éŸ³é¢‘å¢å¼ºæ•ˆæœ: SNRæå‡{comparison_data['improvements']['snr_improvement_db']:.1f}dB")
        return comparison_data
    
    def generate_detailed_analysis_report(self, audio_file, basic_analysis):
        """ç”Ÿæˆè¯¦ç»†çš„éŸ³é¢‘è´¨é‡åˆ†ææŠ¥å‘Š - Task 7.1"""
        self.logger.info("ç”Ÿæˆè¯¦ç»†éŸ³é¢‘è´¨é‡åˆ†ææŠ¥å‘Š...")
        
        # åŠ è½½éŸ³é¢‘æ•°æ®
        y, sr = librosa.load(audio_file, sr=48000)
        duration = len(y) / sr
        
        # 1. åŸºæœ¬éŸ³é¢‘ç‰¹å¾åˆ†æ
        rms_energy = np.sqrt(np.mean(y**2))
        peak_amplitude = np.max(np.abs(y))
        zero_crossing_rate = np.mean(librosa.feature.zero_crossing_rate(y)[0])
        
        # 2. é¢‘è°±ç‰¹å¾åˆ†æ
        spectral_centroids = librosa.feature.spectral_centroid(y=y, sr=sr)[0]
        spectral_bandwidth = librosa.feature.spectral_bandwidth(y=y, sr=sr)[0]
        spectral_rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)[0]
        spectral_contrast = librosa.feature.spectral_contrast(y=y, sr=sr)
        
        # 3. å™ªéŸ³åˆ†æ
        # ä½¿ç”¨é™éŸ³æ®µä¼°ç®—å™ªéŸ³åº•å™ª
        silence_threshold = np.percentile(np.abs(y), 20)  # 20%åˆ†ä½æ•°ä½œä¸ºé™éŸ³é˜ˆå€¼
        silence_mask = np.abs(y) < silence_threshold
        noise_floor = np.mean(np.abs(y[silence_mask])) if np.any(silence_mask) else silence_threshold
        
        # ä¼°ç®—ä¿¡å™ªæ¯”
        signal_power = rms_energy**2
        noise_power = noise_floor**2
        snr_estimate = 10 * np.log10(signal_power / (noise_power + 1e-10))
        
        # 4. åŠ¨æ€èŒƒå›´åˆ†æ
        # è®¡ç®—ä¸åŒç™¾åˆ†ä½æ•°çš„éŸ³é‡åˆ†å¸ƒ
        volume_percentiles = {
            "10th": np.percentile(np.abs(y), 10),
            "25th": np.percentile(np.abs(y), 25),
            "50th": np.percentile(np.abs(y), 50),
            "75th": np.percentile(np.abs(y), 75),
            "90th": np.percentile(np.abs(y), 90),
            "95th": np.percentile(np.abs(y), 95),
            "99th": np.percentile(np.abs(y), 99)
        }
        
        # è®¡ç®—å³°å€¼å› å­ (Crest Factor)
        crest_factor = 20 * np.log10(peak_amplitude / (rms_energy + 1e-10))
        
        # 5. è¯å‰§ç‰¹æœ‰éŸ³é¢‘ç‰¹å¾åˆ†æ
        # æ£€æµ‹è¯­éŸ³æ´»åŠ¨æ®µ
        # ä½¿ç”¨èƒ½é‡å’Œè¿‡é›¶ç‡æ£€æµ‹è¯­éŸ³æ®µ
        frame_length = 2048
        hop_length = 512
        
        # è®¡ç®—çŸ­æ—¶èƒ½é‡
        frames = librosa.util.frame(y, frame_length=frame_length, hop_length=hop_length)
        frame_energy = np.sum(frames**2, axis=0)
        
        # è¯­éŸ³æ´»åŠ¨æ£€æµ‹ (ç®€åŒ–ç‰ˆVAD)
        energy_threshold = np.percentile(frame_energy, 60)  # 60%åˆ†ä½æ•°ä½œä¸ºè¯­éŸ³é˜ˆå€¼
        speech_frames = frame_energy > energy_threshold
        speech_ratio = np.sum(speech_frames) / len(speech_frames)
        
        # 6. é¢‘ç‡åˆ†å¸ƒåˆ†æ
        # è®¡ç®—ä¸åŒé¢‘æ®µçš„èƒ½é‡åˆ†å¸ƒ
        stft = librosa.stft(y, hop_length=hop_length)
        magnitude = np.abs(stft)
        freqs = librosa.fft_frequencies(sr=sr)
        
        # å®šä¹‰é¢‘æ®µ
        freq_bands = {
            "sub_bass": (20, 60),      # è¶…ä½é¢‘
            "bass": (60, 250),         # ä½é¢‘
            "low_mid": (250, 500),     # ä¸­ä½é¢‘
            "mid": (500, 2000),        # ä¸­é¢‘
            "high_mid": (2000, 4000),  # ä¸­é«˜é¢‘ (äººå£°å…³é”®åŒºåŸŸ)
            "presence": (4000, 6000),  # å­˜åœ¨æ„Ÿé¢‘æ®µ
            "brilliance": (6000, 20000) # é«˜é¢‘
        }
        
        freq_energy = {}
        for band_name, (low_freq, high_freq) in freq_bands.items():
            band_indices = np.where((freqs >= low_freq) & (freqs <= high_freq))[0]
            if len(band_indices) > 0:
                band_energy = np.mean(magnitude[band_indices, :])
                freq_energy[band_name] = float(band_energy)
            else:
                freq_energy[band_name] = 0.0
        
        # 7. ç«‹ä½“å£°åˆ†æ (å¦‚æœæ˜¯ç«‹ä½“å£°)
        stereo_analysis = {}
        if len(y.shape) > 1 or audio_file.endswith('.wav'):
            # é‡æ–°åŠ è½½ä¸ºç«‹ä½“å£°
            y_stereo, _ = librosa.load(audio_file, sr=48000, mono=False)
            if len(y_stereo.shape) > 1:
                left_channel = y_stereo[0]
                right_channel = y_stereo[1]
                
                # è®¡ç®—ç«‹ä½“å£°ç›¸å…³æ€§
                correlation = np.corrcoef(left_channel, right_channel)[0, 1]
                
                # è®¡ç®—å·¦å³å£°é“èƒ½é‡å·®å¼‚
                left_rms = np.sqrt(np.mean(left_channel**2))
                right_rms = np.sqrt(np.mean(right_channel**2))
                channel_balance = 20 * np.log10((left_rms + 1e-10) / (right_rms + 1e-10))
                
                stereo_analysis = {
                    "correlation": float(correlation),
                    "channel_balance_db": float(channel_balance),
                    "left_rms": float(left_rms),
                    "right_rms": float(right_rms),
                    "stereo_width": float(1.0 - abs(correlation))  # ç«‹ä½“å£°å®½åº¦ä¼°ç®—
                }
        
        # 8. è¯å‰§éŸ³é¢‘è´¨é‡è¯„ä¼°
        theater_quality_assessment = {
            "dialogue_clarity": "good" if freq_energy.get("high_mid", 0) > freq_energy.get("bass", 0) else "needs_improvement",
            "background_noise_level": "low" if snr_estimate > 20 else "moderate" if snr_estimate > 10 else "high",
            "dynamic_range_type": "wide" if crest_factor > 15 else "moderate" if crest_factor > 10 else "compressed",
            "speech_activity_ratio": float(speech_ratio),
            "overall_quality": "excellent" if snr_estimate > 25 and crest_factor > 15 else 
                             "good" if snr_estimate > 15 and crest_factor > 10 else
                             "fair" if snr_estimate > 10 else "poor"
        }
        
        # 9. å¤„ç†å»ºè®®
        processing_recommendations = {
            "noise_reduction": "heavy" if snr_estimate < 10 else "medium" if snr_estimate < 20 else "light",
            "eq_adjustments": {
                "bass_cut": freq_energy.get("bass", 0) > freq_energy.get("mid", 0),
                "speech_boost": freq_energy.get("high_mid", 0) < freq_energy.get("mid", 0),
                "presence_boost": freq_energy.get("presence", 0) < freq_energy.get("high_mid", 0)
            },
            "dynamics_processing": {
                "compression_needed": crest_factor > 20,
                "limiting_needed": peak_amplitude > 0.9
            },
            "spatial_enhancement": len(stereo_analysis) > 0 and stereo_analysis.get("correlation", 1.0) > 0.9
        }
        
        # 10. æ±‡æ€»åˆ†æç»“æœ
        detailed_analysis = {
            "file_info": {
                "duration_seconds": float(duration),
                "sample_rate": int(sr),
                "channels": 2 if len(stereo_analysis) > 0 else 1,
                "file_path": audio_file
            },
            "basic_metrics": {
                "rms_energy": float(rms_energy),
                "peak_amplitude": float(peak_amplitude),
                "dynamic_range_db": float(crest_factor),
                "zero_crossing_rate": float(zero_crossing_rate),
                "estimated_snr_db": float(snr_estimate)
            },
            "spectral_features": {
                "spectral_centroid_mean": float(np.mean(spectral_centroids)),
                "spectral_bandwidth_mean": float(np.mean(spectral_bandwidth)),
                "spectral_rolloff_mean": float(np.mean(spectral_rolloff)),
                "spectral_contrast_mean": float(np.mean(spectral_contrast))
            },
            "noise_analysis": {
                "noise_floor": float(noise_floor),
                "silence_ratio": float(np.sum(silence_mask) / len(silence_mask)),
                "snr_estimate_db": float(snr_estimate)
            },
            "volume_distribution": {k: float(v) for k, v in volume_percentiles.items()},
            "frequency_energy_distribution": freq_energy,
            "stereo_analysis": stereo_analysis,
            "theater_specific": {
                "speech_activity_ratio": float(speech_ratio),
                "dialogue_prominence": float(freq_energy.get("high_mid", 0) / (freq_energy.get("bass", 1) + 1e-10)),
                "ambient_noise_level": float(noise_floor),
                "stage_acoustics_estimate": float(np.mean(spectral_rolloff) / sr * 100)  # ç®€åŒ–çš„å£°å­¦ç‰¹å¾
            },
            "quality_assessment": theater_quality_assessment,
            "processing_recommendations": processing_recommendations,
            "analysis_timestamp": datetime.now().isoformat()
        }
        
        # ä¿å­˜è¯¦ç»†åˆ†ææŠ¥å‘Š
        report_file = self.workspace / "detailed_audio_analysis_report.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(detailed_analysis, f, indent=2, ensure_ascii=False)
        
        # ç”Ÿæˆå¯è§†åŒ–åˆ†æå›¾è¡¨
        self.generate_comprehensive_analysis_plots(y, sr, detailed_analysis)
        
        # ç”ŸæˆMarkdownæ ¼å¼çš„åˆ†ææŠ¥å‘Š
        self.generate_markdown_analysis_report(detailed_analysis)
        
        self.logger.info(f"è¯¦ç»†éŸ³é¢‘åˆ†æå®Œæˆ:")
        self.logger.info(f"  - æ—¶é•¿: {duration:.1f}ç§’")
        self.logger.info(f"  - ä¼°ç®—SNR: {snr_estimate:.1f}dB")
        self.logger.info(f"  - åŠ¨æ€èŒƒå›´: {crest_factor:.1f}dB")
        self.logger.info(f"  - è¯­éŸ³æ´»åŠ¨æ¯”ä¾‹: {speech_ratio:.1%}")
        self.logger.info(f"  - æ•´ä½“è´¨é‡è¯„ä¼°: {theater_quality_assessment['overall_quality']}")
        self.logger.info(f"  - æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
        
        return detailed_analysis

    def generate_comprehensive_analysis_plots(self, y, sr, analysis_data):
        """ç”Ÿæˆç»¼åˆéŸ³é¢‘åˆ†æå›¾è¡¨"""
        plt.style.use('default')
        fig = plt.figure(figsize=(16, 12))
        
        # 1. æ³¢å½¢å›¾
        plt.subplot(3, 3, 1)
        time = np.linspace(0, len(y)/sr, len(y))
        plt.plot(time[:sr*30], y[:sr*30])  # æ˜¾ç¤ºå‰30ç§’
        plt.title('éŸ³é¢‘æ³¢å½¢ (å‰30ç§’)')
        plt.xlabel('æ—¶é—´ (ç§’)')
        plt.ylabel('æŒ¯å¹…')
        plt.grid(True, alpha=0.3)
        
        # 2. é¢‘è°±å›¾
        plt.subplot(3, 3, 2)
        D = librosa.amplitude_to_db(np.abs(librosa.stft(y[:sr*60])), ref=np.max)  # å‰60ç§’
        librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='hz', cmap='viridis')
        plt.colorbar(format='%+2.0f dB')
        plt.title('é¢‘è°±å›¾ (å‰60ç§’)')
        
        # 3. é¢‘ç‡å“åº”
        plt.subplot(3, 3, 3)
        fft = np.fft.fft(y[:sr*10])  # å‰10ç§’çš„FFT
        freqs = np.fft.fftfreq(len(fft), 1/sr)
        magnitude = np.abs(fft)
        pos_freqs = freqs[:len(freqs)//2]
        pos_magnitude = magnitude[:len(magnitude)//2]
        
        plt.semilogx(pos_freqs[1:], 20*np.log10(pos_magnitude[1:] + 1e-10))
        plt.title('é¢‘ç‡å“åº”')
        plt.xlabel('é¢‘ç‡ (Hz)')
        plt.ylabel('å¹…åº¦ (dB)')
        plt.grid(True, alpha=0.3)
        
        # 4. é¢‘æ®µèƒ½é‡åˆ†å¸ƒ
        plt.subplot(3, 3, 4)
        freq_bands = analysis_data['frequency_energy_distribution']
        bands = list(freq_bands.keys())
        energies = list(freq_bands.values())
        
        plt.bar(bands, energies, color='skyblue', alpha=0.7)
        plt.title('é¢‘æ®µèƒ½é‡åˆ†å¸ƒ')
        plt.xlabel('é¢‘æ®µ')
        plt.ylabel('èƒ½é‡')
        plt.xticks(rotation=45)
        plt.grid(True, alpha=0.3)
        
        # 5. éŸ³é‡åˆ†å¸ƒç›´æ–¹å›¾
        plt.subplot(3, 3, 5)
        plt.hist(np.abs(y), bins=50, alpha=0.7, color='green', density=True)
        plt.title('éŸ³é‡åˆ†å¸ƒ')
        plt.xlabel('æŒ¯å¹…')
        plt.ylabel('æ¦‚ç‡å¯†åº¦')
        plt.yscale('log')
        plt.grid(True, alpha=0.3)
        
        # 6. åŠ¨æ€èŒƒå›´å¯è§†åŒ–
        plt.subplot(3, 3, 6)
        volume_percentiles = analysis_data['volume_distribution']
        percentiles = list(volume_percentiles.keys())
        values = list(volume_percentiles.values())
        
        plt.plot(percentiles, values, 'o-', color='red', linewidth=2, markersize=6)
        plt.title('éŸ³é‡ç™¾åˆ†ä½æ•°åˆ†å¸ƒ')
        plt.xlabel('ç™¾åˆ†ä½æ•°')
        plt.ylabel('æŒ¯å¹…')
        plt.yscale('log')
        plt.grid(True, alpha=0.3)
        
        # 7. è¯­éŸ³æ´»åŠ¨æ£€æµ‹
        plt.subplot(3, 3, 7)
        frame_length = 2048
        hop_length = 512
        frames = librosa.util.frame(y, frame_length=frame_length, hop_length=hop_length)
        frame_energy = np.sum(frames**2, axis=0)
        frame_times = librosa.frames_to_time(np.arange(len(frame_energy)), sr=sr, hop_length=hop_length)
        
        energy_threshold = np.percentile(frame_energy, 60)
        
        plt.plot(frame_times[:min(len(frame_times), sr//hop_length*60)], 
                frame_energy[:min(len(frame_energy), sr//hop_length*60)], 
                alpha=0.7, label='å¸§èƒ½é‡')
        plt.axhline(y=energy_threshold, color='red', linestyle='--', label='è¯­éŸ³é˜ˆå€¼')
        plt.title('è¯­éŸ³æ´»åŠ¨æ£€æµ‹ (å‰60ç§’)')
        plt.xlabel('æ—¶é—´ (ç§’)')
        plt.ylabel('èƒ½é‡')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # 8. ç«‹ä½“å£°åˆ†æ (å¦‚æœæœ‰)
        plt.subplot(3, 3, 8)
        if analysis_data['stereo_analysis']:
            stereo = analysis_data['stereo_analysis']
            metrics = ['ç›¸å…³æ€§', 'å£°é“å¹³è¡¡', 'ç«‹ä½“å£°å®½åº¦']
            values = [stereo['correlation'], 
                     abs(stereo['channel_balance_db'])/20,  # å½’ä¸€åŒ–åˆ°0-1
                     stereo['stereo_width']]
            
            plt.bar(metrics, values, color=['blue', 'orange', 'green'], alpha=0.7)
            plt.title('ç«‹ä½“å£°ç‰¹å¾')
            plt.ylabel('å½’ä¸€åŒ–å€¼')
            plt.ylim(0, 1)
        else:
            plt.text(0.5, 0.5, 'å•å£°é“éŸ³é¢‘', ha='center', va='center', transform=plt.gca().transAxes)
            plt.title('ç«‹ä½“å£°åˆ†æ')
        plt.grid(True, alpha=0.3)
        
        # 9. è´¨é‡è¯„ä¼°é›·è¾¾å›¾
        plt.subplot(3, 3, 9, projection='polar')
        
        # è´¨é‡æŒ‡æ ‡ (è½¬æ¢ä¸º0-1èŒƒå›´)
        snr_score = min(analysis_data['basic_metrics']['estimated_snr_db'] / 30, 1.0)
        dynamic_score = min(analysis_data['basic_metrics']['dynamic_range_db'] / 25, 1.0)
        speech_score = analysis_data['theater_specific']['speech_activity_ratio']
        dialogue_score = min(analysis_data['theater_specific']['dialogue_prominence'] / 2, 1.0)
        
        categories = ['SNR', 'åŠ¨æ€èŒƒå›´', 'è¯­éŸ³æ´»åŠ¨', 'å¯¹è¯çªå‡ºåº¦']
        values = [snr_score, dynamic_score, speech_score, dialogue_score]
        
        # é—­åˆé›·è¾¾å›¾
        angles = np.linspace(0, 2*np.pi, len(categories), endpoint=False).tolist()
        values += values[:1]
        angles += angles[:1]
        
        plt.plot(angles, values, 'o-', linewidth=2, color='purple')
        plt.fill(angles, values, alpha=0.25, color='purple')
        plt.xticks(angles[:-1], categories)
        plt.ylim(0, 1)
        plt.title('éŸ³é¢‘è´¨é‡è¯„ä¼°')
        
        plt.tight_layout()
        plt.savefig(self.workspace / "comprehensive_audio_analysis.png", dpi=150, bbox_inches='tight')
        plt.close()
        
        self.logger.info("ç»¼åˆéŸ³é¢‘åˆ†æå›¾è¡¨å·²ç”Ÿæˆ")

    def generate_markdown_analysis_report(self, analysis_data):
        """ç”ŸæˆMarkdownæ ¼å¼çš„åˆ†ææŠ¥å‘Š"""
        report_content = f"""# è¯å‰§éŸ³é¢‘è´¨é‡åˆ†ææŠ¥å‘Š

## åŸºæœ¬ä¿¡æ¯
- **æ–‡ä»¶è·¯å¾„**: {analysis_data['file_info']['file_path']}
- **æ—¶é•¿**: {analysis_data['file_info']['duration_seconds']:.1f} ç§’ ({analysis_data['file_info']['duration_seconds']/60:.1f} åˆ†é’Ÿ)
- **é‡‡æ ·ç‡**: {analysis_data['file_info']['sample_rate']} Hz
- **å£°é“æ•°**: {analysis_data['file_info']['channels']}
- **åˆ†ææ—¶é—´**: {analysis_data['analysis_timestamp']}

## éŸ³é¢‘è´¨é‡è¯„ä¼°

### æ•´ä½“è´¨é‡: **{analysis_data['quality_assessment']['overall_quality'].upper()}**

### å…³é”®æŒ‡æ ‡
| æŒ‡æ ‡ | æ•°å€¼ | è¯„ä¼° |
|------|------|------|
| ä¼°ç®—ä¿¡å™ªæ¯” | {analysis_data['basic_metrics']['estimated_snr_db']:.1f} dB | {analysis_data['quality_assessment']['background_noise_level']} |
| åŠ¨æ€èŒƒå›´ | {analysis_data['basic_metrics']['dynamic_range_db']:.1f} dB | {analysis_data['quality_assessment']['dynamic_range_type']} |
| è¯­éŸ³æ´»åŠ¨æ¯”ä¾‹ | {analysis_data['theater_specific']['speech_activity_ratio']:.1%} | - |
| å¯¹è¯æ¸…æ™°åº¦ | - | {analysis_data['quality_assessment']['dialogue_clarity']} |

## è¯¦ç»†åˆ†æç»“æœ

### 1. åŸºç¡€éŸ³é¢‘ç‰¹å¾
- **RMSèƒ½é‡**: {analysis_data['basic_metrics']['rms_energy']:.4f}
- **å³°å€¼æŒ¯å¹…**: {analysis_data['basic_metrics']['peak_amplitude']:.4f}
- **è¿‡é›¶ç‡**: {analysis_data['basic_metrics']['zero_crossing_rate']:.4f}

### 2. é¢‘è°±ç‰¹å¾
- **é¢‘è°±è´¨å¿ƒå‡å€¼**: {analysis_data['spectral_features']['spectral_centroid_mean']:.1f} Hz
- **é¢‘è°±å¸¦å®½å‡å€¼**: {analysis_data['spectral_features']['spectral_bandwidth_mean']:.1f} Hz
- **é¢‘è°±æ»šé™å‡å€¼**: {analysis_data['spectral_features']['spectral_rolloff_mean']:.1f} Hz

### 3. å™ªéŸ³åˆ†æ
- **å™ªéŸ³åº•å™ª**: {analysis_data['noise_analysis']['noise_floor']:.6f}
- **é™éŸ³æ¯”ä¾‹**: {analysis_data['noise_analysis']['silence_ratio']:.1%}
- **ä¼°ç®—SNR**: {analysis_data['noise_analysis']['snr_estimate_db']:.1f} dB

### 4. é¢‘æ®µèƒ½é‡åˆ†å¸ƒ
"""
        
        for band, energy in analysis_data['frequency_energy_distribution'].items():
            report_content += f"- **{band}**: {energy:.4f}\n"
        
        if analysis_data['stereo_analysis']:
            report_content += f"""
### 5. ç«‹ä½“å£°åˆ†æ
- **å£°é“ç›¸å…³æ€§**: {analysis_data['stereo_analysis']['correlation']:.3f}
- **å£°é“å¹³è¡¡**: {analysis_data['stereo_analysis']['channel_balance_db']:.1f} dB
- **ç«‹ä½“å£°å®½åº¦**: {analysis_data['stereo_analysis']['stereo_width']:.3f}
"""
        
        report_content += f"""
### 6. è¯å‰§ç‰¹æœ‰ç‰¹å¾
- **è¯­éŸ³æ´»åŠ¨æ¯”ä¾‹**: {analysis_data['theater_specific']['speech_activity_ratio']:.1%}
- **å¯¹è¯çªå‡ºåº¦**: {analysis_data['theater_specific']['dialogue_prominence']:.2f}
- **ç¯å¢ƒå™ªéŸ³æ°´å¹³**: {analysis_data['theater_specific']['ambient_noise_level']:.6f}
- **èˆå°å£°å­¦ä¼°ç®—**: {analysis_data['theater_specific']['stage_acoustics_estimate']:.2f}

## å¤„ç†å»ºè®®

### é™å™ªå¤„ç†
- **æ¨èå¼ºåº¦**: {analysis_data['processing_recommendations']['noise_reduction']}

### å‡è¡¡å™¨è°ƒæ•´
"""
        
        eq_adj = analysis_data['processing_recommendations']['eq_adjustments']
        if eq_adj['bass_cut']:
            report_content += "- âœ… å»ºè®®è¿›è¡Œä½é¢‘è¡°å‡\n"
        if eq_adj['speech_boost']:
            report_content += "- âœ… å»ºè®®å¢å¼ºäººå£°é¢‘æ®µ\n"
        if eq_adj['presence_boost']:
            report_content += "- âœ… å»ºè®®æå‡å­˜åœ¨æ„Ÿé¢‘æ®µ\n"
        
        dynamics = analysis_data['processing_recommendations']['dynamics_processing']
        report_content += f"""
### åŠ¨æ€å¤„ç†
- **éœ€è¦å‹ç¼©**: {'æ˜¯' if dynamics['compression_needed'] else 'å¦'}
- **éœ€è¦é™å¹…**: {'æ˜¯' if dynamics['limiting_needed'] else 'å¦'}

### ç©ºé—´å¢å¼º
- **éœ€è¦ç«‹ä½“å£°å¢å¼º**: {'æ˜¯' if analysis_data['processing_recommendations']['spatial_enhancement'] else 'å¦'}

## éŸ³é‡åˆ†å¸ƒç»Ÿè®¡
"""
        
        for percentile, value in analysis_data['volume_distribution'].items():
            report_content += f"- **{percentile}**: {value:.6f}\n"
        
        report_content += """
## ç»“è®ºä¸å»ºè®®

åŸºäºä»¥ä¸Šåˆ†æï¼Œè¯¥è¯å‰§éŸ³é¢‘æ–‡ä»¶çš„ä¸»è¦ç‰¹ç‚¹å’Œå»ºè®®å¤„ç†æ–¹æ¡ˆå¦‚ä¸‹ï¼š

1. **éŸ³é¢‘è´¨é‡**: æ•´ä½“è´¨é‡è¯„ä¼°ä¸º **{overall_quality}**
2. **ä¸»è¦é—®é¢˜**: {main_issues}
3. **ä¼˜å…ˆå¤„ç†**: {priority_processing}
4. **é¢„æœŸæ”¹å–„**: é€šè¿‡å»ºè®®çš„å¤„ç†æµç¨‹ï¼Œé¢„è®¡å¯ä»¥æ˜¾è‘—æå‡éŸ³é¢‘è´¨é‡

---
*æœ¬æŠ¥å‘Šç”±è¯å‰§éŸ³é¢‘å¢å¼ºç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆ*
""".format(
            overall_quality=analysis_data['quality_assessment']['overall_quality'],
            main_issues="èƒŒæ™¯å™ªéŸ³" if analysis_data['basic_metrics']['estimated_snr_db'] < 15 else "åŠ¨æ€èŒƒå›´æ§åˆ¶",
            priority_processing="é™å™ªå’Œå‡è¡¡å¤„ç†" if analysis_data['basic_metrics']['estimated_snr_db'] < 15 else "åŠ¨æ€èŒƒå›´ä¼˜åŒ–"
        )
        
        # ä¿å­˜MarkdownæŠ¥å‘Š
        report_file = self.workspace / "audio_quality_assessment_report.md"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        self.logger.info(f"Markdownåˆ†ææŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")

    def generate_comparison_plot(self, y_orig, y_enh, sr):
        plt.figure(figsize=(15, 10))
        
        # åŸå§‹éŸ³é¢‘é¢‘è°±
        plt.subplot(2, 2, 1)
        D_orig = librosa.amplitude_to_db(np.abs(librosa.stft(y_orig[:sr*30])), ref=np.max)
        librosa.display.specshow(D_orig, sr=sr, x_axis='time', y_axis='hz')
        plt.colorbar(format='%+2.0f dB')
        plt.title('åŸå§‹éŸ³é¢‘é¢‘è°± (å‰30ç§’)')
        
        # å¢å¼ºéŸ³é¢‘é¢‘è°±
        plt.subplot(2, 2, 2)
        D_enh = librosa.amplitude_to_db(np.abs(librosa.stft(y_enh[:sr*30])), ref=np.max)
        librosa.display.specshow(D_enh, sr=sr, x_axis='time', y_axis='hz')
        plt.colorbar(format='%+2.0f dB')
        plt.title('å¢å¼ºéŸ³é¢‘é¢‘è°± (å‰30ç§’)')
        
        # é¢‘ç‡å“åº”å¯¹æ¯”
        plt.subplot(2, 1, 2)
        
        # è®¡ç®—å¹³å‡é¢‘è°±
        fft_orig = np.fft.fft(y_orig[:sr*10])
        fft_enh = np.fft.fft(y_enh[:sr*10])
        
        freqs = np.fft.fftfreq(len(fft_orig), 1/sr)
        pos_freqs = freqs[:len(freqs)//2]
        
        mag_orig = np.abs(fft_orig[:len(fft_orig)//2])
        mag_enh = np.abs(fft_enh[:len(fft_enh)//2])
        
        plt.semilogx(pos_freqs[1:], 20*np.log10(mag_orig[1:] + 1e-10), 
                    label='åŸå§‹éŸ³é¢‘', alpha=0.7)
        plt.semilogx(pos_freqs[1:], 20*np.log10(mag_enh[1:] + 1e-10), 
                    label='å¢å¼ºéŸ³é¢‘', alpha=0.7)
        
        plt.title('é¢‘ç‡å“åº”å¯¹æ¯”')
        plt.xlabel('é¢‘ç‡ (Hz)')
        plt.ylabel('å¹…åº¦ (dB)')
        plt.legend()
        plt.grid(True)
        
        plt.tight_layout()
        plt.savefig(self.workspace / "audio_comparison.png", dpi=150, bbox_inches='tight')
        plt.close()
        
        self.logger.info("å¯¹æ¯”å›¾è¡¨å·²ç”Ÿæˆ")
    
    def enhance_audio(self, video_file, output_video=None):
        """å®Œæ•´çš„éŸ³é¢‘å¢å¼ºæµç¨‹"""
        start_time = datetime.now()
        
        if output_video is None:
            video_path = Path(video_file)
            output_video = f"enhanced_audio_{video_path.stem}.mp4"
        
        try:
            self.logger.info("ğŸµ å¼€å§‹è¯å‰§éŸ³é¢‘å¢å¼ºå¤„ç†")
            self.logger.info(f"è¾“å…¥è§†é¢‘: {video_file}")
            self.logger.info(f"è¾“å‡ºè§†é¢‘: {output_video}")
            
            # æ­¥éª¤1: æå–éŸ³é¢‘
            original_audio = self.extract_audio(video_file)
            
            # æ­¥éª¤2: åˆ†æéŸ³é¢‘
            analysis = self.analyze_audio(original_audio)
            
            # æ­¥éª¤3: é™å™ªå¤„ç†
            denoised_audio = self.noise_reduction(original_audio)
            
            # æ­¥éª¤4: é¢‘ç‡å‡è¡¡
            equalized_audio = self.apply_equalizer(denoised_audio)
            
            # æ­¥éª¤5: åŠ¨æ€èŒƒå›´æ§åˆ¶
            compressed_audio = self.apply_dynamics_processing(equalized_audio)
            
            # æ­¥éª¤6: ç©ºé—´éŸ³æ•ˆä¼˜åŒ–
            enhanced_audio = self.apply_spatial_enhancement(compressed_audio)
            
            # æ­¥éª¤7: ä¸è§†é¢‘åˆå¹¶
            self.merge_with_video(enhanced_audio, video_file, output_video)
            
            # æ­¥éª¤8: ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
            comparison = self.generate_comparison_report(original_audio, enhanced_audio)
            
            processing_time = (datetime.now() - start_time).total_seconds()
            
            self.logger.info(f"ğŸ‰ éŸ³é¢‘å¢å¼ºå®Œæˆ! å¤„ç†æ—¶é—´: {processing_time:.1f}ç§’")
            self.logger.info(f"âœ… è¾“å‡ºæ–‡ä»¶: {output_video}")
            self.logger.info(f"ğŸ“Š SNRæå‡: {comparison['improvements']['snr_improvement_db']:.1f}dB")
            
            return output_video
            
        except Exception as e:
            self.logger.error(f"âŒ éŸ³é¢‘å¢å¼ºå¤±è´¥: {str(e)}")
            raise

def main():
    """ä¸»ç¨‹åºå…¥å£"""
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•: python theater_audio_enhancer.py input_video.mp4 [output_video.mp4]")
        print("æˆ–è€…: python theater_audio_enhancer.py --analyze-only input_video.mp4")
        sys.exit(1)
    
    # æ£€æŸ¥æ˜¯å¦åªè¿›è¡ŒéŸ³é¢‘åˆ†æ
    if sys.argv[1] == "--analyze-only" and len(sys.argv) >= 3:
        input_video = sys.argv[2]
        enhancer = TheaterAudioEnhancer()
        
        # åªæ‰§è¡ŒéŸ³é¢‘åˆ†æéƒ¨åˆ†
        print("ğŸµ å¼€å§‹è¯å‰§éŸ³é¢‘è´¨é‡åˆ†æ...")
        original_audio = enhancer.extract_audio(input_video)
        analysis = enhancer.analyze_audio(original_audio)
        
        # ç”Ÿæˆè¯¦ç»†çš„åˆ†ææŠ¥å‘Š
        enhancer.generate_detailed_analysis_report(original_audio, analysis)
        print("âœ… éŸ³é¢‘è´¨é‡åˆ†æå®Œæˆ!")
        return
    
    input_video = sys.argv[1]
    output_video = sys.argv[2] if len(sys.argv) > 2 else None
    
    enhancer = TheaterAudioEnhancer()
    enhancer.enhance_audio(input_video, output_video)

if __name__ == "__main__":
    main()
    main()