#!/usr/bin/env python3
"""
åŸºäºOpenCV CUDAçš„GPUåŠ é€Ÿå™¨
é’ˆå¯¹ç°æœ‰ç¯å¢ƒä¼˜åŒ–çš„GPUåŠ é€Ÿå®ç°
"""

import os
import sys
import json
import subprocess
import logging
import time
import numpy as np
import cv2
from pathlib import Path
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed

class OpenCVGPUAccelerator:
    def __init__(self):
        self.setup_logging()
        self.setup_gpu_environment()
        
        # GPUé…ç½®
        self.gpu_config = {
            'batch_size': 8,
            'use_gpu_memory_optimization': True,
            'gpu_streams': 2,
            'fallback_to_cpu': True
        }
        
    def setup_logging(self):
        """è®¾ç½®æ—¥å¿—ç³»ç»Ÿ"""
        log_file = f"opencv_gpu_acceleration_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file, encoding='utf-8'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
        
    def setup_gpu_environment(self):
        """è®¾ç½®OpenCV GPUç¯å¢ƒ"""
        self.logger.info("ğŸ”§ è®¾ç½®OpenCV GPUç¯å¢ƒ...")
        
        # æ£€æŸ¥CUDAè®¾å¤‡
        self.cuda_device_count = cv2.cuda.getCudaEnabledDeviceCount()
        self.gpu_available = self.cuda_device_count > 0
        
        if self.gpu_available:
            self.logger.info(f"âœ… æ£€æµ‹åˆ° {self.cuda_device_count} ä¸ªCUDAè®¾å¤‡")
            
            # è·å–GPUä¿¡æ¯
            try:
                result = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total', 
                                       '--format=csv,noheader'], 
                                      capture_output=True, text=True)
                if result.returncode == 0:
                    gpu_info = result.stdout.strip().split(', ')
                    self.logger.info(f"   GPU: {gpu_info[0]}")
                    self.logger.info(f"   æ˜¾å­˜: {gpu_info[1]} MB")
            except:
                pass
                
            # è®¾ç½®CUDAè®¾å¤‡
            cv2.cuda.setDevice(0)
            self.logger.info("âœ… OpenCV CUDAç¯å¢ƒè®¾ç½®å®Œæˆ")
        else:
            self.logger.warning("âš ï¸ æœªæ£€æµ‹åˆ°CUDAè®¾å¤‡ï¼Œå°†ä½¿ç”¨CPUå¤„ç†")
            
    def gpu_denoise_opencv(self, image):
        """ä½¿ç”¨OpenCV CUDAè¿›è¡Œé™å™ª"""
        if not self.gpu_available:
            return cv2.bilateralFilter(image, 9, 75, 75)
            
        try:
            # ä¸Šä¼ åˆ°GPU
            gpu_img = cv2.cuda_GpuMat()
            gpu_img.upload(image)
            
            # GPUåŒè¾¹æ»¤æ³¢é™å™ª
            gpu_result = cv2.cuda.bilateralFilter(gpu_img, -1, 50, 50)
            
            # ä¸‹è½½åˆ°CPU
            result = gpu_result.download()
            return result
            
        except Exception as e:
            self.logger.warning(f"GPUé™å™ªå¤±è´¥ï¼Œä½¿ç”¨CPU: {e}")
            return cv2.bilateralFilter(image, 9, 75, 75)
            
    def gpu_upscale_opencv(self, image, scale_factor=2):
        """ä½¿ç”¨OpenCV CUDAè¿›è¡Œæ”¾å¤§"""
        if not self.gpu_available:
            height, width = image.shape[:2]
            new_size = (width * scale_factor, height * scale_factor)
            return cv2.resize(image, new_size, interpolation=cv2.INTER_LANCZOS4)
            
        try:
            # ä¸Šä¼ åˆ°GPU
            gpu_img = cv2.cuda_GpuMat()
            gpu_img.upload(image)
            
            # GPUç¼©æ”¾
            height, width = image.shape[:2]
            new_size = (width * scale_factor, height * scale_factor)
            gpu_result = cv2.cuda.resize(gpu_img, new_size, interpolation=cv2.INTER_CUBIC)
            
            # ä¸‹è½½åˆ°CPU
            result = gpu_result.download()
            return result
            
        except Exception as e:
            self.logger.warning(f"GPUæ”¾å¤§å¤±è´¥ï¼Œä½¿ç”¨CPU: {e}")
            height, width = image.shape[:2]
            new_size = (width * scale_factor, height * scale_factor)
            return cv2.resize(image, new_size, interpolation=cv2.INTER_LANCZOS4)
            
    def gpu_enhance_image(self, image, operations=['upscale']):
        """GPUå›¾åƒå¢å¼º"""
        result = image.copy()
        
        for operation in operations:
            if operation == 'denoise':
                result = self.gpu_denoise_opencv(result)
            elif operation == 'upscale':
                result = self.gpu_upscale_opencv(result, 2)
            elif operation == 'sharpen':
                result = self.gpu_sharpen_opencv(result)
                
        return result
        
    def gpu_sharpen_opencv(self, image):
        """ä½¿ç”¨OpenCV CUDAè¿›è¡Œé”åŒ–"""
        if not self.gpu_available:
            kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])
            return cv2.filter2D(image, -1, kernel)
            
        try:
            # ä¸Šä¼ åˆ°GPU
            gpu_img = cv2.cuda_GpuMat()
            gpu_img.upload(image)
            
            # åˆ›å»ºé”åŒ–æ ¸
            kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]], dtype=np.float32)
            
            # GPUæ»¤æ³¢
            gpu_result = cv2.cuda.filter2D(gpu_img, -1, kernel)
            
            # ä¸‹è½½åˆ°CPU
            result = gpu_result.download()
            return result
            
        except Exception as e:
            self.logger.warning(f"GPUé”åŒ–å¤±è´¥ï¼Œä½¿ç”¨CPU: {e}")
            kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])
            return cv2.filter2D(image, -1, kernel)
            
    def process_frames_batch_gpu(self, frame_files, output_dir, operations=['upscale']):
        """GPUæ‰¹é‡å¤„ç†å¸§"""
        self.logger.info(f"ğŸš€ GPUæ‰¹é‡å¤„ç† {len(frame_files)} å¸§...")
        
        processed_count = 0
        failed_count = 0
        
        for i, frame_file in enumerate(frame_files):
            try:
                # åŠ è½½å›¾åƒ
                image = cv2.imread(str(frame_file))
                if image is None:
                    failed_count += 1
                    continue
                
                # GPUå¢å¼ºå¤„ç†
                enhanced = self.gpu_enhance_image(image, operations)
                
                # ä¿å­˜ç»“æœ
                output_file = Path(output_dir) / frame_file.name
                success = cv2.imwrite(str(output_file), enhanced)
                
                if success:
                    processed_count += 1
                else:
                    failed_count += 1
                    
                # è¿›åº¦æ˜¾ç¤º
                if (i + 1) % 10 == 0:
                    progress = ((i + 1) / len(frame_files)) * 100
                    gpu_util = self.get_gpu_utilization()
                    self.logger.info(f"ğŸ“Š GPUæ‰¹é‡å¤„ç†è¿›åº¦: {progress:.1f}% "
                                   f"({processed_count}/{len(frame_files)}) "
                                   f"GPU: {gpu_util['gpu_utilization']:.1f}%")
                    
            except Exception as e:
                self.logger.error(f"å¤„ç†å¸§å¤±è´¥ {frame_file}: {e}")
                failed_count += 1
                
        return processed_count, failed_count
        
    def process_video_frames_directory(self, frames_dir, output_dir, operations=['upscale']):
        """å¤„ç†è§†é¢‘å¸§ç›®å½•"""
        start_time = time.time()
        
        self.logger.info("ğŸ¬ å¼€å§‹GPUåŠ é€Ÿè§†é¢‘å¸§å¤„ç†...")
        self.logger.info(f"è¾“å…¥ç›®å½•: {frames_dir}")
        self.logger.info(f"è¾“å‡ºç›®å½•: {output_dir}")
        self.logger.info(f"æ“ä½œåºåˆ—: {operations}")
        
        # è·å–æ‰€æœ‰å¸§æ–‡ä»¶
        frame_files = sorted(Path(frames_dir).glob("*.png"))
        total_frames = len(frame_files)
        
        if total_frames == 0:
            raise ValueError(f"åœ¨ {frames_dir} ä¸­æœªæ‰¾åˆ°PNGå¸§æ–‡ä»¶")
            
        self.logger.info(f"æ‰¾åˆ° {total_frames} ä¸ªå¸§æ–‡ä»¶")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        Path(output_dir).mkdir(parents=True, exist_ok=True)
        
        # åˆ†æ‰¹å¤„ç†
        batch_size = self.gpu_config['batch_size']
        total_processed = 0
        total_failed = 0
        
        for i in range(0, total_frames, batch_size):
            batch_files = frame_files[i:i + batch_size]
            
            self.logger.info(f"ğŸ”„ å¤„ç†æ‰¹æ¬¡ {i//batch_size + 1}/{(total_frames + batch_size - 1)//batch_size}")
            
            # GPUæ‰¹é‡å¤„ç†
            processed, failed = self.process_frames_batch_gpu(batch_files, output_dir, operations)
            
            total_processed += processed
            total_failed += failed
            
            # æ‰¹æ¬¡å®ŒæˆæŠ¥å‘Š
            batch_progress = ((i + len(batch_files)) / total_frames) * 100
            elapsed = time.time() - start_time
            fps = total_processed / elapsed if elapsed > 0 else 0
            
            self.logger.info(f"ğŸ“Š æ€»è¿›åº¦: {batch_progress:.1f}% "
                           f"æˆåŠŸ: {total_processed} å¤±è´¥: {total_failed} "
                           f"é€Ÿåº¦: {fps:.1f} fps")
        
        # æœ€ç»ˆç»Ÿè®¡
        total_time = time.time() - start_time
        success_rate = (total_processed / total_frames) * 100 if total_frames > 0 else 0
        avg_fps = total_processed / total_time if total_time > 0 else 0
        
        # ç”Ÿæˆå¤„ç†æŠ¥å‘Š
        report = {
            "task": "11.1 GPU-accelerated algorithm integration",
            "processing_timestamp": datetime.now().isoformat(),
            "input_directory": str(frames_dir),
            "output_directory": str(output_dir),
            "operations": operations,
            "statistics": {
                "total_frames": total_frames,
                "processed_frames": total_processed,
                "failed_frames": total_failed,
                "success_rate_percent": success_rate,
                "processing_time_seconds": total_time,
                "average_fps": avg_fps
            },
            "gpu_info": {
                "cuda_devices": self.cuda_device_count,
                "gpu_available": self.gpu_available,
                "final_gpu_utilization": self.get_gpu_utilization()
            },
            "processing_successful": total_processed > 0
        }
        
        # ä¿å­˜æŠ¥å‘Š
        with open("task_11_1_gpu_acceleration_report.json", 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
            
        self.logger.info("âœ… GPUåŠ é€Ÿå¤„ç†å®Œæˆ!")
        self.logger.info(f"   æ€»å¸§æ•°: {total_frames}")
        self.logger.info(f"   æˆåŠŸå¤„ç†: {total_processed}")
        self.logger.info(f"   å¤±è´¥: {total_failed}")
        self.logger.info(f"   æˆåŠŸç‡: {success_rate:.1f}%")
        self.logger.info(f"   æ€»ç”¨æ—¶: {total_time:.1f}ç§’")
        self.logger.info(f"   å¹³å‡é€Ÿåº¦: {avg_fps:.1f} fps")
        
        return report
        
    def get_gpu_utilization(self):
        """è·å–GPUåˆ©ç”¨ç‡"""
        try:
            result = subprocess.run(['nvidia-smi', '--query-gpu=utilization.gpu,memory.used,memory.total', 
                                   '--format=csv,noheader,nounits'], 
                                  capture_output=True, text=True)
            if result.returncode == 0:
                gpu_util, mem_used, mem_total = result.stdout.strip().split(', ')
                return {
                    'gpu_utilization': float(gpu_util),
                    'memory_used_mb': float(mem_used),
                    'memory_total_mb': float(mem_total),
                    'memory_utilization': (float(mem_used) / float(mem_total)) * 100
                }
        except:
            pass
        return {'gpu_utilization': 0, 'memory_utilization': 0}
        
    def benchmark_gpu_vs_cpu(self, test_image_path, iterations=5):
        """GPU vs CPUæ€§èƒ½å¯¹æ¯”æµ‹è¯•"""
        self.logger.info("ğŸ å¼€å§‹GPU vs CPUæ€§èƒ½å¯¹æ¯”æµ‹è¯•...")
        
        # åŠ è½½æµ‹è¯•å›¾åƒ
        test_img = cv2.imread(test_image_path)
        if test_img is None:
            raise ValueError(f"æ— æ³•åŠ è½½æµ‹è¯•å›¾åƒ: {test_image_path}")
            
        self.logger.info(f"æµ‹è¯•å›¾åƒå¤§å°: {test_img.shape}")
        
        results = {
            'test_image_size': test_img.shape,
            'iterations': iterations,
            'gpu_available': self.gpu_available,
            'operations': {}
        }
        
        # æµ‹è¯•æ“ä½œ
        operations = {
            'upscale_2x': {
                'gpu': lambda img: self.gpu_upscale_opencv(img, 2),
                'cpu': lambda img: cv2.resize(img, (img.shape[1]*2, img.shape[0]*2), interpolation=cv2.INTER_LANCZOS4)
            },
            'denoise': {
                'gpu': lambda img: self.gpu_denoise_opencv(img),
                'cpu': lambda img: cv2.bilateralFilter(img, 9, 75, 75)
            }
        }
        
        for op_name, op_funcs in operations.items():
            self.logger.info(f"æµ‹è¯•æ“ä½œ: {op_name}")
            
            # GPUæµ‹è¯•
            gpu_times = []
            if self.gpu_available:
                for i in range(iterations):
                    start_time = time.time()
                    result = op_funcs['gpu'](test_img.copy())
                    end_time = time.time()
                    gpu_times.append(end_time - start_time)
                    
            # CPUæµ‹è¯•
            cpu_times = []
            for i in range(iterations):
                start_time = time.time()
                result = op_funcs['cpu'](test_img.copy())
                end_time = time.time()
                cpu_times.append(end_time - start_time)
            
            # è®¡ç®—ç»Ÿè®¡
            results['operations'][op_name] = {
                'gpu': {
                    'avg_time': np.mean(gpu_times) if gpu_times else 0,
                    'min_time': np.min(gpu_times) if gpu_times else 0,
                    'max_time': np.max(gpu_times) if gpu_times else 0
                } if self.gpu_available else None,
                'cpu': {
                    'avg_time': np.mean(cpu_times),
                    'min_time': np.min(cpu_times),
                    'max_time': np.max(cpu_times)
                },
                'speedup': np.mean(cpu_times) / np.mean(gpu_times) if gpu_times else 0
            }
            
            if self.gpu_available and gpu_times:
                speedup = np.mean(cpu_times) / np.mean(gpu_times)
                self.logger.info(f"  {op_name} - GPU: {np.mean(gpu_times):.3f}s, CPU: {np.mean(cpu_times):.3f}s, åŠ é€Ÿæ¯”: {speedup:.1f}x")
            else:
                self.logger.info(f"  {op_name} - CPU: {np.mean(cpu_times):.3f}s")
        
        # ä¿å­˜åŸºå‡†æµ‹è¯•ç»“æœ
        with open("gpu_vs_cpu_benchmark.json", 'w') as f:
            json.dump(results, f, indent=2)
            
        self.logger.info("âœ… GPU vs CPUæ€§èƒ½å¯¹æ¯”æµ‹è¯•å®Œæˆ")
        return results

def main():
    if len(sys.argv) < 3:
        print("ä½¿ç”¨æ–¹æ³•: python3 opencv_gpu_accelerator.py <operation> <input_path> [output_path]")
        print("æ“ä½œé€‰é¡¹:")
        print("  process - å¤„ç†è§†é¢‘å¸§ç›®å½•")
        print("  benchmark - GPU vs CPUæ€§èƒ½å¯¹æ¯”")
        print("  test - æµ‹è¯•å•å¼ å›¾åƒ")
        sys.exit(1)
    
    operation = sys.argv[1]
    input_path = sys.argv[2]
    output_path = sys.argv[3] if len(sys.argv) > 3 else None
    
    accelerator = OpenCVGPUAccelerator()
    
    if operation == "process":
        if not output_path:
            output_path = "gpu_enhanced_frames"
        operations = ['upscale']  # å¯ä»¥ä¿®æ”¹ä¸º ['denoise', 'upscale', 'sharpen']
        accelerator.process_video_frames_directory(input_path, output_path, operations)
        
    elif operation == "benchmark":
        accelerator.benchmark_gpu_vs_cpu(input_path)
        
    elif operation == "test":
        # æµ‹è¯•å•å¼ å›¾åƒ
        test_img = cv2.imread(input_path)
        if test_img is not None:
            print("æµ‹è¯•GPUå›¾åƒå¢å¼º...")
            enhanced = accelerator.gpu_enhance_image(test_img, ['upscale'])
            if output_path:
                cv2.imwrite(output_path, enhanced)
                print(f"âœ… å¢å¼ºå›¾åƒå·²ä¿å­˜: {output_path}")
            else:
                print("âœ… GPUå›¾åƒå¢å¼ºæµ‹è¯•å®Œæˆ")
        else:
            print("âŒ æ— æ³•åŠ è½½æµ‹è¯•å›¾åƒ")

if __name__ == "__main__":
    main()