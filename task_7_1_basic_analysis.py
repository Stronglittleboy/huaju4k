#!/usr/bin/env python3
"""
Task 7.1: Basic Audio Quality Analysis
Simplified version without heavy plotting
"""

import os
import sys
import json
import numpy as np
from pathlib import Path
from datetime import datetime

def basic_audio_analysis():
    """æ‰§è¡ŒåŸºç¡€éŸ³é¢‘åˆ†æ"""
    
    print("ğŸµ Task 7.1: è¯å‰§éŸ³é¢‘è´¨é‡åˆ†æ (åŸºç¡€ç‰ˆ)")
    
    video_file = "videos/å¤§å­¦ç”ŸåŸåˆ›è¯å‰§ã€Šè‡ªæ€æ—¢é‚ã€‹.mp4"
    
    if not Path(video_file).exists():
        print(f"âŒ è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_file}")
        return
    
    # åˆ›å»ºå·¥ä½œç›®å½•
    workspace = Path("audio_workspace")
    workspace.mkdir(exist_ok=True)
    
    try:
        print("æ­¥éª¤1: åŠ è½½éŸ³é¢‘æ•°æ®...")
        
        # ä½¿ç”¨librosaåŠ è½½éŸ³é¢‘ (å‰30ç§’)
        import librosa
        
        print("  - æ­£åœ¨åŠ è½½éŸ³é¢‘æ•°æ® (å‰30ç§’)...")
        y, sr = librosa.load(video_file, sr=48000, duration=30)
        
        duration = len(y) / sr
        print(f"  âœ… éŸ³é¢‘åŠ è½½æˆåŠŸ: {duration:.1f}ç§’, é‡‡æ ·ç‡: {sr} Hz")
        
        print("\næ­¥éª¤2: åŸºæœ¬ç‰¹å¾åˆ†æ...")
        
        # åŸºæœ¬ç»Ÿè®¡
        rms_energy = np.sqrt(np.mean(y**2))
        peak_amplitude = np.max(np.abs(y))
        zero_crossing_rate = np.mean(librosa.feature.zero_crossing_rate(y)[0])
        dynamic_range_db = 20 * np.log10(peak_amplitude / (rms_energy + 1e-10))
        
        print(f"  - RMSèƒ½é‡: {rms_energy:.6f}")
        print(f"  - å³°å€¼æŒ¯å¹…: {peak_amplitude:.6f}")
        print(f"  - åŠ¨æ€èŒƒå›´: {dynamic_range_db:.1f} dB")
        
        print("\næ­¥éª¤3: é¢‘è°±åˆ†æ...")
        
        # é¢‘è°±ç‰¹å¾
        spectral_centroids = librosa.feature.spectral_centroid(y=y, sr=sr)[0]
        spectral_bandwidth = librosa.feature.spectral_bandwidth(y=y, sr=sr)[0]
        
        print(f"  - é¢‘è°±è´¨å¿ƒ: {np.mean(spectral_centroids):.1f} Hz")
        print(f"  - é¢‘è°±å¸¦å®½: {np.mean(spectral_bandwidth):.1f} Hz")
        
        print("\næ­¥éª¤4: å™ªéŸ³åˆ†æ...")
        
        # å™ªéŸ³ä¼°ç®—
        silence_threshold = np.percentile(np.abs(y), 20)
        silence_mask = np.abs(y) < silence_threshold
        noise_floor = np.mean(np.abs(y[silence_mask])) if np.any(silence_mask) else silence_threshold
        
        signal_power = rms_energy**2
        noise_power = noise_floor**2
        snr_estimate = 10 * np.log10(signal_power / (noise_power + 1e-10))
        
        print(f"  - å™ªéŸ³åº•å™ª: {noise_floor:.6f}")
        print(f"  - ä¼°ç®—SNR: {snr_estimate:.1f} dB")
        
        print("\næ­¥éª¤5: è¯­éŸ³æ´»åŠ¨æ£€æµ‹...")
        
        # ç®€å•çš„è¯­éŸ³æ´»åŠ¨æ£€æµ‹
        frame_length = 2048
        hop_length = 512
        frames = librosa.util.frame(y, frame_length=frame_length, hop_length=hop_length)
        frame_energy = np.sum(frames**2, axis=0)
        energy_threshold = np.percentile(frame_energy, 60)
        speech_frames = frame_energy > energy_threshold
        speech_ratio = np.sum(speech_frames) / len(speech_frames)
        
        print(f"  - è¯­éŸ³æ´»åŠ¨æ¯”ä¾‹: {speech_ratio:.1%}")
        
        print("\næ­¥éª¤6: è´¨é‡è¯„ä¼°...")
        
        # è´¨é‡è¯„ä¼°
        if snr_estimate > 25 and dynamic_range_db > 15:
            overall_quality = "excellent"
        elif snr_estimate > 15 and dynamic_range_db > 10:
            overall_quality = "good"
        elif snr_estimate > 10:
            overall_quality = "fair"
        else:
            overall_quality = "poor"
        
        print(f"  - æ•´ä½“è´¨é‡: {overall_quality}")
        
        # å¤„ç†å»ºè®®
        noise_reduction = "heavy" if snr_estimate < 10 else "medium" if snr_estimate < 20 else "light"
        print(f"  - å»ºè®®é™å™ª: {noise_reduction}")
        
        print("\næ­¥éª¤7: ç”ŸæˆæŠ¥å‘Š...")
        
        # åˆ†æç»“æœ
        analysis_result = {
            "task": "7.1 Audio quality analysis and assessment",
            "file_info": {
                "file_path": str(video_file),
                "sample_duration_seconds": float(duration),
                "sample_rate": int(sr),
                "analysis_timestamp": datetime.now().isoformat()
            },
            "basic_metrics": {
                "rms_energy": float(rms_energy),
                "peak_amplitude": float(peak_amplitude),
                "dynamic_range_db": float(dynamic_range_db),
                "zero_crossing_rate": float(zero_crossing_rate),
                "estimated_snr_db": float(snr_estimate)
            },
            "spectral_features": {
                "spectral_centroid_mean": float(np.mean(spectral_centroids)),
                "spectral_bandwidth_mean": float(np.mean(spectral_bandwidth))
            },
            "noise_analysis": {
                "noise_floor": float(noise_floor),
                "silence_ratio": float(np.sum(silence_mask) / len(silence_mask)),
                "snr_estimate_db": float(snr_estimate)
            },
            "theater_specific": {
                "speech_activity_ratio": float(speech_ratio)
            },
            "quality_assessment": {
                "overall_quality": overall_quality,
                "background_noise_level": "low" if snr_estimate > 20 else "moderate" if snr_estimate > 10 else "high",
                "dynamic_range_type": "wide" if dynamic_range_db > 15 else "moderate" if dynamic_range_db > 10 else "compressed"
            },
            "processing_recommendations": {
                "noise_reduction": noise_reduction,
                "compression_needed": bool(dynamic_range_db > 20),
                "limiting_needed": bool(peak_amplitude > 0.9)
            }
        }
        
        # ä¿å­˜æŠ¥å‘Š
        report_file = workspace / "task_7_1_basic_audio_analysis.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(analysis_result, f, indent=2, ensure_ascii=False)
        
        print(f"  âœ… æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
        
        # ç”Ÿæˆç®€å•çš„MarkdownæŠ¥å‘Š
        markdown_content = f"""# Task 7.1: è¯å‰§éŸ³é¢‘è´¨é‡åˆ†ææŠ¥å‘Š

## åŸºæœ¬ä¿¡æ¯
- **æ–‡ä»¶**: {video_file}
- **åˆ†ææ ·æœ¬**: å‰{duration:.1f}ç§’
- **é‡‡æ ·ç‡**: {sr} Hz
- **åˆ†ææ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## åˆ†æç»“æœ

### æ•´ä½“è´¨é‡: **{overall_quality.upper()}**

| æŒ‡æ ‡ | æ•°å€¼ |
|------|------|
| RMSèƒ½é‡ | {rms_energy:.6f} |
| å³°å€¼æŒ¯å¹… | {peak_amplitude:.6f} |
| åŠ¨æ€èŒƒå›´ | {dynamic_range_db:.1f} dB |
| ä¼°ç®—SNR | {snr_estimate:.1f} dB |
| è¯­éŸ³æ´»åŠ¨æ¯”ä¾‹ | {speech_ratio:.1%} |

### é¢‘è°±ç‰¹å¾
- **é¢‘è°±è´¨å¿ƒ**: {np.mean(spectral_centroids):.1f} Hz
- **é¢‘è°±å¸¦å®½**: {np.mean(spectral_bandwidth):.1f} Hz

### è´¨é‡è¯„ä¼°
- **æ•´ä½“è´¨é‡**: {overall_quality}
- **èƒŒæ™¯å™ªéŸ³**: {analysis_result['quality_assessment']['background_noise_level']}
- **åŠ¨æ€èŒƒå›´**: {analysis_result['quality_assessment']['dynamic_range_type']}

### å¤„ç†å»ºè®®
- **é™å™ªå¼ºåº¦**: {noise_reduction}
- **éœ€è¦å‹ç¼©**: {'æ˜¯' if analysis_result['processing_recommendations']['compression_needed'] else 'å¦'}
- **éœ€è¦é™å¹…**: {'æ˜¯' if analysis_result['processing_recommendations']['limiting_needed'] else 'å¦'}

## ç»“è®º

åŸºäºå¯¹è¯å‰§éŸ³é¢‘çš„åˆ†æï¼Œè¯¥æ–‡ä»¶çš„éŸ³é¢‘è´¨é‡ä¸º **{overall_quality}**ï¼Œå»ºè®®è¿›è¡Œ **{noise_reduction}** å¼ºåº¦çš„é™å™ªå¤„ç†ã€‚

---
*Task 7.1 å®Œæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
"""
        
        markdown_file = workspace / "task_7_1_audio_analysis_report.md"
        with open(markdown_file, 'w', encoding='utf-8') as f:
            f.write(markdown_content)
        
        print(f"  âœ… MarkdownæŠ¥å‘Šå·²ä¿å­˜: {markdown_file}")
        
        print(f"\nğŸ‰ Task 7.1 å®Œæˆ!")
        print(f"ğŸ“Š å…³é”®ç»“æœ:")
        print(f"  - æ•´ä½“è´¨é‡: {overall_quality}")
        print(f"  - SNR: {snr_estimate:.1f}dB")
        print(f"  - åŠ¨æ€èŒƒå›´: {dynamic_range_db:.1f}dB")
        print(f"  - è¯­éŸ³æ´»åŠ¨: {speech_ratio:.1%}")
        
        return analysis_result
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return None

if __name__ == "__main__":
    basic_audio_analysis()