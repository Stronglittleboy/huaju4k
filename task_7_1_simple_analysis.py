#!/usr/bin/env python3
"""
Task 7.1: Audio Quality Analysis and Assessment
Simple implementation for theater drama audio analysis
"""

import os
import sys
import json
import numpy as np
import matplotlib
matplotlib.use('Agg')  # Use non-interactive backend
import matplotlib.pyplot as plt
from pathlib import Path
from datetime import datetime

def analyze_theater_audio_simple():
    """æ‰§è¡ŒTask 7.1çš„éŸ³é¢‘è´¨é‡åˆ†æ"""
    
    print("ğŸµ Task 7.1: è¯å‰§éŸ³é¢‘è´¨é‡åˆ†æå¼€å§‹")
    
    video_file = "videos/å¤§å­¦ç”ŸåŸåˆ›è¯å‰§ã€Šè‡ªæ€æ—¢é‚ã€‹.mp4"
    
    if not Path(video_file).exists():
        print(f"âŒ è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_file}")
        return
    
    # åˆ›å»ºå·¥ä½œç›®å½•
    workspace = Path("audio_workspace")
    workspace.mkdir(exist_ok=True)
    
    try:
        print("æ­¥éª¤1: åŠ è½½éŸ³é¢‘æ•°æ®è¿›è¡Œåˆ†æ...")
        
        # ä½¿ç”¨librosaç›´æ¥ä»è§†é¢‘åŠ è½½éŸ³é¢‘ (å‰60ç§’ç”¨äºåˆ†æ)
        import librosa
        import soundfile as sf
        
        print("  - æ­£åœ¨ä»è§†é¢‘æ–‡ä»¶åŠ è½½éŸ³é¢‘æ•°æ®...")
        y, sr = librosa.load(video_file, sr=48000, duration=60)  # åªåŠ è½½å‰60ç§’è¿›è¡Œåˆ†æ
        
        duration = len(y) / sr
        print(f"  âœ… éŸ³é¢‘åŠ è½½æˆåŠŸ: {duration:.1f}ç§’, é‡‡æ ·ç‡: {sr} Hz")
        
        # ä¿å­˜ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶ç”¨äºåç»­åˆ†æ
        temp_audio_file = workspace / "sample_audio_60s.wav"
        sf.write(temp_audio_file, y, sr)
        print(f"  - æ ·æœ¬éŸ³é¢‘å·²ä¿å­˜: {temp_audio_file}")
        
        print("\næ­¥éª¤2: åŸºæœ¬éŸ³é¢‘ç‰¹å¾åˆ†æ...")
        
        # åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯
        rms_energy = np.sqrt(np.mean(y**2))
        peak_amplitude = np.max(np.abs(y))
        zero_crossing_rate = np.mean(librosa.feature.zero_crossing_rate(y)[0])
        
        print(f"  - RMSèƒ½é‡: {rms_energy:.6f}")
        print(f"  - å³°å€¼æŒ¯å¹…: {peak_amplitude:.6f}")
        print(f"  - è¿‡é›¶ç‡: {zero_crossing_rate:.6f}")
        
        # åŠ¨æ€èŒƒå›´åˆ†æ
        dynamic_range_db = 20 * np.log10(peak_amplitude / (rms_energy + 1e-10))
        print(f"  - åŠ¨æ€èŒƒå›´: {dynamic_range_db:.1f} dB")
        
        print("\næ­¥éª¤3: é¢‘è°±ç‰¹å¾åˆ†æ...")
        
        # é¢‘è°±ç‰¹å¾
        spectral_centroids = librosa.feature.spectral_centroid(y=y, sr=sr)[0]
        spectral_bandwidth = librosa.feature.spectral_bandwidth(y=y, sr=sr)[0]
        spectral_rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)[0]
        
        print(f"  - é¢‘è°±è´¨å¿ƒå‡å€¼: {np.mean(spectral_centroids):.1f} Hz")
        print(f"  - é¢‘è°±å¸¦å®½å‡å€¼: {np.mean(spectral_bandwidth):.1f} Hz")
        print(f"  - é¢‘è°±æ»šé™å‡å€¼: {np.mean(spectral_rolloff):.1f} Hz")
        
        print("\næ­¥éª¤4: å™ªéŸ³å’Œä¿¡å™ªæ¯”åˆ†æ...")
        
        # å™ªéŸ³åˆ†æ
        silence_threshold = np.percentile(np.abs(y), 20)
        silence_mask = np.abs(y) < silence_threshold
        noise_floor = np.mean(np.abs(y[silence_mask])) if np.any(silence_mask) else silence_threshold
        
        # ä¼°ç®—ä¿¡å™ªæ¯”
        signal_power = rms_energy**2
        noise_power = noise_floor**2
        snr_estimate = 10 * np.log10(signal_power / (noise_power + 1e-10))
        
        print(f"  - å™ªéŸ³åº•å™ª: {noise_floor:.6f}")
        print(f"  - é™éŸ³æ¯”ä¾‹: {np.sum(silence_mask) / len(silence_mask):.1%}")
        print(f"  - ä¼°ç®—SNR: {snr_estimate:.1f} dB")
        
        print("\næ­¥éª¤5: è¯å‰§ç‰¹æœ‰éŸ³é¢‘ç‰¹å¾åˆ†æ...")
        
        # è¯­éŸ³æ´»åŠ¨æ£€æµ‹
        frame_length = 2048
        hop_length = 512
        frames = librosa.util.frame(y, frame_length=frame_length, hop_length=hop_length)
        frame_energy = np.sum(frames**2, axis=0)
        energy_threshold = np.percentile(frame_energy, 60)
        speech_frames = frame_energy > energy_threshold
        speech_ratio = np.sum(speech_frames) / len(speech_frames)
        
        print(f"  - è¯­éŸ³æ´»åŠ¨æ¯”ä¾‹: {speech_ratio:.1%}")
        
        # é¢‘æ®µèƒ½é‡åˆ†æ
        stft = librosa.stft(y, hop_length=hop_length)
        magnitude = np.abs(stft)
        freqs = librosa.fft_frequencies(sr=sr)
        
        # å®šä¹‰è¯å‰§å…³é”®é¢‘æ®µ
        freq_bands = {
            "ä½é¢‘": (20, 250),
            "ä¸­é¢‘": (250, 2000),
            "äººå£°å…³é”®": (2000, 4000),
            "æ¸…æ™°åº¦": (4000, 8000),
            "é«˜é¢‘": (8000, 20000)
        }
        
        freq_energy = {}
        for band_name, (low_freq, high_freq) in freq_bands.items():
            band_indices = np.where((freqs >= low_freq) & (freqs <= high_freq))[0]
            if len(band_indices) > 0:
                band_energy = np.mean(magnitude[band_indices, :])
                freq_energy[band_name] = float(band_energy)
                print(f"  - {band_name}é¢‘æ®µèƒ½é‡: {band_energy:.4f}")
        
        print("\næ­¥éª¤6: éŸ³é¢‘è´¨é‡è¯„ä¼°...")
        
        # è´¨é‡è¯„ä¼°
        dialogue_prominence = freq_energy.get("äººå£°å…³é”®", 0) / (freq_energy.get("ä½é¢‘", 1) + 1e-10)
        
        # æ•´ä½“è´¨é‡è¯„ä¼°
        if snr_estimate > 25 and dynamic_range_db > 15:
            overall_quality = "excellent"
        elif snr_estimate > 15 and dynamic_range_db > 10:
            overall_quality = "good"
        elif snr_estimate > 10:
            overall_quality = "fair"
        else:
            overall_quality = "poor"
        
        print(f"  - å¯¹è¯çªå‡ºåº¦: {dialogue_prominence:.2f}")
        print(f"  - æ•´ä½“è´¨é‡è¯„ä¼°: {overall_quality}")
        
        # å¤„ç†å»ºè®®
        noise_reduction_needed = "heavy" if snr_estimate < 10 else "medium" if snr_estimate < 20 else "light"
        eq_needed = freq_energy.get("ä½é¢‘", 0) > freq_energy.get("ä¸­é¢‘", 0)
        compression_needed = dynamic_range_db > 20
        
        print(f"  - å»ºè®®é™å™ªå¼ºåº¦: {noise_reduction_needed}")
        print(f"  - éœ€è¦EQè°ƒæ•´: {'æ˜¯' if eq_needed else 'å¦'}")
        print(f"  - éœ€è¦åŠ¨æ€å‹ç¼©: {'æ˜¯' if compression_needed else 'å¦'}")
        
        print("\næ­¥éª¤7: ç”Ÿæˆåˆ†ææŠ¥å‘Š...")
        
        # æ±‡æ€»åˆ†æç»“æœ
        analysis_result = {
            "file_info": {
                "file_path": str(video_file),
                "sample_duration_seconds": float(duration),
                "sample_rate": int(sr),
                "analysis_timestamp": datetime.now().isoformat()
            },
            "basic_metrics": {
                "rms_energy": float(rms_energy),
                "peak_amplitude": float(peak_amplitude),
                "dynamic_range_db": float(dynamic_range_db),
                "zero_crossing_rate": float(zero_crossing_rate),
                "estimated_snr_db": float(snr_estimate)
            },
            "spectral_features": {
                "spectral_centroid_mean": float(np.mean(spectral_centroids)),
                "spectral_bandwidth_mean": float(np.mean(spectral_bandwidth)),
                "spectral_rolloff_mean": float(np.mean(spectral_rolloff))
            },
            "noise_analysis": {
                "noise_floor": float(noise_floor),
                "silence_ratio": float(np.sum(silence_mask) / len(silence_mask)),
                "snr_estimate_db": float(snr_estimate)
            },
            "frequency_energy_distribution": freq_energy,
            "theater_specific": {
                "speech_activity_ratio": float(speech_ratio),
                "dialogue_prominence": float(dialogue_prominence),
                "ambient_noise_level": float(noise_floor)
            },
            "quality_assessment": {
                "overall_quality": overall_quality,
                "dialogue_clarity": "good" if dialogue_prominence > 1.0 else "needs_improvement",
                "background_noise_level": "low" if snr_estimate > 20 else "moderate" if snr_estimate > 10 else "high",
                "dynamic_range_type": "wide" if dynamic_range_db > 15 else "moderate" if dynamic_range_db > 10 else "compressed"
            },
            "processing_recommendations": {
                "noise_reduction": noise_reduction_needed,
                "eq_adjustments": {
                    "bass_cut": freq_energy.get("ä½é¢‘", 0) > freq_energy.get("ä¸­é¢‘", 0),
                    "speech_boost": freq_energy.get("äººå£°å…³é”®", 0) < freq_energy.get("ä¸­é¢‘", 0),
                    "presence_boost": freq_energy.get("æ¸…æ™°åº¦", 0) < freq_energy.get("äººå£°å…³é”®", 0)
                },
                "dynamics_processing": {
                    "compression_needed": compression_needed,
                    "limiting_needed": peak_amplitude > 0.9
                }
            }
        }
        
        # ä¿å­˜JSONæŠ¥å‘Š
        report_file = workspace / "task_7_1_audio_analysis_report.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(analysis_result, f, indent=2, ensure_ascii=False)
        
        print(f"  âœ… JSONæŠ¥å‘Šå·²ä¿å­˜: {report_file}")
        
        # ç”Ÿæˆç®€å•çš„å¯è§†åŒ–å›¾è¡¨
        print("\næ­¥éª¤8: ç”Ÿæˆåˆ†æå›¾è¡¨...")
        
        plt.figure(figsize=(12, 8))
        
        # æ³¢å½¢å›¾
        plt.subplot(2, 2, 1)
        time = np.linspace(0, duration, len(y))
        plt.plot(time, y, alpha=0.7)
        plt.title('éŸ³é¢‘æ³¢å½¢')
        plt.xlabel('æ—¶é—´ (ç§’)')
        plt.ylabel('æŒ¯å¹…')
        plt.grid(True, alpha=0.3)
        
        # é¢‘è°±å›¾
        plt.subplot(2, 2, 2)
        D = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)
        librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='hz')
        plt.colorbar(format='%+2.0f dB')
        plt.title('é¢‘è°±å›¾')
        
        # é¢‘æ®µèƒ½é‡åˆ†å¸ƒ
        plt.subplot(2, 2, 3)
        bands = list(freq_energy.keys())
        energies = list(freq_energy.values())
        plt.bar(bands, energies, color='skyblue', alpha=0.7)
        plt.title('é¢‘æ®µèƒ½é‡åˆ†å¸ƒ')
        plt.xlabel('é¢‘æ®µ')
        plt.ylabel('èƒ½é‡')
        plt.xticks(rotation=45)
        plt.grid(True, alpha=0.3)
        
        # è´¨é‡æŒ‡æ ‡é›·è¾¾å›¾
        plt.subplot(2, 2, 4)
        categories = ['SNR', 'åŠ¨æ€èŒƒå›´', 'è¯­éŸ³æ´»åŠ¨', 'å¯¹è¯çªå‡ºåº¦']
        values = [
            min(snr_estimate / 30, 1.0),
            min(dynamic_range_db / 25, 1.0),
            speech_ratio,
            min(dialogue_prominence / 2, 1.0)
        ]
        
        angles = np.linspace(0, 2*np.pi, len(categories), endpoint=False).tolist()
        values += values[:1]
        angles += angles[:1]
        
        ax = plt.subplot(2, 2, 4, projection='polar')
        ax.plot(angles, values, 'o-', linewidth=2, color='purple')
        ax.fill(angles, values, alpha=0.25, color='purple')
        ax.set_xticks(angles[:-1])
        ax.set_xticklabels(categories)
        ax.set_ylim(0, 1)
        plt.title('éŸ³é¢‘è´¨é‡è¯„ä¼°')
        
        plt.tight_layout()
        
        plot_file = workspace / "task_7_1_audio_analysis_plots.png"
        plt.savefig(plot_file, dpi=150, bbox_inches='tight')
        plt.close()
        
        print(f"  âœ… åˆ†æå›¾è¡¨å·²ä¿å­˜: {plot_file}")
        
        # ç”ŸæˆMarkdownæŠ¥å‘Š
        print("\næ­¥éª¤9: ç”ŸæˆMarkdownæŠ¥å‘Š...")
        
        markdown_content = f"""# Task 7.1: è¯å‰§éŸ³é¢‘è´¨é‡åˆ†ææŠ¥å‘Š

## åˆ†ææ¦‚è¿°
- **è§†é¢‘æ–‡ä»¶**: {video_file}
- **åˆ†ææ ·æœ¬**: å‰{duration:.1f}ç§’
- **é‡‡æ ·ç‡**: {sr} Hz
- **åˆ†ææ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## å…³é”®å‘ç°

### æ•´ä½“è´¨é‡è¯„ä¼°: **{overall_quality.upper()}**

| æŒ‡æ ‡ | æ•°å€¼ | è¯„ä¼° |
|------|------|------|
| ä¼°ç®—ä¿¡å™ªæ¯” | {snr_estimate:.1f} dB | {analysis_result['quality_assessment']['background_noise_level']} |
| åŠ¨æ€èŒƒå›´ | {dynamic_range_db:.1f} dB | {analysis_result['quality_assessment']['dynamic_range_type']} |
| è¯­éŸ³æ´»åŠ¨æ¯”ä¾‹ | {speech_ratio:.1%} | - |
| å¯¹è¯æ¸…æ™°åº¦ | - | {analysis_result['quality_assessment']['dialogue_clarity']} |

## è¯¦ç»†åˆ†æç»“æœ

### åŸºç¡€éŸ³é¢‘ç‰¹å¾
- **RMSèƒ½é‡**: {rms_energy:.6f}
- **å³°å€¼æŒ¯å¹…**: {peak_amplitude:.6f}
- **è¿‡é›¶ç‡**: {zero_crossing_rate:.6f}

### é¢‘è°±ç‰¹å¾
- **é¢‘è°±è´¨å¿ƒ**: {np.mean(spectral_centroids):.1f} Hz
- **é¢‘è°±å¸¦å®½**: {np.mean(spectral_bandwidth):.1f} Hz
- **é¢‘è°±æ»šé™**: {np.mean(spectral_rolloff):.1f} Hz

### å™ªéŸ³åˆ†æ
- **å™ªéŸ³åº•å™ª**: {noise_floor:.6f}
- **é™éŸ³æ¯”ä¾‹**: {np.sum(silence_mask) / len(silence_mask):.1%}
- **ä¼°ç®—SNR**: {snr_estimate:.1f} dB

### é¢‘æ®µèƒ½é‡åˆ†å¸ƒ
"""
        
        for band, energy in freq_energy.items():
            markdown_content += f"- **{band}**: {energy:.4f}\n"
        
        markdown_content += f"""
### è¯å‰§ç‰¹æœ‰ç‰¹å¾
- **è¯­éŸ³æ´»åŠ¨æ¯”ä¾‹**: {speech_ratio:.1%}
- **å¯¹è¯çªå‡ºåº¦**: {dialogue_prominence:.2f}
- **ç¯å¢ƒå™ªéŸ³æ°´å¹³**: {noise_floor:.6f}

## å¤„ç†å»ºè®®

### é™å™ªå¤„ç†
- **æ¨èå¼ºåº¦**: {noise_reduction_needed}

### å‡è¡¡å™¨è°ƒæ•´
"""
        
        eq_adj = analysis_result['processing_recommendations']['eq_adjustments']
        if eq_adj['bass_cut']:
            markdown_content += "- âœ… å»ºè®®è¿›è¡Œä½é¢‘è¡°å‡\n"
        if eq_adj['speech_boost']:
            markdown_content += "- âœ… å»ºè®®å¢å¼ºäººå£°é¢‘æ®µ\n"
        if eq_adj['presence_boost']:
            markdown_content += "- âœ… å»ºè®®æå‡å­˜åœ¨æ„Ÿé¢‘æ®µ\n"
        
        dynamics = analysis_result['processing_recommendations']['dynamics_processing']
        markdown_content += f"""
### åŠ¨æ€å¤„ç†
- **éœ€è¦å‹ç¼©**: {'æ˜¯' if dynamics['compression_needed'] else 'å¦'}
- **éœ€è¦é™å¹…**: {'æ˜¯' if dynamics['limiting_needed'] else 'å¦'}

## ç»“è®º

åŸºäºå¯¹è¯å‰§éŸ³é¢‘å‰{duration:.1f}ç§’çš„åˆ†æï¼Œè¯¥éŸ³é¢‘æ–‡ä»¶çš„æ•´ä½“è´¨é‡ä¸º **{overall_quality}**ã€‚

ä¸»è¦å»ºè®®ï¼š
1. åº”ç”¨ **{noise_reduction_needed}** å¼ºåº¦çš„é™å™ªå¤„ç†
2. {'è¿›è¡ŒEQè°ƒæ•´ä»¥ä¼˜åŒ–äººå£°æ¸…æ™°åº¦' if eq_needed else 'å½“å‰é¢‘ç‡åˆ†å¸ƒè¾ƒä¸ºåˆç†'}
3. {'åº”ç”¨åŠ¨æ€å‹ç¼©ä»¥å¹³è¡¡éŸ³é‡å˜åŒ–' if compression_needed else 'åŠ¨æ€èŒƒå›´é€‚ä¸­'}

---
*æœ¬æŠ¥å‘ŠåŸºäºTask 7.1çš„éŸ³é¢‘è´¨é‡åˆ†æè¦æ±‚ç”Ÿæˆ*
"""
        
        markdown_file = workspace / "task_7_1_audio_quality_assessment_report.md"
        with open(markdown_file, 'w', encoding='utf-8') as f:
            f.write(markdown_content)
        
        print(f"  âœ… MarkdownæŠ¥å‘Šå·²ä¿å­˜: {markdown_file}")
        
        print(f"\nğŸ‰ Task 7.1 éŸ³é¢‘è´¨é‡åˆ†æå®Œæˆ!")
        print(f"ğŸ“Š ä¸»è¦ç»“æœ:")
        print(f"  - æ•´ä½“è´¨é‡: {overall_quality}")
        print(f"  - ä¼°ç®—SNR: {snr_estimate:.1f}dB")
        print(f"  - åŠ¨æ€èŒƒå›´: {dynamic_range_db:.1f}dB")
        print(f"  - è¯­éŸ³æ´»åŠ¨: {speech_ratio:.1%}")
        print(f"ğŸ“ æ‰€æœ‰æŠ¥å‘Šæ–‡ä»¶å·²ä¿å­˜åˆ°: {workspace}/")
        
        return analysis_result
        
    except Exception as e:
        print(f"âŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return None

if __name__ == "__main__":
    analyze_theater_audio_simple()