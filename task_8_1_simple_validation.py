#!/usr/bin/env python3
"""
ä»»åŠ¡8.1: éŸ³é¢‘å¢å¼ºæ•ˆæœåˆ†æ - ç®€åŒ–ç‰ˆæœ¬
å¿«é€Ÿå®ŒæˆéŸ³é¢‘è´¨é‡éªŒè¯å’Œå¯¹æ¯”åˆ†æ
"""

import os
import json
import numpy as np
import matplotlib
matplotlib.use('Agg')  # ä½¿ç”¨éäº¤äº’å¼åç«¯
import matplotlib.pyplot as plt
from pathlib import Path
from datetime import datetime
import librosa
import librosa.display

def analyze_audio_simple(audio_path):
    """ç®€åŒ–çš„éŸ³é¢‘åˆ†æ"""
    print(f"ğŸµ åˆ†æéŸ³é¢‘: {audio_path}")
    
    # åŠ è½½éŸ³é¢‘
    y, sr = librosa.load(str(audio_path), sr=None)
    duration = len(y) / sr
    
    # åŸºæœ¬ç»Ÿè®¡
    rms_energy = np.sqrt(np.mean(y**2))
    peak_amplitude = np.max(np.abs(y))
    dynamic_range = 20 * np.log10(peak_amplitude / (rms_energy + 1e-10))
    
    # é¢‘è°±åˆ†æ
    spectral_centroid = librosa.feature.spectral_centroid(y=y, sr=sr)[0]
    
    # ç®€å•SNRä¼°è®¡
    stft = librosa.stft(y)
    magnitude = np.abs(stft)
    sorted_magnitude = np.sort(magnitude.flatten())
    noise_floor = np.mean(sorted_magnitude[:int(len(sorted_magnitude) * 0.1)])
    signal_power = np.mean(magnitude)
    snr_estimate = 20 * np.log10(signal_power / (noise_floor + 1e-10))
    
    return {
        "duration": duration,
        "rms_energy": rms_energy,
        "peak_amplitude": peak_amplitude,
        "dynamic_range_db": dynamic_range,
        "spectral_centroid_mean": np.mean(spectral_centroid),
        "estimated_snr_db": snr_estimate
    }, y, sr

def create_comparison_plot(original_data, enhanced_data, original_sr, enhanced_sr):
    """åˆ›å»ºå¯¹æ¯”å›¾"""
    print("ğŸ“Š ç”Ÿæˆå¯¹æ¯”å›¾...")
    
    fig, axes = plt.subplots(2, 2, figsize=(12, 8))
    fig.suptitle('éŸ³é¢‘å¢å¼ºæ•ˆæœå¯¹æ¯”', fontsize=14)
    
    # é¢‘è°±å›¾å¯¹æ¯”
    D_orig = librosa.amplitude_to_db(np.abs(librosa.stft(original_data)), ref=np.max)
    D_enh = librosa.amplitude_to_db(np.abs(librosa.stft(enhanced_data)), ref=np.max)
    
    librosa.display.specshow(D_orig, sr=original_sr, x_axis='time', y_axis='hz', ax=axes[0,0])
    axes[0,0].set_title('åŸå§‹éŸ³é¢‘é¢‘è°±')
    
    librosa.display.specshow(D_enh, sr=enhanced_sr, x_axis='time', y_axis='hz', ax=axes[0,1])
    axes[0,1].set_title('å¢å¼ºéŸ³é¢‘é¢‘è°±')
    
    # é¢‘ç‡å“åº”å¯¹æ¯”
    freqs_orig = np.fft.rfftfreq(len(original_data), 1/original_sr)
    fft_orig = np.abs(np.fft.rfft(original_data))
    freqs_enh = np.fft.rfftfreq(len(enhanced_data), 1/enhanced_sr)
    fft_enh = np.abs(np.fft.rfft(enhanced_data))
    
    axes[1,0].semilogx(freqs_orig, 20*np.log10(fft_orig + 1e-10), label='åŸå§‹', alpha=0.7)
    axes[1,0].semilogx(freqs_enh, 20*np.log10(fft_enh + 1e-10), label='å¢å¼º', alpha=0.7)
    axes[1,0].set_xlabel('é¢‘ç‡ (Hz)')
    axes[1,0].set_ylabel('å¹…åº¦ (dB)')
    axes[1,0].set_title('é¢‘ç‡å“åº”å¯¹æ¯”')
    axes[1,0].legend()
    axes[1,0].grid(True, alpha=0.3)
    
    # æ—¶åŸŸæ³¢å½¢å¯¹æ¯” (å‰5ç§’)
    max_samples_orig = min(len(original_data), int(5 * original_sr))
    max_samples_enh = min(len(enhanced_data), int(5 * enhanced_sr))
    
    time_orig = np.linspace(0, max_samples_orig/original_sr, max_samples_orig)
    time_enh = np.linspace(0, max_samples_enh/enhanced_sr, max_samples_enh)
    
    axes[1,1].plot(time_orig, original_data[:max_samples_orig], label='åŸå§‹', alpha=0.7, linewidth=0.5)
    axes[1,1].plot(time_enh, enhanced_data[:max_samples_enh], label='å¢å¼º', alpha=0.7, linewidth=0.5)
    axes[1,1].set_xlabel('æ—¶é—´ (ç§’)')
    axes[1,1].set_ylabel('å¹…åº¦')
    axes[1,1].set_title('æ³¢å½¢å¯¹æ¯” (å‰5ç§’)')
    axes[1,1].legend()
    axes[1,1].grid(True, alpha=0.3)
    
    plt.tight_layout()
    
    plot_path = "task_8_1_audio_comparison.png"
    plt.savefig(plot_path, dpi=150, bbox_inches='tight')
    plt.close()
    
    print(f"âœ… å¯¹æ¯”å›¾å·²ä¿å­˜: {plot_path}")
    return plot_path

def main():
    print("ğŸš€ å¼€å§‹ä»»åŠ¡8.1: éŸ³é¢‘å¢å¼ºæ•ˆæœåˆ†æ")
    
    # æ–‡ä»¶è·¯å¾„
    original_audio = Path("audio_workspace/original_audio.wav")
    enhanced_audio = Path("audio_workspace/acoustics_optimized_audio.wav")
    
    # åˆ†æåŸå§‹éŸ³é¢‘
    orig_analysis, orig_data, orig_sr = analyze_audio_simple(original_audio)
    
    # åˆ†æå¢å¼ºéŸ³é¢‘
    enh_analysis, enh_data, enh_sr = analyze_audio_simple(enhanced_audio)
    
    # è®¡ç®—æ”¹å–„æŒ‡æ ‡
    snr_improvement = enh_analysis["estimated_snr_db"] - orig_analysis["estimated_snr_db"]
    dr_improvement = enh_analysis["dynamic_range_db"] - orig_analysis["dynamic_range_db"]
    centroid_change = enh_analysis["spectral_centroid_mean"] - orig_analysis["spectral_centroid_mean"]
    
    # ç”Ÿæˆå¯¹æ¯”å›¾
    plot_path = create_comparison_plot(orig_data, enh_data, orig_sr, enh_sr)
    
    # ç”ŸæˆæŠ¥å‘Š
    report = {
        "task": "8.1 Audio enhancement effectiveness analysis",
        "timestamp": datetime.now().isoformat(),
        "original_audio": {
            "file": str(original_audio),
            "duration_seconds": orig_analysis["duration"],
            "dynamic_range_db": orig_analysis["dynamic_range_db"],
            "estimated_snr_db": orig_analysis["estimated_snr_db"],
            "spectral_centroid_hz": orig_analysis["spectral_centroid_mean"]
        },
        "enhanced_audio": {
            "file": str(enhanced_audio),
            "duration_seconds": enh_analysis["duration"],
            "dynamic_range_db": enh_analysis["dynamic_range_db"],
            "estimated_snr_db": enh_analysis["estimated_snr_db"],
            "spectral_centroid_hz": enh_analysis["spectral_centroid_mean"]
        },
        "improvements": {
            "snr_improvement_db": snr_improvement,
            "dynamic_range_improvement_db": dr_improvement,
            "spectral_centroid_change_hz": centroid_change
        },
        "assessment": {
            "snr_status": "æ”¹å–„" if snr_improvement > 1 else "è½»å¾®æ”¹å–„" if snr_improvement > 0 else "æ— æ˜æ˜¾æ”¹å–„",
            "dynamic_range_status": "æ”¹å–„" if dr_improvement > 1 else "è½»å¾®æ”¹å–„" if dr_improvement > 0 else "æ— æ˜æ˜¾æ”¹å–„",
            "overall_quality": "æ˜¾è‘—æ”¹å–„" if (snr_improvement > 3 and dr_improvement > 2) else "ä¸­ç­‰æ”¹å–„" if (snr_improvement > 1 or dr_improvement > 1) else "è½»å¾®æ”¹å–„"
        },
        "visualization": plot_path
    }
    
    # ä¿å­˜æŠ¥å‘Š
    report_path = "task_8_1_audio_enhancement_report.json"
    with open(report_path, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    # æ‰“å°ç»“æœ
    print("\nğŸ“Š éŸ³é¢‘å¢å¼ºæ•ˆæœåˆ†æç»“æœ:")
    print(f"   SNRæ”¹å–„: {snr_improvement:.1f}dB ({report['assessment']['snr_status']})")
    print(f"   åŠ¨æ€èŒƒå›´æ”¹å–„: {dr_improvement:.1f}dB ({report['assessment']['dynamic_range_status']})")
    print(f"   é¢‘è°±é‡å¿ƒå˜åŒ–: {centroid_change:.1f}Hz")
    print(f"   æ•´ä½“è´¨é‡è¯„ä¼°: {report['assessment']['overall_quality']}")
    print(f"   æŠ¥å‘Šæ–‡ä»¶: {report_path}")
    print(f"   å¯¹æ¯”å›¾: {plot_path}")
    
    print("\nâœ… ä»»åŠ¡8.1å®Œæˆ: éŸ³é¢‘å¢å¼ºæ•ˆæœåˆ†æ")
    return True

if __name__ == "__main__":
    main()