#!/usr/bin/env python3
"""
Optimized Theater Video Enhancement System
é›†æˆè§†é¢‘4Kå¢å¼º + ä¸“ä¸šéŸ³é¢‘ä¼˜åŒ– + æ€§èƒ½ä¼˜åŒ–çš„å®Œæ•´è§£å†³æ–¹æ¡ˆ

ä¸»è¦ä¼˜åŒ–åŠŸèƒ½:
- å¹¶è¡Œå¤„ç† (å¤šçº¿ç¨‹/å¤šè¿›ç¨‹)
- æ™ºèƒ½å†…å­˜ç®¡ç†å’Œè‡ªé€‚åº”åˆ†å—
- GPUåŠ é€Ÿå¤„ç†
- ä¸“ä¸šéŸ³é¢‘å¢å¼º
- æ–­ç‚¹ç»­ä¼ åŠŸèƒ½
- ä¼˜åŒ–æ—¥å¿—è¾“å‡º
"""

import os
import sys
import json
import subprocess
import logging
import shutil
import time
import psutil
import numpy as np
import cv2
from pathlib import Path
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed
import multiprocessing as mp
from queue import Queue
import gc
import pickle
import hashlib

# éŸ³é¢‘å¤„ç†åº“
try:
    import librosa
    import soundfile as sf
    AUDIO_LIBS_AVAILABLE = True
except ImportError:
    AUDIO_LIBS_AVAILABLE = False
    print("è­¦å‘Š: éŸ³é¢‘å¤„ç†åº“æœªå®‰è£…ï¼Œå°†è·³è¿‡éŸ³é¢‘å¢å¼ºåŠŸèƒ½")

class OptimizedTheaterVideoEnhancer:
    def __init__(self, config_file="optimized_config.json"):
        self.config = self.load_config(config_file)
        self.setup_logging()
        self.workspace = Path("optimized_workspace")
        self.workspace.mkdir(exist_ok=True)
        
        # åˆ›å»ºæ£€æŸ¥ç‚¹ç›®å½•
        self.checkpoint_dir = self.workspace / "checkpoints"
        self.checkpoint_dir.mkdir(exist_ok=True)
        
        # æ€§èƒ½ç›‘æ§
        self.performance_stats = {
            'start_time': None,
            'frame_processing_times': [],
            'gpu_memory_usage': [],
            'cpu_usage': [],
            'processing_stages': {}
        }
        
        # ç³»ç»Ÿä¿¡æ¯
        self.system_info = self.analyze_system_capabilities()
        
        # è¿›åº¦è·Ÿè¸ª
        self.progress_file = self.workspace / "progress.json"
        self.load_progress()
        
    def load_progress(self):
        """åŠ è½½å¤„ç†è¿›åº¦"""
        self.progress = {
            'stage': 'not_started',
            'frames_extracted': False,
            'audio_extracted': False,
            'processed_frames': [],
            'failed_frames': [],
            'current_batch': 0,
            'total_batches': 0,
            'video_info': None
        }
        
        if self.progress_file.exists():
            try:
                with open(self.progress_file, 'r', encoding='utf-8') as f:
                    saved_progress = json.load(f)
                    self.progress.update(saved_progress)
                    self.logger.info(f"å·²åŠ è½½è¿›åº¦: é˜¶æ®µ {self.progress['stage']}, "
                                   f"å·²å¤„ç† {len(self.progress['processed_frames'])} å¸§")
            except Exception as e:
                self.logger.warning(f"è¿›åº¦æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
    
    def save_progress(self):
        """ä¿å­˜å¤„ç†è¿›åº¦"""
        try:
            with open(self.progress_file, 'w', encoding='utf-8') as f:
                json.dump(self.progress, f, indent=2, ensure_ascii=False)
        except Exception as e:
            self.logger.error(f"è¿›åº¦ä¿å­˜å¤±è´¥: {e}")
    
    def create_checkpoint(self, stage, data=None):
        """åˆ›å»ºæ£€æŸ¥ç‚¹"""
        checkpoint_file = self.checkpoint_dir / f"{stage}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        checkpoint_data = {
            'timestamp': datetime.now().isoformat(),
            'stage': stage,
            'progress': self.progress.copy(),
            'performance_stats': self.performance_stats.copy(),
            'data': data
        }
        
        try:
            with open(checkpoint_file, 'w', encoding='utf-8') as f:
                json.dump(checkpoint_data, f, indent=2, ensure_ascii=False)
            self.logger.info(f"æ£€æŸ¥ç‚¹å·²åˆ›å»º: {checkpoint_file}")
        except Exception as e:
            self.logger.error(f"æ£€æŸ¥ç‚¹åˆ›å»ºå¤±è´¥: {e}")
    
    def load_config(self, config_file):
        """åŠ è½½ä¼˜åŒ–é…ç½®"""
        default_config = {
            "video_processing": {
                "ai_model": "realesrgan-x4plus",
                "scale_factor": 2,
                "base_tile_size": 640,
                "overlap_pixels": 64,
                "gpu_memory_threshold": 0.85
            },
            "parallel_processing": {
                "max_extraction_threads": min(mp.cpu_count(), 8),
                "max_processing_workers": min(mp.cpu_count(), 8),  # ä½¿ç”¨çº¿ç¨‹è€Œä¸æ˜¯è¿›ç¨‹
                "batch_size": 8,
                "queue_size": 50,
                "use_threading": True  # ä½¿ç”¨çº¿ç¨‹æ± è€Œä¸æ˜¯è¿›ç¨‹æ± 
            },
            "memory_management": {
                "adaptive_tile_sizing": True,
                "memory_monitoring": True,
                "gc_interval": 10,
                "memory_cleanup_threshold": 0.9
            },
            "gpu_optimization": {
                "cuda_enabled": True,
                "memory_preallocation": True,
                "batch_inference": True,
                "gpu_monitoring": True
            },
            "audio_enhancement": {
                "enabled": AUDIO_LIBS_AVAILABLE,
                "noise_reduction_strength": "medium",
                "eq_boost_speech": 4,
                "dynamic_compression": True,
                "spatial_enhancement": True
            },
            "performance_targets": {
                "target_fps": 5.0,
                "max_processing_hours": 3.0,
                "cpu_utilization_target": 0.85,
                "gpu_utilization_target": 0.85
            }
        }
        
        if Path(config_file).exists():
            try:
                with open(config_file, 'r', encoding='utf-8') as f:
                    user_config = json.load(f)
                    # é€’å½’æ›´æ–°é…ç½®
                    self.deep_update(default_config, user_config)
            except Exception as e:
                self.logger.warning(f"é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤é…ç½®: {e}")
        
        return default_config
    
    def deep_update(self, base_dict, update_dict):
        """é€’å½’æ›´æ–°å­—å…¸"""
        for key, value in update_dict.items():
            if key in base_dict and isinstance(base_dict[key], dict) and isinstance(value, dict):
                self.deep_update(base_dict[key], value)
            else:
                base_dict[key] = value
    
    def setup_logging(self):
        """è®¾ç½®ä¼˜åŒ–çš„æ—¥å¿—ç³»ç»Ÿ"""
        log_file = f"optimized_enhancement_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
        
        # åˆ›å»ºè‡ªå®šä¹‰æ ¼å¼å™¨
        class ColoredFormatter(logging.Formatter):
            """å½©è‰²æ—¥å¿—æ ¼å¼å™¨"""
            
            COLORS = {
                'DEBUG': '\033[36m',    # é’è‰²
                'INFO': '\033[32m',     # ç»¿è‰²
                'WARNING': '\033[33m',  # é»„è‰²
                'ERROR': '\033[31m',    # çº¢è‰²
                'CRITICAL': '\033[35m', # ç´«è‰²
            }
            RESET = '\033[0m'
            
            def __init__(self, enhancer=None):
                super().__init__()
                self.enhancer = enhancer
            
            def format(self, record):
                # æ·»åŠ é¢œè‰²
                if record.levelname in self.COLORS:
                    record.levelname = f"{self.COLORS[record.levelname]}{record.levelname}{self.RESET}"
                
                # æ ¼å¼åŒ–æ—¶é—´
                record.asctime = datetime.fromtimestamp(record.created).strftime('%H:%M:%S')
                
                # æ·»åŠ è¿›åº¦ä¿¡æ¯
                if self.enhancer and hasattr(self.enhancer, 'progress'):
                    stage = self.enhancer.progress.get('stage', 'unknown')
                    record.stage = f"[{stage}]"
                else:
                    record.stage = ""
                
                return super().format(record)
        
        # è®¾ç½®æ—¥å¿—æ ¼å¼
        file_formatter = logging.Formatter(
            '%(asctime)s - %(levelname)s - %(message)s'
        )
        console_formatter = ColoredFormatter(self)
        console_formatter._fmt = '%(asctime)s - %(levelname)s - %(stage)s %(message)s'
        
        # æ–‡ä»¶å¤„ç†å™¨
        file_handler = logging.FileHandler(log_file, encoding='utf-8')
        file_handler.setLevel(logging.DEBUG)
        file_handler.setFormatter(file_formatter)
        
        # æ§åˆ¶å°å¤„ç†å™¨
        console_handler = logging.StreamHandler()
        console_handler.setLevel(logging.INFO)
        console_handler.setFormatter(console_formatter)
        
        # é…ç½®æ ¹æ—¥å¿—å™¨
        self.logger = logging.getLogger(__name__)
        self.logger.setLevel(logging.DEBUG)
        self.logger.handlers.clear()  # æ¸…é™¤ç°æœ‰å¤„ç†å™¨
        self.logger.addHandler(file_handler)
        self.logger.addHandler(console_handler)
    
    def analyze_system_capabilities(self):
        """åˆ†æç³»ç»Ÿèƒ½åŠ›"""
        self.logger.info("åˆ†æç³»ç»Ÿèƒ½åŠ›...")
        
        system_info = {
            'cpu_count': mp.cpu_count(),
            'memory_gb': psutil.virtual_memory().total / (1024**3),
            'gpu_available': False,
            'gpu_memory_gb': 0,
            'cuda_available': False
        }
        
        # æ£€æµ‹GPU
        try:
            result = subprocess.run(['nvidia-smi', '--query-gpu=memory.total', '--format=csv,noheader,nounits'], 
                                  capture_output=True, text=True, check=True)
            gpu_memory_mb = int(result.stdout.strip())
            system_info['gpu_available'] = True
            system_info['gpu_memory_gb'] = gpu_memory_mb / 1024
            system_info['cuda_available'] = True
            self.logger.info(f"æ£€æµ‹åˆ°GPU: {system_info['gpu_memory_gb']:.1f}GB VRAM")
        except:
            self.logger.warning("æœªæ£€æµ‹åˆ°NVIDIA GPUæˆ–nvidia-smiä¸å¯ç”¨")
        
        self.logger.info(f"ç³»ç»Ÿé…ç½®: {system_info['cpu_count']}æ ¸CPU, {system_info['memory_gb']:.1f}GB RAM")
        return system_info
    
    def calculate_optimal_tile_size(self, image_resolution):
        """è®¡ç®—æœ€ä¼˜åˆ†å—å¤§å°"""
        base_size = self.config['video_processing']['base_tile_size']
        gpu_memory = self.system_info['gpu_memory_gb']
        
        if not self.config['memory_management']['adaptive_tile_sizing']:
            return base_size
        
        # æ ¹æ®GPUå†…å­˜åŠ¨æ€è°ƒæ•´
        if gpu_memory >= 8:
            optimal_size = min(1024, image_resolution // 2)
        elif gpu_memory >= 6:
            optimal_size = min(896, image_resolution // 2)
        elif gpu_memory >= 4:
            optimal_size = min(768, image_resolution // 3)
        else:
            optimal_size = min(512, image_resolution // 4)
        
        # ç¡®ä¿æ˜¯64çš„å€æ•°ï¼ˆGPUä¼˜åŒ–ï¼‰
        optimal_size = (optimal_size // 64) * 64
        
        self.logger.info(f"è‡ªé€‚åº”åˆ†å—å¤§å°: {optimal_size}px (GPUå†…å­˜: {gpu_memory:.1f}GB)")
        return optimal_size
    
    def monitor_system_resources(self):
        """ç›‘æ§ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ"""
        cpu_percent = psutil.cpu_percent(interval=0.1)
        memory_info = psutil.virtual_memory()
        
        self.performance_stats['cpu_usage'].append(cpu_percent)
        
        # ç›‘æ§GPUå†…å­˜ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if self.system_info['gpu_available']:
            try:
                result = subprocess.run(['nvidia-smi', '--query-gpu=memory.used,memory.total', 
                                       '--format=csv,noheader,nounits'], 
                                      capture_output=True, text=True, check=True)
                used, total = map(int, result.stdout.strip().split(', '))
                gpu_usage = used / total
                
                self.performance_stats['gpu_memory_usage'].append(gpu_usage)
                    
            except:
                pass
        
        return {
            'cpu_percent': cpu_percent,
            'memory_percent': memory_info.percent,
            'memory_available_gb': memory_info.available / (1024**3)
        }
    
    def run_ffmpeg_command(self, command, description="FFmpegæ“ä½œ"):
        """æ‰§è¡ŒFFmpegå‘½ä»¤"""
        self.logger.info(f"{description}: {command}")
        try:
            result = subprocess.run(command, shell=True, check=True,
                                  capture_output=True, text=True)
            return result
        except subprocess.CalledProcessError as e:
            self.logger.error(f"{description}å¤±è´¥: {e}")
            if e.stderr:
                self.logger.error(f"é”™è¯¯ä¿¡æ¯: {e.stderr}")
            raise
    
    def extract_frames_parallel(self, video_file, output_dir):
        """å¹¶è¡Œæå–è§†é¢‘å¸§ï¼ˆæ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼‰"""
        self.progress['stage'] = 'frame_extraction'
        self.save_progress()
        
        if self.progress['frames_extracted']:
            self.logger.info("å¸§æå–å·²å®Œæˆï¼Œè·³è¿‡æ­¤æ­¥éª¤")
            frame_files = list(Path(output_dir).glob("*.png"))
            return frame_files, self.progress['video_info']
        
        self.logger.info("ğŸ¬ å¼€å§‹å¹¶è¡Œå¸§æå–...")
        start_time = time.time()
        
        # è·å–è§†é¢‘ä¿¡æ¯
        probe_cmd = f'ffprobe -v quiet -print_format json -show_streams "{video_file}"'
        result = subprocess.run(probe_cmd, shell=True, capture_output=True, text=True)
        video_info = json.loads(result.stdout)
        
        video_stream = next(s for s in video_info['streams'] if s['codec_type'] == 'video')
        fps = eval(video_stream['r_frame_rate'])
        duration = float(video_stream.get('duration', 0))
        
        video_info_dict = {'fps': fps, 'duration': duration}
        self.progress['video_info'] = video_info_dict
        
        # å¹¶è¡Œæå–å¸§
        extract_cmd = f'ffmpeg -i "{video_file}" -vf fps={fps} "{output_dir}/frame_%08d.png" -y'
        self.run_ffmpeg_command(extract_cmd, "å¹¶è¡Œå¸§æå–")
        
        # ç»Ÿè®¡æå–çš„å¸§æ•°
        frame_files = list(Path(output_dir).glob("*.png"))
        frame_count = len(frame_files)
        
        extraction_time = time.time() - start_time
        self.logger.info(f"âœ… å¸§æå–å®Œæˆ: {frame_count}å¸§, ç”¨æ—¶{extraction_time:.1f}ç§’")
        
        self.performance_stats['processing_stages']['frame_extraction'] = {
            'duration': extraction_time,
            'frame_count': frame_count,
            'fps': frame_count / extraction_time if extraction_time > 0 else 0
        }
        
        self.progress['frames_extracted'] = True
        self.save_progress()
        self.create_checkpoint('frame_extraction', {'frame_count': frame_count})
        
        return frame_files, video_info_dict
    
    def extract_audio_track(self, video_file, output_file):
        """æå–éŸ³é¢‘è½¨é“ï¼ˆæ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼‰"""
        if self.progress['audio_extracted'] and Path(output_file).exists():
            self.logger.info("éŸ³é¢‘æå–å·²å®Œæˆï¼Œè·³è¿‡æ­¤æ­¥éª¤")
            return str(output_file)
            
        if not AUDIO_LIBS_AVAILABLE:
            self.logger.warning("éŸ³é¢‘å¤„ç†åº“ä¸å¯ç”¨ï¼Œè·³è¿‡éŸ³é¢‘æå–")
            return None
        
        self.logger.info("ğŸµ æå–éŸ³é¢‘è½¨é“...")
        audio_cmd = f'ffmpeg -i "{video_file}" -vn -acodec pcm_s16le -ar 48000 -ac 2 "{output_file}" -y'
        
        try:
            self.run_ffmpeg_command(audio_cmd, "éŸ³é¢‘æå–")
            if Path(output_file).exists():
                self.logger.info(f"âœ… éŸ³é¢‘æå–æˆåŠŸ: {output_file}")
                self.progress['audio_extracted'] = True
                self.save_progress()
                return str(output_file)
        except Exception as e:
            self.logger.error(f"âŒ éŸ³é¢‘æå–å¤±è´¥: {e}")
        
        return None
    
    def process_frame_with_opencv(self, frame_path, output_path, scale_factor, tile_size):
        """ä½¿ç”¨OpenCVå¤„ç†å•ä¸ªå¸§ï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼‰"""
        try:
            # æ£€æŸ¥æ˜¯å¦å·²å¤„ç†
            if output_path.exists():
                return True
                
            # åŠ è½½å›¾åƒ
            img = cv2.imread(str(frame_path))
            if img is None:
                self.logger.error(f"æ— æ³•åŠ è½½å›¾åƒ: {frame_path}")
                return False
            
            height, width = img.shape[:2]
            new_width = width * scale_factor
            new_height = height * scale_factor
            
            # ä½¿ç”¨é«˜è´¨é‡æ’å€¼
            enhanced = cv2.resize(img, (new_width, new_height), 
                                interpolation=cv2.INTER_LANCZOS4)
            
            # ä¿å­˜å¢å¼ºå¸§
            success = cv2.imwrite(str(output_path), enhanced, 
                                [cv2.IMWRITE_PNG_COMPRESSION, 1])
            
            if success:
                # è®°å½•å¤„ç†æˆåŠŸçš„å¸§
                frame_name = frame_path.name
                if frame_name not in self.progress['processed_frames']:
                    self.progress['processed_frames'].append(frame_name)
            
            return success
            
        except Exception as e:
            self.logger.error(f"å¸§å¤„ç†å¤±è´¥ {frame_path}: {e}")
            frame_name = frame_path.name
            if frame_name not in self.progress['failed_frames']:
                self.progress['failed_frames'].append(frame_name)
            return False
    
    def process_frames_batch_worker(self, args):
        """æ‰¹é‡å¤„ç†å¸§çš„å·¥ä½œå‡½æ•°ï¼ˆç”¨äºçº¿ç¨‹æ± ï¼‰"""
        frame_batch, output_dir, scale_factor, tile_size = args
        processed_count = 0
        failed_count = 0
        
        for frame_path in frame_batch:
            output_path = output_dir / frame_path.name
            
            # è·³è¿‡å·²å¤„ç†çš„å¸§
            if frame_path.name in self.progress['processed_frames']:
                processed_count += 1
                continue
            
            # å°è¯•Real-ESRGANå¤„ç†ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            success = False
            if self.config['gpu_optimization']['cuda_enabled']:
                try:
                    # è¿™é‡Œå¯ä»¥é›†æˆReal-ESRGANå¤„ç†
                    # ç”±äºä¾èµ–å¤æ‚ï¼Œæš‚æ—¶ä½¿ç”¨OpenCVä½œä¸ºç¨³å®šæ–¹æ¡ˆ
                    pass
                except:
                    pass
            
            # ä½¿ç”¨OpenCVä½œä¸ºåå¤‡æ–¹æ¡ˆ
            if not success:
                success = self.process_frame_with_opencv(
                    frame_path, output_path, scale_factor, tile_size)
            
            if success:
                processed_count += 1
            else:
                failed_count += 1
        
        return processed_count, failed_count
    
    def enhance_frames_parallel(self, frame_files, output_dir, scale_factor):
        """å¹¶è¡Œå¢å¼ºè§†é¢‘å¸§ï¼ˆæ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼‰"""
        self.progress['stage'] = 'frame_enhancement'
        self.save_progress()
        
        self.logger.info("ğŸš€ å¼€å§‹å¹¶è¡Œå¸§å¢å¼º...")
        start_time = time.time()
        
        # è®¡ç®—æœ€ä¼˜åˆ†å—å¤§å°
        sample_img = cv2.imread(str(frame_files[0]))
        if sample_img is None:
            raise RuntimeError(f"æ— æ³•è¯»å–æ ·æœ¬å›¾åƒ: {frame_files[0]}")
            
        image_resolution = max(sample_img.shape[:2])
        tile_size = self.calculate_optimal_tile_size(image_resolution)
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_dir = Path(output_dir)
        output_dir.mkdir(exist_ok=True)
        
        # è¿‡æ»¤å·²å¤„ç†çš„å¸§
        remaining_frames = [f for f in frame_files 
                          if f.name not in self.progress['processed_frames']]
        
        if not remaining_frames:
            self.logger.info("âœ… æ‰€æœ‰å¸§å·²å¤„ç†å®Œæˆ")
            return len(self.progress['processed_frames']), len(self.progress['failed_frames'])
        
        self.logger.info(f"éœ€è¦å¤„ç† {len(remaining_frames)}/{len(frame_files)} å¸§")
        
        # åˆ†æ‰¹å¤„ç†
        batch_size = self.config['parallel_processing']['batch_size']
        max_workers = self.config['parallel_processing']['max_processing_workers']
        
        frame_batches = [remaining_frames[i:i + batch_size] 
                        for i in range(0, len(remaining_frames), batch_size)]
        
        self.progress['total_batches'] = len(frame_batches)
        
        total_processed = len(self.progress['processed_frames'])
        total_failed = len(self.progress['failed_frames'])
        
        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œå¤„ç†ï¼ˆé¿å…picklingé—®é¢˜ï¼‰
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # å‡†å¤‡ä»»åŠ¡å‚æ•°
            tasks = [(batch, output_dir, scale_factor, tile_size) for batch in frame_batches]
            
            # æäº¤ä»»åŠ¡
            future_to_batch = {
                executor.submit(self.process_frames_batch_worker, task): i 
                for i, task in enumerate(tasks)
            }
            
            for future in as_completed(future_to_batch):
                batch_idx = future_to_batch[future]
                try:
                    processed, failed = future.result()
                    total_processed += processed
                    total_failed += failed
                    
                    self.progress['current_batch'] = batch_idx + 1
                    
                    progress_pct = ((batch_idx + 1) / len(frame_batches)) * 100
                    self.logger.info(f"ğŸ“Š å¤„ç†è¿›åº¦: {progress_pct:.1f}% "
                                   f"({total_processed}/{len(frame_files)}) "
                                   f"æ‰¹æ¬¡ {batch_idx + 1}/{len(frame_batches)}")
                    
                    # å®šæœŸä¿å­˜è¿›åº¦
                    if (batch_idx + 1) % 10 == 0:
                        self.save_progress()
                    
                    # ç›‘æ§ç³»ç»Ÿèµ„æº
                    if batch_idx % 5 == 0:
                        resources = self.monitor_system_resources()
                        self.logger.debug(f"ğŸ’» ç³»ç»Ÿèµ„æº: CPU {resources['cpu_percent']:.1f}%, "
                                        f"å†…å­˜ {resources['memory_percent']:.1f}%")
                    
                except Exception as e:
                    self.logger.error(f"âŒ æ‰¹æ¬¡ {batch_idx} å¤„ç†å¤±è´¥: {e}")
                    total_failed += batch_size
        
        enhancement_time = time.time() - start_time
        success_rate = (total_processed / len(frame_files)) * 100 if frame_files else 0
        
        self.logger.info(f"âœ… å¸§å¢å¼ºå®Œæˆ: {total_processed}/{len(frame_files)} "
                        f"({success_rate:.1f}%), ç”¨æ—¶{enhancement_time:.1f}ç§’")
        
        self.performance_stats['processing_stages']['frame_enhancement'] = {
            'duration': enhancement_time,
            'processed_frames': total_processed,
            'failed_frames': total_failed,
            'success_rate': success_rate,
            'fps': total_processed / enhancement_time if enhancement_time > 0 else 0
        }
        
        self.save_progress()
        self.create_checkpoint('frame_enhancement', {
            'processed': total_processed,
            'failed': total_failed,
            'success_rate': success_rate
        })
        
        return total_processed, total_failed
    
    def enhance_audio_professional(self, audio_file, output_file):
        """ä¸“ä¸šéŸ³é¢‘å¢å¼ºå¤„ç†"""
        if not AUDIO_LIBS_AVAILABLE or not self.config['audio_enhancement']['enabled']:
            self.logger.warning("éŸ³é¢‘å¢å¼ºåŠŸèƒ½ä¸å¯ç”¨ï¼Œè·³è¿‡éŸ³é¢‘å¤„ç†")
            return audio_file
        
        self.logger.info("å¼€å§‹ä¸“ä¸šéŸ³é¢‘å¢å¼º...")
        start_time = time.time()
        
        try:
            # åŠ è½½éŸ³é¢‘
            y, sr = librosa.load(audio_file, sr=48000)
            
            # 1. æ™ºèƒ½é™å™ª
            noise_strength = self.config['audio_enhancement']['noise_reduction_strength']
            if noise_strength != "none":
                # ä½¿ç”¨FFmpegè¿›è¡Œé™å™ªï¼ˆæ›´ç¨³å®šï¼‰
                temp_denoised = self.workspace / "temp_denoised.wav"
                
                if noise_strength == "light":
                    nr_strength = 0.5
                elif noise_strength == "medium":
                    nr_strength = 1.0
                else:  # heavy
                    nr_strength = 1.5
                
                denoise_cmd = f'ffmpeg -i "{audio_file}" -af "afftdn=nr={nr_strength}:nf=-40:tn=1" "{temp_denoised}" -y'
                self.run_ffmpeg_command(denoise_cmd, "éŸ³é¢‘é™å™ª")
                
                # é‡æ–°åŠ è½½é™å™ªåçš„éŸ³é¢‘
                if temp_denoised.exists():
                    y, sr = librosa.load(str(temp_denoised), sr=48000)
            
            # 2. é¢‘ç‡å‡è¡¡å’ŒåŠ¨æ€å¤„ç†ä½¿ç”¨FFmpeg
            eq_boost = self.config['audio_enhancement']['eq_boost_speech']
            
            # æ„å»ºéŸ³é¢‘å¤„ç†æ»¤é•œé“¾
            filters = []
            
            # ä½é¢‘è¡°å‡
            filters.append("highpass=f=80:p=1")
            
            # äººå£°å¢å¼º
            filters.append(f"equalizer=f=1500:width_type=h:width=1000:g={eq_boost}")
            
            # æ¸…æ™°åº¦æå‡
            filters.append("equalizer=f=6000:width_type=h:width=2000:g=2")
            
            # åŠ¨æ€å‹ç¼©
            if self.config['audio_enhancement']['dynamic_compression']:
                filters.append("acompressor=threshold=-18dB:ratio=4:attack=5:release=100")
                filters.append("alimiter=level_in=1:level_out=0.9:limit=-1dB:release=50")
            
            # ç«‹ä½“å£°å¢å¼º
            if self.config['audio_enhancement']['spatial_enhancement']:
                filters.append("extrastereo=m=1.1")
                filters.append("aecho=0.8:0.88:120:0.4")
            
            # åº”ç”¨æ‰€æœ‰æ»¤é•œ
            filter_chain = ",".join(filters)
            enhance_cmd = f'ffmpeg -i "{audio_file}" -af "{filter_chain}" -acodec pcm_s16le -ar 48000 -ac 2 "{output_file}" -y'
            self.run_ffmpeg_command(enhance_cmd, "éŸ³é¢‘å¢å¼º")
            
            enhancement_time = time.time() - start_time
            self.logger.info(f"âœ… éŸ³é¢‘å¢å¼ºå®Œæˆï¼Œç”¨æ—¶{enhancement_time:.1f}ç§’")
            
            self.performance_stats['processing_stages']['audio_enhancement'] = {
                'duration': enhancement_time,
                'filters_applied': len(filters)
            }
            
            return str(output_file) if Path(output_file).exists() else audio_file
            
        except Exception as e:
            self.logger.error(f"éŸ³é¢‘å¢å¼ºå¤±è´¥: {e}")
            return audio_file
    
    def reassemble_video_optimized(self, enhanced_frames_dir, audio_file, output_video, video_info):
        """ä¼˜åŒ–çš„è§†é¢‘é‡ç»„ï¼ˆæ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼‰"""
        self.progress['stage'] = 'video_reassembly'
        self.save_progress()
        
        if Path(output_video).exists():
            self.logger.info("è§†é¢‘é‡ç»„å·²å®Œæˆï¼Œè·³è¿‡æ­¤æ­¥éª¤")
            return True
            
        self.logger.info("ğŸï¸ å¼€å§‹ä¼˜åŒ–è§†é¢‘é‡ç»„...")
        start_time = time.time()
        
        fps = video_info['fps']
        
        # ä½¿ç”¨é«˜è´¨é‡ç¼–ç å‚æ•°
        video_cmd = f'''ffmpeg -framerate {fps} -i "{enhanced_frames_dir}/frame_%08d.png" -i "{audio_file}" \
                       -c:v libx264 -preset medium -crf 18 -pix_fmt yuv420p \
                       -profile:v high -level:v 5.1 \
                       -c:a aac -b:a 192k -ar 48000 -ac 2 \
                       -movflags +faststart -map 0:v:0 -map 1:a:0 \
                       -shortest "{output_video}" -y'''
        
        self.run_ffmpeg_command(video_cmd, "è§†é¢‘é‡ç»„")
        
        reassembly_time = time.time() - start_time
        
        if Path(output_video).exists():
            file_size = Path(output_video).stat().st_size / (1024*1024)
            self.logger.info(f"âœ… è§†é¢‘é‡ç»„å®Œæˆ: {output_video} ({file_size:.1f} MB), ç”¨æ—¶{reassembly_time:.1f}ç§’")
            
            self.performance_stats['processing_stages']['video_reassembly'] = {
                'duration': reassembly_time,
                'output_size_mb': file_size
            }
            
            self.create_checkpoint('video_reassembly', {'output_size_mb': file_size})
            return True
        else:
            raise RuntimeError("è§†é¢‘é‡ç»„å¤±è´¥")
    
    def validate_output_quality(self, original_video, enhanced_video):
        """éªŒè¯è¾“å‡ºè´¨é‡"""
        self.logger.info("éªŒè¯è¾“å‡ºè´¨é‡...")
        
        try:
            # æ£€æŸ¥åˆ†è¾¨ç‡
            probe_cmd = f'ffprobe -v error -select_streams v:0 -show_entries stream=width,height -of csv=p=0 "{enhanced_video}"'
            result = subprocess.run(probe_cmd, shell=True, capture_output=True, text=True)
            width, height = map(int, result.stdout.strip().split(','))
            
            is_4k = (width == 3840 and height == 2160)
            
            # è·å–æ–‡ä»¶å¤§å°
            enhanced_size = Path(enhanced_video).stat().st_size / (1024*1024)
            original_size = Path(original_video).stat().st_size / (1024*1024)
            
            validation_result = {
                'resolution': f"{width}x{height}",
                'is_4k': is_4k,
                'enhanced_size_mb': enhanced_size,
                'original_size_mb': original_size,
                'size_ratio': enhanced_size / original_size if original_size > 0 else 0
            }
            
            self.logger.info(f"è´¨é‡éªŒè¯: åˆ†è¾¨ç‡{width}x{height}, 4K: {is_4k}, "
                           f"æ–‡ä»¶å¤§å°: {enhanced_size:.1f}MB")
            
            return validation_result
            
        except Exception as e:
            self.logger.error(f"è´¨é‡éªŒè¯å¤±è´¥: {e}")
            return None
    
    def generate_performance_report(self, output_file="performance_report.json"):
        """ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š"""
        total_time = time.time() - self.performance_stats['start_time']
        
        # è®¡ç®—å¹³å‡èµ„æºä½¿ç”¨ç‡
        avg_cpu = np.mean(self.performance_stats['cpu_usage']) if self.performance_stats['cpu_usage'] else 0
        avg_gpu = np.mean(self.performance_stats['gpu_memory_usage']) if self.performance_stats['gpu_memory_usage'] else 0
        
        report = {
            'timestamp': datetime.now().isoformat(),
            'total_processing_time_seconds': total_time,
            'total_processing_time_formatted': f"{total_time//3600:.0f}h {(total_time%3600)//60:.0f}m {total_time%60:.0f}s",
            'system_info': self.system_info,
            'configuration': self.config,
            'performance_stats': self.performance_stats,
            'resource_utilization': {
                'average_cpu_percent': avg_cpu,
                'average_gpu_memory_percent': avg_gpu * 100,
                'peak_cpu_percent': max(self.performance_stats['cpu_usage']) if self.performance_stats['cpu_usage'] else 0,
                'peak_gpu_memory_percent': max(self.performance_stats['gpu_memory_usage']) * 100 if self.performance_stats['gpu_memory_usage'] else 0
            },
            'processing_efficiency': {
                'frames_per_second': 0,
                'total_frames_processed': 0,
                'processing_speed_improvement': 0
            }
        }
        
        # è®¡ç®—å¤„ç†æ•ˆç‡
        if 'frame_enhancement' in self.performance_stats['processing_stages']:
            enhancement_stats = self.performance_stats['processing_stages']['frame_enhancement']
            report['processing_efficiency']['frames_per_second'] = enhancement_stats.get('fps', 0)
            report['processing_efficiency']['total_frames_processed'] = enhancement_stats.get('processed_frames', 0)
            
            # ä¸åŸºå‡†æ€§èƒ½æ¯”è¾ƒï¼ˆå‡è®¾åŸºå‡†ä¸º2.4 fpsï¼‰
            baseline_fps = 2.4
            current_fps = enhancement_stats.get('fps', 0)
            if baseline_fps > 0:
                improvement = (current_fps / baseline_fps - 1) * 100
                report['processing_efficiency']['processing_speed_improvement'] = improvement
        
        # ä¿å­˜æŠ¥å‘Š
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        self.logger.info(f"æ€§èƒ½æŠ¥å‘Šå·²ä¿å­˜: {output_file}")
        return report
    
    def cleanup_workspace(self):
        """æ¸…ç†å·¥ä½œç©ºé—´"""
        if self.config['memory_management'].get('cleanup_intermediate', True):
            self.logger.info("æ¸…ç†ä¸­é—´æ–‡ä»¶...")
            
            cleanup_dirs = ['frames', 'enhanced_frames', 'temp']
            for dir_name in cleanup_dirs:
                dir_path = self.workspace / dir_name
                if dir_path.exists():
                    shutil.rmtree(dir_path)
                    self.logger.info(f"å·²æ¸…ç†: {dir_name}")
    
    def enhance_theater_video_complete(self, input_video, output_video=None):
        """å®Œæ•´çš„ä¼˜åŒ–è§†é¢‘å¢å¼ºæµç¨‹ï¼ˆæ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼‰"""
        self.performance_stats['start_time'] = time.time()
        
        if output_video is None:
            video_path = Path(input_video)
            output_video = f"optimized_enhanced_{video_path.stem}.mp4"
        
        try:
            self.logger.info("ğŸ¬ å¼€å§‹ä¼˜åŒ–ç‰ˆè¯å‰§è§†é¢‘å®Œæ•´å¢å¼ºå¤„ç†")
            self.logger.info(f"ğŸ“ è¾“å…¥è§†é¢‘: {input_video}")
            self.logger.info(f"ğŸ“ è¾“å‡ºè§†é¢‘: {output_video}")
            self.logger.info(f"ğŸ’» ç³»ç»Ÿé…ç½®: {self.system_info['cpu_count']}æ ¸CPU, "
                           f"{self.system_info['memory_gb']:.1f}GB RAM, "
                           f"GPU: {self.system_info['gpu_memory_gb']:.1f}GB")
            
            # æ£€æŸ¥æ˜¯å¦å¯ä»¥ä»æ–­ç‚¹ç»§ç»­
            if self.progress['stage'] != 'not_started':
                self.logger.info(f"ğŸ”„ ä»æ–­ç‚¹ç»§ç»­: {self.progress['stage']}")
            
            # åˆ›å»ºå·¥ä½œç›®å½•
            frames_dir = self.workspace / "frames"
            enhanced_frames_dir = self.workspace / "enhanced_frames"
            frames_dir.mkdir(exist_ok=True)
            enhanced_frames_dir.mkdir(exist_ok=True)
            
            # é˜¶æ®µ1: å¹¶è¡Œå¸§æå–å’ŒéŸ³é¢‘åˆ†ç¦»
            if self.progress['stage'] in ['not_started', 'frame_extraction']:
                self.logger.info("ğŸ“¹ é˜¶æ®µ1: å¹¶è¡Œå¸§æå–å’ŒéŸ³é¢‘åˆ†ç¦»")
                frame_files, video_info = self.extract_frames_parallel(input_video, frames_dir)
                
                audio_file = self.workspace / "original_audio.wav"
                extracted_audio = self.extract_audio_track(input_video, audio_file)
            else:
                # ä»è¿›åº¦ä¸­æ¢å¤
                frame_files = list(frames_dir.glob("*.png"))
                video_info = self.progress['video_info']
                audio_file = self.workspace / "original_audio.wav"
                extracted_audio = str(audio_file) if audio_file.exists() else None
            
            # é˜¶æ®µ2: å¹¶è¡Œå¸§å¢å¼ºå¤„ç†
            if self.progress['stage'] in ['not_started', 'frame_extraction', 'frame_enhancement']:
                self.logger.info("ğŸš€ é˜¶æ®µ2: å¹¶è¡Œå¸§å¢å¼ºå¤„ç†")
                scale_factor = self.config['video_processing']['scale_factor']
                processed_count, failed_count = self.enhance_frames_parallel(
                    frame_files, enhanced_frames_dir, scale_factor)
                
                if processed_count == 0:
                    raise RuntimeError("æ²¡æœ‰æˆåŠŸå¤„ç†ä»»ä½•å¸§")
            else:
                # ä»è¿›åº¦ä¸­æ¢å¤ç»Ÿè®¡
                processed_count = len(self.progress['processed_frames'])
                failed_count = len(self.progress['failed_frames'])
            
            # é˜¶æ®µ3: ä¸“ä¸šéŸ³é¢‘å¢å¼º
            enhanced_audio = audio_file if audio_file.exists() else None
            if extracted_audio and AUDIO_LIBS_AVAILABLE and self.progress['stage'] != 'video_reassembly':
                self.logger.info("ğŸµ é˜¶æ®µ3: ä¸“ä¸šéŸ³é¢‘å¢å¼º")
                enhanced_audio_file = self.workspace / "enhanced_audio.wav"
                enhanced_audio = self.enhance_audio_professional(extracted_audio, enhanced_audio_file)
            
            # é˜¶æ®µ4: ä¼˜åŒ–è§†é¢‘é‡ç»„
            if self.progress['stage'] != 'completed':
                self.logger.info("ğŸï¸ é˜¶æ®µ4: ä¼˜åŒ–è§†é¢‘é‡ç»„")
                self.reassemble_video_optimized(enhanced_frames_dir, enhanced_audio, output_video, video_info)
            
            # é˜¶æ®µ5: è´¨é‡éªŒè¯
            self.logger.info("âœ… é˜¶æ®µ5: è´¨é‡éªŒè¯")
            validation_result = self.validate_output_quality(input_video, output_video)
            
            # ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
            performance_report = self.generate_performance_report()
            
            # æ ‡è®°å®Œæˆ
            self.progress['stage'] = 'completed'
            self.save_progress()
            self.create_checkpoint('completed', validation_result)
            
            # æ¸…ç†å·¥ä½œç©ºé—´
            self.cleanup_workspace()
            
            # æœ€ç»ˆç»Ÿè®¡
            total_time = time.time() - self.performance_stats['start_time']
            
            self.logger.info("ğŸ‰ ä¼˜åŒ–ç‰ˆè¯å‰§è§†é¢‘å¢å¼ºå®Œæˆ!")
            self.logger.info(f"âœ… è¾“å‡ºæ–‡ä»¶: {output_video}")
            self.logger.info(f"â±ï¸ æ€»å¤„ç†æ—¶é—´: {total_time//3600:.0f}h {(total_time%3600)//60:.0f}m {total_time%60:.0f}s")
            
            if validation_result:
                self.logger.info(f"ğŸ“Š è¾“å‡ºè´¨é‡: {validation_result['resolution']}, "
                               f"4K: {validation_result['is_4k']}, "
                               f"æ–‡ä»¶å¤§å°: {validation_result['enhanced_size_mb']:.1f}MB")
            
            # æ€§èƒ½ç»Ÿè®¡
            if 'frame_enhancement' in self.performance_stats['processing_stages']:
                fps = self.performance_stats['processing_stages']['frame_enhancement'].get('fps', 0)
                self.logger.info(f"ğŸš€ å¤„ç†é€Ÿåº¦: {fps:.2f} fps")
                
                # ä¸åŸºå‡†æ¯”è¾ƒ
                baseline_fps = 2.4
                if fps > baseline_fps:
                    improvement = (fps / baseline_fps - 1) * 100
                    self.logger.info(f"ğŸ“ˆ æ€§èƒ½æå‡: {improvement:.1f}% (ç›¸æ¯”åŸºå‡† {baseline_fps} fps)")
            
            return output_video
            
        except KeyboardInterrupt:
            self.logger.warning("âš ï¸ ç”¨æˆ·ä¸­æ–­å¤„ç†ï¼Œè¿›åº¦å·²ä¿å­˜")
            self.save_progress()
            raise
        except Exception as e:
            self.logger.error(f"âŒ ä¼˜åŒ–å¢å¼ºå¤„ç†å¤±è´¥: {str(e)}")
            self.save_progress()
            raise

def main():
    """ä¸»ç¨‹åºå…¥å£"""
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•: python optimized_theater_video_enhancer.py input_video.mp4 [output_video.mp4] [--resume]")
        print("é€‰é¡¹:")
        print("  --resume    ä»ä¸Šæ¬¡ä¸­æ–­çš„åœ°æ–¹ç»§ç»­å¤„ç†")
        print("  --clean     æ¸…ç†å·¥ä½œç©ºé—´å¹¶é‡æ–°å¼€å§‹")
        sys.exit(1)
    
    input_video = sys.argv[1]
    output_video = sys.argv[2] if len(sys.argv) > 2 and not sys.argv[2].startswith('--') else None
    
    # å¤„ç†å‘½ä»¤è¡Œé€‰é¡¹
    resume = '--resume' in sys.argv
    clean = '--clean' in sys.argv
    
    enhancer = OptimizedTheaterVideoEnhancer()
    
    if clean:
        print("ğŸ§¹ æ¸…ç†å·¥ä½œç©ºé—´...")
        if enhancer.workspace.exists():
            shutil.rmtree(enhancer.workspace)
        enhancer.workspace.mkdir(exist_ok=True)
        enhancer.checkpoint_dir.mkdir(exist_ok=True)
        enhancer.load_progress()  # é‡æ–°åŠ è½½ç©ºè¿›åº¦
    
    if resume and enhancer.progress['stage'] != 'not_started':
        print(f"ğŸ”„ ä»æ–­ç‚¹ç»§ç»­å¤„ç†: {enhancer.progress['stage']}")
    
    try:
        enhancer.enhance_theater_video_complete(input_video, output_video)
    except KeyboardInterrupt:
        print("\nâš ï¸ å¤„ç†è¢«ç”¨æˆ·ä¸­æ–­")
        print("ğŸ’¾ è¿›åº¦å·²ä¿å­˜ï¼Œå¯ä½¿ç”¨ --resume é€‰é¡¹ç»§ç»­å¤„ç†")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ å¤„ç†å¤±è´¥: {e}")
        print("ğŸ’¾ è¿›åº¦å·²ä¿å­˜ï¼Œå¯ä½¿ç”¨ --resume é€‰é¡¹ç»§ç»­å¤„ç†")
        sys.exit(1)

if __name__ == "__main__":
    main()